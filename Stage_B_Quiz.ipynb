{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOhoEPJ3EkkjuaTut2P3JuY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akanbiabiodun25/Hamoye-166a464ba141f000/blob/main/Stage_B_Quiz.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ETDu_fWCTI5q"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# update or install the necessary libraries\n",
        "!pip install openai==v0.28.1\n",
        "!pip install --upgrade python-dotenv\n",
        "!pip install --upgrade langchain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import os\n",
        "import IPython\n",
        "from dotenv import load_dotenv"
      ],
      "metadata": {
        "id": "57vtdaLeTOuJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_dotenv()\n",
        "\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "LQS-sCI4VwOt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_open_params(\n",
        "    model=\"gpt-3.5-turbo-instruct\",\n",
        "    temperature=0.7,\n",
        "    max_tokens=256,\n",
        "    top_p=1,\n",
        "    frequency_penalty=0,\n",
        "    presence_penalty=0,\n",
        "):\n",
        "    \"\"\"set openai parameter\"\"\"\n",
        "    openai_params = {}\n",
        "\n",
        "    openai_params['model'] = model\n",
        "    openai_params['temperature'] = temperature\n",
        "    openai_params['max_tokens'] = max_tokens\n",
        "    openai_params['top_p'] = top_p\n",
        "    openai_params['frequency_penalty'] = frequency_penalty\n",
        "    openai_params['presence_penalty'] = presence_penalty\n",
        "    return openai_params\n",
        "\n",
        "def get_completion(params, prompt):\n",
        "    \"\"\"Get completion from openai api\"\"\"\n",
        "    response = openai.Completion.create(\n",
        "        engine = params['model'],\n",
        "        prompt = prompt,\n",
        "        temperature = params['temperature'],\n",
        "        max_tokens = params['max_tokens'],\n",
        "        top_p = params['top_p'],\n",
        "        frequency_penalty = params['frequency_penalty'],\n",
        "        presence_penalty = params['presence_penalty'],\n",
        "    )\n",
        "    return response"
      ],
      "metadata": {
        "id": "2-zwgdaBVxYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.ChatCompletion.create(\n",
        "\n",
        "model=\"gpt-3.5-turbo\",\n",
        "\n",
        "messages=[\n",
        "\n",
        "{\n",
        "\n",
        "\"role\": \"system\",\n",
        "\n",
        "\"content\": \"You are a knowledgeable assistant. A user will ask a question and you should provide a clear and concise answer briefly enough to fit as an MCQ option.\"\n",
        "\n",
        "},\n",
        "\n",
        "{\n",
        "\n",
        "\"role\": \"user\",\n",
        "\n",
        "\"content\": \"What causes the Northern Lights?\"\n",
        "\n",
        "}\n",
        "\n",
        "],\n",
        "\n",
        "temperature=0,\n",
        "\n",
        "max_tokens=150,\n",
        "\n",
        "top_p=1\n",
        "\n",
        ")\n",
        "\n",
        "print(response.choices[0].message['content'])"
      ],
      "metadata": {
        "id": "ChcGzN0CjI0D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71da4dc0-a4d2-4b01-ee13-261ddfa27d8d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Solar wind interacting with the Earth's magnetic field.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",  # Note: This model might be unavailable, consider alternatives\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"Provide a concise fact about the event in history mentioned by the user briefly enough to fit as an MCQ option.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"What was the main cause of the American Civil War?\"\n",
        "        }\n",
        "    ],\n",
        "    temperature=0.7,  # Increased for some creativity in fact selection\n",
        "    max_tokens=30,  # Limited for a concise fact\n",
        "    top_p=0.9  # Balanced informativeness and diversity\n",
        ")\n",
        "\n",
        "print(response.choices[0].message['content'])"
      ],
      "metadata": {
        "id": "3z11LU9CjRCU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "500a11ff-4eeb-4624-f2f7-aca72fedc40a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The main cause of the American Civil War was: D. Disagreements over states' rights and slavery.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.ChatCompletion.create(\n",
        "\n",
        "model=\"gpt-3.5-turbo\",\n",
        "\n",
        "messages=[\n",
        "\n",
        "{\n",
        "\n",
        "\"role\": \"system\",\n",
        "\n",
        "\"content\": \"You are to summarize the provided text into a concise form, maintaining the key points and context, briefly enough to fit as an MCQ option.\"\n",
        "\n",
        "},\n",
        "\n",
        "{\n",
        "\n",
        "\"role\": \"user\",\n",
        "\n",
        "\"content\": \"The economy has been growing steadily over the past few quarters, driven by increases in consumer spending and substantial investments in renewable energy infrastructure. Unemployment rates have also fallen to record lows as new industries are creating more jobs.\"\n",
        "\n",
        "}\n",
        "\n",
        "],\n",
        "\n",
        "temperature=0,\n",
        "\n",
        "max_tokens=100,\n",
        "\n",
        "top_p=1\n",
        "\n",
        ")\n",
        "\n",
        "print(response.choices[0].message['content'])"
      ],
      "metadata": {
        "id": "h7UuUGd-jgVJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6361e379-d1e0-4682-c71a-7f2c3effb6da"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The economy is growing steadily due to consumer spending and investments in renewable energy, leading to record low unemployment rates and job creation in new industries.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.ChatCompletion.create(\n",
        "\n",
        "model=\"gpt-3.5-turbo\",\n",
        "\n",
        "messages=[\n",
        "{\n",
        " \"role\": \"system\",\n",
        "\n",
        "\n",
        "\"content\": \"Translate the following sentence into Spanish concisely to fit as an MCQ option.\" # Insert system role and content here\n",
        "},\n",
        "{\n",
        "\n",
        "\"role\": \"user\",\n",
        "\n",
        "\"content\": \"What time is the meeting?\"\n",
        "\n",
        "}\n",
        "\n",
        "],\n",
        "\n",
        "temperature=0,\n",
        "\n",
        "max_tokens=30,\n",
        "\n",
        "top_p=1\n",
        "\n",
        ")\n",
        "\n",
        "print(response.choices[0].message['content'])"
      ],
      "metadata": {
        "id": "uonTuxuzjoQd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13ed801b-a13b-41b0-9111-f129df61d824"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "¿A qué hora es la reunión?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"Classify the sentiment of the text provided by the user as positive, negative, or neutral.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"I had an awful experience at the restaurant. The food was bland and the service was slow.\"\n",
        "        }\n",
        "    ],\n",
        "    temperature=0.7,  # Increased for some creativity\n",
        "    max_tokens=30,  # Increased to allow for a more complete response\n",
        "    top_p=0.9  # Adjusted for a balance between informativeness and diversity\n",
        ")\n",
        "\n",
        "print(response.choices[0].message['content'])"
      ],
      "metadata": {
        "id": "zOHkDD_4jwqY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a767115-f3fc-4c29-f40d-398e48766be8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The sentiment of the text is negative.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.ChatCompletion.create(\n",
        "\n",
        "model=\"gpt-3.5-turbo\",\n",
        "\n",
        "messages=[\n",
        "\n",
        "{\n",
        "\n",
        "\"role\": \"system\",\n",
        "\n",
        "\"content\": \"You will be provided with a sentence in English, and your task is to translate it into German.\"\n",
        "\n",
        "},\n",
        "\n",
        "{\n",
        "\n",
        "\"role\": \"user\",\n",
        "\n",
        "\"content\": \"How do you say 'I love to travel in German?\"\n",
        "\n",
        "}\n",
        "\n",
        "],\n",
        "\n",
        "temperature=0,\n",
        "\n",
        "max_tokens=64,\n",
        "\n",
        "top_p=1\n",
        "\n",
        ")\n",
        "\n",
        "print(response.choices[0].message['content'])"
      ],
      "metadata": {
        "id": "A23kCo7rj36n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "347fa803-5729-4bf7-ff0b-0db5cb57e48c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ich liebe es zu reisen.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"What is cloud computing?\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Explain the concept of cloud computing briefly enough to fit as an MCQ option.\"\n",
        "        }\n",
        "    ],\n",
        "    temperature=0.7,  # Increased for some creativity\n",
        "    max_tokens=60,  # Increased to allow for a more comprehensive explanation\n",
        "    top_p=0.9  # Adjusted for a balance between informativeness and diversity\n",
        ")\n",
        "\n",
        "print(response.choices[0].message['content'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TiLxxThmRSV7",
        "outputId": "027cf963-1fd5-4668-d5db-c30506820a0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloud computing is a technology that allows users to access and store data, applications, and services over the internet instead of on a local computer or server.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        " messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"Who is known as the father of computer science?\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Provide a brief, accurate answer to the user’s question that can be used as an MCQ option.\"\n",
        "        }\n",
        "    ],\n",
        "    temperature=0.7,\n",
        "    max_tokens=30,\n",
        "    top_p=0.9\n",
        ")\n",
        "\n",
        "print(response.choices[0].message['content'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1CHMe8oT8xQ",
        "outputId": "3af7625e-ce66-4f54-ebff-4138132156dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alan Turing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"Summarize the text in a concise form, highlighting key points about the economy.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"The economy has been growing steadily over the past few quarters, driven by increases in consumer spending and substantial investments in renewable energy infrastructure. Unemployment rates have also fallen to record lows as new industries are creating more jobs.\"\n",
        "        }\n",
        "    ],\n",
        "    temperature=0.7,  # Increased for some creativity in phrasing\n",
        "    max_tokens=30,  # Reduced for a tighter MCQ option\n",
        "    top_p=0.9  # Balanced informativeness and diversity\n",
        ")\n",
        "\n",
        "print(response.choices[0].message['content'])"
      ],
      "metadata": {
        "id": "s70J-nO1j-6p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "132a3f76-85b3-4aa8-bd5c-f483ffac09ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The economy is experiencing steady growth fueled by consumer spending and investments in renewable energy infrastructure. Unemployment rates have reached record lows due to job creation in new\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",  # Note: This model might be unavailable, consider alternatives\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"Classify the following text's tone in a brief form that could fit as an MCQ option.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\":\"The meeting was cancelled due to unforeseen circumstances.\"\n",
        "\n",
        "        }\n",
        "    ],\n",
        "    temperature=0,  # Lowest randomness (might lead to repetitive responses)\n",
        "    max_tokens=15,  # Limited for a brief classification\n",
        "    top_p=1  # Focuses on the most likely words (might be overly rigid)\n",
        ")\n",
        "\n",
        "print(response.choices[0].message['content'])"
      ],
      "metadata": {
        "id": "fm0IzgZfkGWL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e13e0db-a563-41c3-f151-4bc16c7b6783"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neutral\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"Summarize the following text into a concise phrase suitable for an MCQ answer option.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"The internet was developed to help researchers communicate and share computing resources. Today, it connects millions of people and devices across the globe.\"\n",
        "        }\n",
        "    ],\n",
        "    temperature=0,\n",
        "    max_tokens=30,\n",
        "    top_p=1\n",
        ")\n",
        "\n",
        "print(response.choices[0].message['content'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJzRHjj8XRv9",
        "outputId": "8da7ce96-01bb-4adf-b22c-3cb9650ad53a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evolution of the internet from research communication to global connectivity.\n"
          ]
        }
      ]
    }
  ]
}