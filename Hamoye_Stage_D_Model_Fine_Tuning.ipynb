{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akanbiabiodun25/Hamoye-166a464ba141f000/blob/main/Hamoye_Stage_D_Model_Fine_Tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rikTPbKs5FML",
        "outputId": "88b00aa0-7396-4b04-d65b-4a9e44fbb4bd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training complete (assuming one training step here)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "from transformers import AdamW, AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "# Save the checkpoint name (assuming you want to use a pre-trained model)\n",
        "checkpoint = \"bert-base-uncased\"  # \"bert-base-incased\" is also a valid option\n",
        "\n",
        "# Load tokenizer from the pre-trained model\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "\n",
        "# Load model from the pre-trained model\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
        "\n",
        "# Sample sentences\n",
        "sentences = [\"I've been waiting for a HuggingFace course my whole life.\", \"This course is amazing!\"]\n",
        "labels = torch.tensor([1, 1])  # Assuming labels are 1 for both sentences\n",
        "\n",
        "# Tokenize sentences with padding, truncation, and return tensors\n",
        "batch = tokenizer(sentences, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "# Add \"labels\" to the batch dictionary (assuming it's for classification)\n",
        "batch[\"labels\"] = labels\n",
        "\n",
        "# Create optimizer\n",
        "optimizer = AdamW(model.parameters())  # Using AdamW optimizer\n",
        "\n",
        "# Forward pass (assuming you want to classify the sentiment of the sentences)\n",
        "outputs = model(**batch)  # Unpack the batch dictionary for the model\n",
        "loss = outputs.loss  # Extract the loss from the model output\n",
        "\n",
        "# Backward pass and parameter update\n",
        "loss.backward()\n",
        "optimizer.step()\n",
        "\n",
        "print(\"Training complete (assuming one training step here)\")  # Add for clarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubVXvwF_5Uj7",
        "outputId": "515e61bc-393f-480c-839b-aefd755ea2bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.19.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.14.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.32.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.1->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.1->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.1->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.1->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
            "        num_rows: 3668\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
            "        num_rows: 408\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
            "        num_rows: 1725\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets\n",
        "from datasets import load_dataset\n",
        "\n",
        "raw_datasets = load_dataset(\"glue\", \"mrpc\")\n",
        "\n",
        "print(raw_datasets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcphYr2I8SRA",
        "outputId": "62d123c7-4f4e-4bf0-af68-099a6d9b2239"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'sentence1': 'Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence .',\n",
              " 'sentence2': 'Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .',\n",
              " 'label': 1,\n",
              " 'idx': 0}"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "raw_train_dataset = raw_datasets[\"train\"]\n",
        "raw_train_dataset[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBfICT9C8kRl",
        "outputId": "676284c8-fb5a-433b-aeea-9a6c1419eb7a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'sentence1': Value(dtype='string', id=None),\n",
              " 'sentence2': Value(dtype='string', id=None),\n",
              " 'label': ClassLabel(names=['not_equivalent', 'equivalent'], id=None),\n",
              " 'idx': Value(dtype='int32', id=None)}"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "raw_train_dataset.features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pwt5U3Zj8lmU"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bjkDCgjT9dRA"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "checkpoint = \"bert-base-uncased\"  # Model identifier, not a path\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "# Tokenize sentence 1 from the \"sentence\" column in the training split\n",
        "tokenized_sentences_1 = tokenizer(raw_datasets[\"train\"][\"sentence1\"])\n",
        "\n",
        "# Tokenize sentence 2 from the \"sentence\" column in the training split\n",
        "tokenized_sentences_2 = tokenizer(raw_datasets[\"train\"][\"sentence2\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGbwzrIa9qim",
        "outputId": "67984ecc-71fd-4623-c5a1-d104886f0ed1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_ids': [101, 2023, 2003, 1996, 2034, 6251, 102, 2023, 2003, 1996, 2117, 2028, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inputs = tokenizer(\"This is the first sentence\", \"This is the second one.\")\n",
        "inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXmY5wP-9_wE",
        "outputId": "331e2e4a-bde8-4744-d584-bdf2c3e76edd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['[CLS]',\n",
              " 'this',\n",
              " 'is',\n",
              " 'the',\n",
              " 'first',\n",
              " 'sentence',\n",
              " '[SEP]',\n",
              " 'this',\n",
              " 'is',\n",
              " 'the',\n",
              " 'second',\n",
              " 'one',\n",
              " '.',\n",
              " '[SEP]']"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"])\n",
        "tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K6Zkl--3-ZBv"
      },
      "outputs": [],
      "source": [
        "\n",
        "tokens = ['[CLS]', \"this\", \"is\", \"the\", \"first\", \"sentence\", ',', '[SEP]', \"this\", \"is\", \"the\",\"second\", ',', '[SEP]']\n",
        "attention_mask = [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]\n",
        "\n",
        "# Use tokens and attention_mask separately for your model or further processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lp5_etwt--X5"
      },
      "outputs": [],
      "source": [
        "tokenized_dataset = tokenizer(\n",
        "    raw_datasets[\"train\"][\"sentence1\"],\n",
        "    raw_datasets[\"train\"][\"sentence2\"],\n",
        "    padding= True,\n",
        "    truncation=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7R7-xfyUBw_Q"
      },
      "outputs": [],
      "source": [
        "def tokenize_function(example):\n",
        "\n",
        "\n",
        "  return tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154,
          "referenced_widgets": [
            "70588b3ecacc484b89da71f25cae7180",
            "152d9931075c473abcccc38f8bc98a73",
            "0fd043a6d67c428bab277f120ecc6637",
            "69d378fd866f4a28b1441a97d31166fe",
            "67dc6c7ce69e42c983009ca037db81e3",
            "a6a27c5ece674977a0dc9e1d1a3ceea7",
            "d138e5f113d644659ffe3ec4742c527c",
            "7a9f21fc893d40a48080fc1e48d180d7",
            "8017d8c61e7a487db87d9f2b1442279c",
            "bd29138f267a4675a0148eceb5cfb9d4",
            "e82735f0b3ac417c8fe58f4d7d45311b"
          ]
        },
        "id": "fVBtVW6uCjV3",
        "outputId": "4b930845-7cfe-426f-f17e-8fb42e216989"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "70588b3ecacc484b89da71f25cae7180",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/408 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'The way the 🤗 Datasets library applies this processing is by adding new fields to the datasets,\\none for each key in the dictionary returned by the preprocessing function:'"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
        "\n",
        "# Explanation about how Datasets library works\n",
        "'''The way the 🤗 Datasets library applies this processing is by adding new fields to the datasets,\n",
        "one for each key in the dictionary returned by the preprocessing function:'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erxtsgOoC7KH",
        "outputId": "39f7a0b9-9f7e-4234-9d67-c49769ce87ed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DataCollatorWithPadding(tokenizer=BertTokenizerFast(name_or_path='bert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
              "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "}, padding=True, max_length=None, pad_to_multiple_of=None, return_tensors='pt')"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "data_collator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqVEFSA2EcOb",
        "outputId": "5c4f0002-5312-4b6f-aa6a-993f211592da"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[50, 59, 47, 67, 59, 50, 62, 32]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "samples = tokenized_datasets[\"train\"][:8]\n",
        "\n",
        "samples = {k: v for k, v in samples.items() if k not in [\"idx\", \"sentence1\", \"sentence2\"]}\n",
        "\n",
        "[len(x) for x in samples[\"input_ids\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1lcxDAwGLte",
        "outputId": "f7461649-9197-4ca9-fd99-c3624ff5f2e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_ids': torch.Size([8, 67]), 'token_type_ids': torch.Size([8, 67]), 'attention_mask': torch.Size([8, 67]), 'labels': torch.Size([8])}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "batch = data_collator(samples)\n",
        "\n",
        "# Print the shapes of elements in the batch\n",
        "print({k: v.shape for k, v in batch.items()})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "13353bb8dc5444ab8031d868326c806c",
            "e5c68d8de65e44b089b4b9e14aa3753e",
            "e15c53783c994ae4869c7675beac8ba8",
            "eda8c74b61ec4782a368dd199390102f",
            "26e0e90956f94c3992bb7afae89a43e6",
            "c40a94dd21a847ca9e30de09afa51ea9",
            "62443c400f2f4cac8e0124f3fa26f081",
            "723d781ab3f04c55b2efff36d662fd6b",
            "dbc6591f505c4d2abd1de6e3d7577f38",
            "9c9d12c690614ec08a688806a92d6481",
            "b58f436dcf664d8eb9ba3ca574c38707"
          ]
        },
        "id": "8BPPlMMUIVzc",
        "outputId": "9c012d36-f8bb-4ccc-fa98-7e34f3c3b972"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "13353bb8dc5444ab8031d868326c806c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/408 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from datasets import load_dataset  # Correct import\n",
        "\n",
        "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
        "\n",
        "# Load the dataset\n",
        "raw_datasets = load_dataset(\"glue\", \"mrpc\")  # Consistent variable name\n",
        "\n",
        "# Define the pre-trained model checkpoint\n",
        "checkpoint = \"bert-base-uncased\"  # Typo correction: 'bert'\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)  # Typo correction: 'pretrained'\n",
        "\n",
        "def tokenize_function(example):\n",
        "    \"\"\"Tokenizes a pair of sentences with truncation.\"\"\"\n",
        "    return tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation=True)\n",
        "\n",
        "# Tokenize the dataset in batches\n",
        "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
        "\n",
        "# Create the data collator\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkjABWuzIqUu",
        "outputId": "2aee6633-f827-492c-9784-d5350e3e4021"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.30.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.3.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.23.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.5.40)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.23.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.3.0+cu121)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.30.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers[torch]) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch]) (12.5.40)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->transformers[torch]) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install accelerate -U\n",
        "\n",
        "!pip install transformers[torch]\n",
        "from transformers import TrainingArguments\n",
        "training_args = TrainingArguments(\"test-trainer\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oa3eH815Komm",
        "outputId": "d9924127-ef96-4981-c2a8-d9f44a6a70c2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "# Define the pre-trained model checkpoint\n",
        "checkpoint = \"bert-base-uncased\"  # Replace with your desired checkpoint name\n",
        "\n",
        "# Load the pre-trained model (assuming num_labels=2)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQF7wvlbNFmZ",
        "outputId": "ab430b41-742a-4011-ccdb-1ea6c56be1c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4.41.1\n"
          ]
        }
      ],
      "source": [
        "from transformers import __version__\n",
        "print(__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxXBWudmOeZj",
        "outputId": "4a4b56a9-4697-48d4-d1c6-d3ea0db2f599"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "# Define the pre-trained model checkpoint name (replace with your desired checkpoint)\n",
        "checkpoint = \"bert-base-uncased\"\n",
        "\n",
        "# Load the pre-trained model\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0jz6eoG0LbyI"
      },
      "outputs": [],
      "source": [
        "\n",
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model,  # Replace with your loaded model\n",
        "    training_args,  # Replace with your TrainingArguments instance\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yiAo3c5ePv8-"
      },
      "outputs": [],
      "source": [
        "#trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "yUEocBeGa570",
        "outputId": "22e76bdd-babf-4582-8497-2b4657c2da7b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(408, 2) (408,)\n"
          ]
        }
      ],
      "source": [
        "predictions = trainer.predict(tokenized_datasets[\"validation\"])\n",
        "\n",
        "print(predictions.predictions.shape, predictions.label_ids.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nLRethPobZ4p"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "preds = np.argmax(predictions.predictions, axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 729,
          "referenced_widgets": [
            "d3badedd89db41c9b3d8eb9f2454fb62",
            "b3e6f2364dc740ad8b2c6ca8374c3968",
            "98bf3ac2006a492abc65ff012622573d",
            "861c5d9c92b2420f9eacc8d2003e0db4",
            "7d2f83b3c4d441219eacdec86f5324cd",
            "89afc011e5004936ba6b2443f6029107",
            "c71b4b85b4e541e592721d88c88a17f1",
            "43adbb55e0ae4205a9eadfb320bacbdf",
            "3046b3f2522b4cb7a2b4a255c66a7d75",
            "6bb7fa0e522d4a739c250fec4aad8a6c",
            "d0086d192d6544bfb406aebd640bdf6c"
          ]
        },
        "id": "riWMkWeVdggJ",
        "outputId": "85036e8b-ccea-4b9c-a3f0-b7ce440e1e10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.19.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.25.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.6.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.23.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.14.0)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.9.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
            "Installing collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.2\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d3badedd89db41c9b3d8eb9f2454fb62",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/5.75k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'accuracy': 0.3161764705882353, 'f1': 0.0}"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "!pip install evaluate\n",
        "\n",
        "\n",
        "import evaluate\n",
        "\n",
        "# Load the ERPC metric from the glue library\n",
        "metric = evaluate.load(\"glue\", \"mrpc\")  # Typo correction: \"mrpc\" for ERPC\n",
        "\n",
        "# Prepare the ground truth data (assuming labels are in 'label_ids')\n",
        "#references = predictions.label_ids\n",
        "\n",
        "# Compute the metric scores\n",
        "metric.compute(predictions=preds, references=predictions.label_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ln67Ed6Jdjgb"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(eval_preds):\n",
        "    \"\"\"\n",
        "    Computes the MRPC metric on the provided evaluation predictions.\n",
        "\n",
        "    Args:\n",
        "        eval_preds (dict): A dictionary containing evaluation predictions.\n",
        "            Expected keys: \"logits\" (model outputs before softmax) and \"label_ids\" (ground truth labels).\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing the computed MRPC metric scores.\n",
        "    \"\"\"\n",
        "\n",
        "    metric = evaluate.load(\"glue\", \"mrpc\")  # Load the MRPC metric\n",
        "\n",
        "    logits,labels = eval_preds[\"label_ids\"]\n",
        "\n",
        "    predictions = np.argmax(logits, axis=-1)  # Find predicted class labels\n",
        "\n",
        "    return metric.compute(predictions=predictions, references=labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gxxx-d2izrai",
        "outputId": "27b7ab18-09fa-47be-85f3-f9fc1aa0c768"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name: transformers\n",
            "Version: 4.41.1\n",
            "Summary: State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow\n",
            "Home-page: https://github.com/huggingface/transformers\n",
            "Author: The Hugging Face team (past and future) with the help of all our contributors (https://github.com/huggingface/transformers/graphs/contributors)\n",
            "Author-email: transformers@huggingface.co\n",
            "License: Apache 2.0 License\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: filelock, huggingface-hub, numpy, packaging, pyyaml, regex, requests, safetensors, tokenizers, tqdm\n",
            "Required-by: \n"
          ]
        }
      ],
      "source": [
        "!pip show transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5n36ayQpdjzT",
        "outputId": "c61fa603-a8e8-4ab9-e66f-162b1647d767"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "training_args=TrainingArguments(\"test-trainer\", evaluation_strategy=\"epoch\")\n",
        "\n",
        "\n",
        "# Model loading\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
        "\n",
        "# Create the Trainer instance\n",
        "trainer = Trainer(\n",
        "    model,\n",
        "    training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,  # Use the defined `compute_metrics` function\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D9fYYPRXzrpW"
      },
      "outputs": [],
      "source": [
        "#trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "068d05c7c65b4d00af3a45a77fa84326",
            "075737954525497e837a9da736313d0d",
            "5b30a76b8d3843c4adbe39cf3a318422",
            "8512abfb3e4b4da5bec9bb18b6cf2da2",
            "41e5b9affce2480a8aa8b159fa5a0e93",
            "30261d4719044732bbcb8f1293eec3b0",
            "00eb02e931774f5db9bd1f259b524153",
            "99264947bcdf43f1b0b0799df186b1ee",
            "6d7923c824144f1f8c19b09faeed66c8",
            "7958f8efdcb2411084b62e7f9bec4698",
            "34c74502ec8e43629d1029f52e263f0e",
            "bc44600265724608a033659b3f15b26d",
            "5abff6fc4e71446b974412876fd70b84",
            "43da891411984f5b90219c24928c1f0d",
            "e7a8cc79695b4788a57446d5878426a6",
            "e8f762acaa95468a80efe683c6c71845",
            "dce8f33164c24e749a343c6b85f08e93",
            "cce7e5e39b5e4de0ac98317e9ca324b1",
            "342500f7b84047429d3891736bc584b5",
            "e5596bb6951f4f26b6ab0f7559672c88",
            "536fb15c9d4b4126b07ee11cf267f3da",
            "5fbedac3216d4bce93ba2e8d0d880909",
            "1b465a9fae1a4d90a1467dfdf703b8a1",
            "05c583e1319f4e37bf4169ba415459f5",
            "10d0d2a6dab749cbafb2fb7d797dffb6",
            "efdda830abc442e1b125c474c7b02057",
            "43c19d81b7704786aaae293237d36fdb",
            "ea855ef28b194860980b65ed33355857",
            "ca44cd25451846afab140913b046d430",
            "ee25e44c03914f849eeba4379d5c2e46",
            "8f6476ad2970476290016b872164e978",
            "99ac9859eaea421880e0c30c626503ff",
            "6456bf586ad84e27806ca49c0af33c64"
          ]
        },
        "id": "S5VEf6n_zr2I",
        "outputId": "a45e28c1-7069-4d8c-c5f6-12e1a000fa45"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "068d05c7c65b4d00af3a45a77fa84326",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/3668 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bc44600265724608a033659b3f15b26d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/408 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1b465a9fae1a4d90a1467dfdf703b8a1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1725 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
        "\n",
        "# Load the MRPC dataset (assuming you want MRPC data)\n",
        "raw_datasets = load_dataset(\"glue\", \"mrpc\")\n",
        "\n",
        "# Pre-trained checkpoint name\n",
        "checkpoint = \"bert-base-uncased\"\n",
        "\n",
        "# Load the tokenizer for the pre-trained model\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "\n",
        "\n",
        "def tokenize_function(example):\n",
        "    \"\"\"\n",
        "    Tokenizes a single example from the dataset, handling both sentences for MRPC.\n",
        "\n",
        "    Args:\n",
        "        example (dict): A dictionary containing the data for a single example.\n",
        "            Expected keys: \"sentence1\" (first sentence), \"sentence2\" (second sentence).\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing the tokenized data with truncation if applicable.\n",
        "    \"\"\"\n",
        "\n",
        "    return tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation=True)\n",
        "\n",
        "\n",
        "# Apply the tokenize_function to all examples in the dataset (batched processing)\n",
        "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
        "\n",
        "# Create the data collator for padding and batching\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scKHP7OZKyNx",
        "outputId": "2f35a3ad-3515-41a0-a64d-8ca786ae2118"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['labels', 'input_ids', 'token_type_ids', 'attention_mask']\n"
          ]
        }
      ],
      "source": [
        "# Remove unnecessary columns\n",
        "tokenized_datasets = tokenized_datasets.remove_columns([\"sentence1\", \"sentence2\", \"idx\"])\n",
        "\n",
        "# Rename the label column (assuming \"label\" exists)\n",
        "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
        "\n",
        "# Set the format to PyTorch tensors\n",
        "tokenized_datasets.set_format(\"torch\")\n",
        "\n",
        "# Print column names for the training set\n",
        "print(tokenized_datasets[\"train\"].column_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g9dWXnI8KynG"
      },
      "outputs": [],
      "source": [
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Train Data Loader\n",
        "train_dataloader = DataLoader(\n",
        "    tokenized_datasets[\"train\"],\n",
        "    shuffle=True,\n",
        "    batch_size=8,\n",
        "    collate_fn=data_collator  # Use '=' for keyword assignment\n",
        ")\n",
        "\n",
        "# Evaluation Data Loader\n",
        "eval_dataloader = DataLoader(\n",
        "    tokenized_datasets[\"validation\"],\n",
        "    batch_size=8,\n",
        "    collate_fn=data_collator  # Use '=' for keyword assignment\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wTKGi7AKyyT",
        "outputId": "b32495f2-8953-4b11-9c1e-367b4051ce2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'labels': torch.Size([8]), 'input_ids': torch.Size([8, 72]), 'token_type_ids': torch.Size([8, 72]), 'attention_mask': torch.Size([8, 72])}\n"
          ]
        }
      ],
      "source": [
        "# Get a single batch from the training data loader\n",
        "batch = next(iter(train_dataloader))\n",
        "\n",
        "# Print the shapes of all elements in the batch\n",
        "print({k: v.shape for k, v in batch.items()})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        },
        "id": "EvSAgsA-Ky8H",
        "outputId": "26a0551f-8f05-4a6a-ff8a-598ac3c40230"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'Invalid key. Only three types of key are available: (1) string, (2) integers for backend Encoding, and (3) slices for data subsetting.'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-527c7a10f95c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1689\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1691\u001b[0;31m         outputs = self.bert(\n\u001b[0m\u001b[1;32m   1692\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1693\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1050\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You cannot specify both input_ids and inputs_embeds at the same time\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1052\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn_if_padding_and_no_attention_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1053\u001b[0m             \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mwarn_if_padding_and_no_attention_mask\u001b[0;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[1;32m   4455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4456\u001b[0m         \u001b[0;31m# Check only the first and last input IDs to reduce overhead.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4457\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_token_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4458\u001b[0m             warn_string = (\n\u001b[1;32m   4459\u001b[0m                 \u001b[0;34m\"We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m             raise KeyError(\n\u001b[0m\u001b[1;32m    261\u001b[0m                 \u001b[0;34m\"Invalid key. Only three types of key are available: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m                 \u001b[0;34m\"(1) string, (2) integers for backend Encoding, and (3) slices for data subsetting.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Invalid key. Only three types of key are available: (1) string, (2) integers for backend Encoding, and (3) slices for data subsetting.'"
          ]
        }
      ],
      "source": [
        "outputs = model(batch)\n",
        "\n",
        "print(outputs.loss, outputs.logits.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wNfIMJxKzGR",
        "outputId": "c95ee27a-834d-480d-e931-f56e6e1a4b51"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from transformers import AdamW  # Use AdamW optimizer\n",
        "\n",
        "\n",
        "# Create the optimizer\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpeLbn9-zsBB",
        "outputId": "7ef5ef99-63a5-4033-e42d-3bf99be73e39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of training steps: 1377\n"
          ]
        }
      ],
      "source": [
        "from transformers import get_scheduler\n",
        "\n",
        "num_epochs = 3\n",
        "\n",
        "# Calculate the total number of training steps\n",
        "num_training_steps = num_epochs * len(train_dataloader)\n",
        "\n",
        "# Define the learning rate scheduler\n",
        "lr_scheduler = get_scheduler(\n",
        "    \"linear\",  # Choose the desired scheduler type (e.g., \"linear\", \"cosine\")\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=0,  # Adjust warmup steps if needed\n",
        "    num_training_steps=num_training_steps,\n",
        ")\n",
        "\n",
        "print(f\"Number of training steps: {num_training_steps}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uBstpV3PJkc",
        "outputId": "6ad0054f-9650-46b2-9a34-95914ae0c962"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Check for GPU availability\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "# Move the model to the chosen device\n",
        "model.to(device)\n",
        "\n",
        "# Print the device information (optional)\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olQ93E6RPKS-",
        "outputId": "8495ae66-7a11-4824-922f-300897897f88"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1377/1377 [2:33:27<00:00,  5.94s/it]"
          ]
        }
      ],
      "source": [
        "# Import libraries (assuming tqdm for progress bar)\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Training loop\n",
        "#num_training_steps = num_epochs * len(train_dataloader)\n",
        "progress_bar = tqdm(range(num_training_steps))  # Initialize progress bar\n",
        "\n",
        "model.train()  # Set model to training mode\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for batch in train_dataloader:\n",
        "        # Move data to device (GPU/CPU)\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(**batch)\n",
        "        loss = outputs.loss  # Extract the loss from outputs\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Optimizer steps\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "\n",
        "        # Zero gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Update progress bar (assuming one update per batch)\n",
        "        progress_bar.update(1)\n",
        "\n",
        "# Close progress bar\n",
        "#progress_bar.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 775
        },
        "id": "LOGe6apePK5M",
        "outputId": "d464f993-e084-4501-da96-6f461a896901",
        "collapsed": true
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "unhashable type: 'slice'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-008dcc6cea94>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Forward pass with gradient suppression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m  \u001b[0;31m# Extract logits from outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1689\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1691\u001b[0;31m         outputs = self.bert(\n\u001b[0m\u001b[1;32m   1692\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1693\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1050\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You cannot specify both input_ids and inputs_embeds at the same time\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1052\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn_if_padding_and_no_attention_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1053\u001b[0m             \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mwarn_if_padding_and_no_attention_mask\u001b[0;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[1;32m   4455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4456\u001b[0m         \u001b[0;31m# Check only the first and last input IDs to reduce overhead.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4457\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_token_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4458\u001b[0m             warn_string = (\n\u001b[1;32m   4459\u001b[0m                 \u001b[0;34m\"We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'slice'"
          ]
        }
      ],
      "source": [
        "import evaluate\n",
        "\n",
        "# Assuming the metric is accuracy (replace with your desired metric)\n",
        "metric = evaluate.load(\"glue\", \"mrpc\")\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()  # Set model to evaluation mode\n",
        "\n",
        "for batch in eval_dataloader:\n",
        "    # Move data to device (GPU/CPU)\n",
        "    batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "    # Forward pass with gradient suppression\n",
        "    with torch.no_grad():\n",
        "        outputs = model(batch)\n",
        "        logits = outputs.logits  # Extract logits from outputs\n",
        "\n",
        "    # Predictions and metric calculation\n",
        "    predictions = torch.argmax(logits, dim=-1)  # Corrected dimension for argmax\n",
        "    metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
        "\n",
        "# Compute the overall metric score\n",
        "metric.compute()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "linear = \"cosine\"  # Assuming linear refers to the scheduler type\n",
        "\n",
        "# Learning rate scheduler\n",
        "lr_scheduler = get_scheduler(\n",
        "    linear,\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=num_training_steps,\n",
        ")"
      ],
      "metadata": {
        "id": "hnpqeFXs53U5"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 810
        },
        "id": "guRWAUEGS4uI",
        "outputId": "fcf6b343-5668-4697-c29c-d55a28423ea5",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "\n",
            "  0%|          | 0/1377 [00:00<?, ?it/s]\u001b[A"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "unhashable type: 'slice'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-6c6748ce425c>\u001b[0m in \u001b[0;36m<cell line: 33>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1689\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1691\u001b[0;31m         outputs = self.bert(\n\u001b[0m\u001b[1;32m   1692\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1693\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1050\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You cannot specify both input_ids and inputs_embeds at the same time\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1052\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn_if_padding_and_no_attention_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1053\u001b[0m             \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mwarn_if_padding_and_no_attention_mask\u001b[0;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[1;32m   4455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4456\u001b[0m         \u001b[0;31m# Check only the first and last input IDs to reduce overhead.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4457\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_token_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4458\u001b[0m             warn_string = (\n\u001b[1;32m   4459\u001b[0m                 \u001b[0;34m\"We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'slice'"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1377 [00:26<?, ?it/s]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "from transformers import AutoModelForSequenceClassification, AdamW, get_scheduler\n",
        "\n",
        "# Create model\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)\n",
        "\n",
        "# Optimizer and learning rate\n",
        "optimizer = AdamW(model.parameters(), lr=3e-5)  # Adjust learning rate as needed\n",
        "\n",
        "# Device selection (GPU or CPU)\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Training parameters\n",
        "num_epochs = 3\n",
        "num_training_steps = num_epochs * len(train_dataloader)\n",
        "\n",
        "# Learning rate scheduler (optional)\n",
        "# Consider using a scheduler like CosineAnnealingLR or ReduceLROnPlateau\n",
        "lr_scheduler = get_scheduler(\n",
        "linear,\n",
        "optimizer,\n",
        "num_warmup_steps=0,\n",
        "num_training_steps = num_training_steps,\n",
        ")\n",
        "\n",
        "from tqdm import tqdm  # Import tqdm for progress bar\n",
        "\n",
        "# Training loop\n",
        "progress_bar = tqdm(range(num_training_steps))  # Initialize progress bar\n",
        "\n",
        "model.train()  # Set model to training mode\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for batch in train_dataloader:\n",
        "        # Move data to device\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(batch)\n",
        "        loss = outputs.loss\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Optimizer steps\n",
        "        optimizer.step()\n",
        "\n",
        "        # Learning rate scheduler (if used)\n",
        "        #if lr_scheduler is not None:\n",
        "        lr_scheduler.step()\n",
        "\n",
        "        # Zero gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Progress bar update\n",
        "        progress_bar.update(1)\n",
        "\n",
        "# Close progress bar\n",
        "#progress_bar.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ry0g5GozPLtU",
        "outputId": "6a61ef22-e6b7-43fd-db37-a4b021e52678"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "\n",
            "100%|██████████| 1377/1377 [2:34:12<00:00,  6.72s/it]\n",
            "\n",
            "  0%|          | 1/1377 [00:06<2:34:30,  6.74s/it]\u001b[A\n",
            "  0%|          | 2/1377 [00:14<2:47:37,  7.31s/it]\u001b[A\n",
            "  0%|          | 3/1377 [00:20<2:30:49,  6.59s/it]\u001b[A\n",
            "  0%|          | 4/1377 [00:26<2:28:50,  6.50s/it]\u001b[A\n",
            "  0%|          | 5/1377 [00:32<2:28:00,  6.47s/it]\u001b[A\n",
            "  0%|          | 6/1377 [00:40<2:33:19,  6.71s/it]\u001b[A\n",
            "  1%|          | 7/1377 [00:46<2:29:29,  6.55s/it]\u001b[A\n",
            "  1%|          | 8/1377 [00:52<2:26:19,  6.41s/it]\u001b[A\n",
            "  1%|          | 9/1377 [00:59<2:29:49,  6.57s/it]\u001b[A\n",
            "  1%|          | 10/1377 [01:05<2:24:07,  6.33s/it]\u001b[A\n",
            "  1%|          | 11/1377 [01:12<2:31:53,  6.67s/it]\u001b[A\n",
            "  1%|          | 12/1377 [01:21<2:44:19,  7.22s/it]\u001b[A\n",
            "  1%|          | 13/1377 [01:29<2:49:16,  7.45s/it]\u001b[A\n",
            "  1%|          | 14/1377 [01:34<2:35:17,  6.84s/it]\u001b[A\n",
            "  1%|          | 15/1377 [01:41<2:35:10,  6.84s/it]\u001b[A\n",
            "  1%|          | 16/1377 [01:47<2:27:12,  6.49s/it]\u001b[A\n",
            "  1%|          | 17/1377 [01:53<2:29:09,  6.58s/it]\u001b[A\n",
            "  1%|▏         | 18/1377 [01:59<2:22:11,  6.28s/it]\u001b[A\n",
            "  1%|▏         | 19/1377 [02:05<2:21:09,  6.24s/it]\u001b[A\n",
            "  1%|▏         | 20/1377 [02:13<2:30:53,  6.67s/it]\u001b[A\n",
            "  2%|▏         | 21/1377 [02:22<2:49:53,  7.52s/it]\u001b[A\n",
            "  2%|▏         | 22/1377 [02:29<2:46:52,  7.39s/it]\u001b[A\n",
            "  2%|▏         | 23/1377 [02:36<2:40:49,  7.13s/it]\u001b[A\n",
            "  2%|▏         | 24/1377 [02:43<2:41:14,  7.15s/it]\u001b[A\n",
            "  2%|▏         | 25/1377 [02:49<2:32:03,  6.75s/it]\u001b[A\n",
            "  2%|▏         | 26/1377 [02:56<2:37:12,  6.98s/it]\u001b[A\n",
            "  2%|▏         | 27/1377 [03:03<2:32:37,  6.78s/it]\u001b[A\n",
            "  2%|▏         | 28/1377 [03:11<2:44:51,  7.33s/it]\u001b[A\n",
            "  2%|▏         | 29/1377 [03:17<2:35:14,  6.91s/it]\u001b[A\n",
            "  2%|▏         | 30/1377 [03:24<2:37:16,  7.01s/it]\u001b[A\n",
            "  2%|▏         | 31/1377 [03:30<2:25:54,  6.50s/it]\u001b[A\n",
            "  2%|▏         | 32/1377 [03:37<2:32:54,  6.82s/it]\u001b[A\n",
            "  2%|▏         | 33/1377 [03:46<2:43:14,  7.29s/it]\u001b[A\n",
            "  2%|▏         | 34/1377 [03:53<2:43:11,  7.29s/it]\u001b[A\n",
            "  3%|▎         | 35/1377 [04:00<2:38:02,  7.07s/it]\u001b[A\n",
            "  3%|▎         | 36/1377 [04:07<2:38:51,  7.11s/it]\u001b[A\n",
            "  3%|▎         | 37/1377 [04:13<2:32:45,  6.84s/it]\u001b[A\n",
            "  3%|▎         | 38/1377 [04:21<2:41:48,  7.25s/it]\u001b[A\n",
            "  3%|▎         | 39/1377 [04:26<2:26:48,  6.58s/it]\u001b[A\n",
            "  3%|▎         | 40/1377 [04:34<2:36:39,  7.03s/it]\u001b[A\n",
            "  3%|▎         | 41/1377 [04:39<2:22:56,  6.42s/it]\u001b[A\n",
            "  3%|▎         | 42/1377 [04:47<2:29:49,  6.73s/it]\u001b[A\n",
            "  3%|▎         | 43/1377 [04:53<2:25:52,  6.56s/it]\u001b[A\n",
            "  3%|▎         | 44/1377 [05:01<2:32:59,  6.89s/it]\u001b[A\n",
            "  3%|▎         | 45/1377 [05:06<2:26:00,  6.58s/it]\u001b[A\n",
            "  3%|▎         | 46/1377 [05:12<2:22:02,  6.40s/it]\u001b[A\n",
            "  3%|▎         | 47/1377 [05:20<2:32:30,  6.88s/it]\u001b[A\n",
            "  3%|▎         | 48/1377 [05:26<2:27:00,  6.64s/it]\u001b[A\n",
            "  4%|▎         | 49/1377 [05:34<2:29:56,  6.77s/it]\u001b[A\n",
            "  4%|▎         | 50/1377 [05:39<2:19:25,  6.30s/it]\u001b[A\n",
            "  4%|▎         | 51/1377 [05:47<2:33:34,  6.95s/it]\u001b[A\n",
            "  4%|▍         | 52/1377 [05:53<2:27:42,  6.69s/it]\u001b[A\n",
            "  4%|▍         | 53/1377 [06:00<2:25:35,  6.60s/it]\u001b[A\n",
            "  4%|▍         | 54/1377 [06:05<2:20:03,  6.35s/it]\u001b[A\n",
            "  4%|▍         | 55/1377 [06:13<2:29:13,  6.77s/it]\u001b[A\n",
            "  4%|▍         | 56/1377 [06:19<2:24:56,  6.58s/it]\u001b[A\n",
            "  4%|▍         | 57/1377 [06:27<2:30:26,  6.84s/it]\u001b[A\n",
            "  4%|▍         | 58/1377 [06:34<2:31:40,  6.90s/it]\u001b[A\n",
            "  4%|▍         | 59/1377 [06:41<2:34:34,  7.04s/it]\u001b[A\n",
            "  4%|▍         | 60/1377 [06:46<2:22:54,  6.51s/it]\u001b[A\n",
            "  4%|▍         | 61/1377 [06:53<2:25:28,  6.63s/it]\u001b[A\n",
            "  5%|▍         | 62/1377 [07:00<2:25:23,  6.63s/it]\u001b[A\n",
            "  5%|▍         | 63/1377 [07:07<2:26:01,  6.67s/it]\u001b[A\n",
            "  5%|▍         | 64/1377 [07:14<2:27:47,  6.75s/it]\u001b[A\n",
            "  5%|▍         | 65/1377 [07:20<2:23:26,  6.56s/it]\u001b[A\n",
            "  5%|▍         | 66/1377 [07:27<2:26:40,  6.71s/it]\u001b[A\n",
            "  5%|▍         | 67/1377 [07:32<2:12:58,  6.09s/it]\u001b[A\n",
            "  5%|▍         | 68/1377 [07:39<2:20:19,  6.43s/it]\u001b[A\n",
            "  5%|▌         | 69/1377 [07:44<2:14:48,  6.18s/it]\u001b[A\n",
            "  5%|▌         | 70/1377 [07:51<2:17:15,  6.30s/it]\u001b[A\n",
            "  5%|▌         | 71/1377 [07:58<2:19:16,  6.40s/it]\u001b[A\n",
            "  5%|▌         | 72/1377 [08:04<2:16:52,  6.29s/it]\u001b[A\n",
            "  5%|▌         | 73/1377 [08:14<2:40:45,  7.40s/it]\u001b[A\n",
            "  5%|▌         | 74/1377 [08:19<2:29:02,  6.86s/it]\u001b[A\n",
            "  5%|▌         | 75/1377 [08:27<2:36:41,  7.22s/it]\u001b[A\n",
            "  6%|▌         | 76/1377 [08:33<2:26:44,  6.77s/it]\u001b[A\n",
            "  6%|▌         | 77/1377 [08:41<2:31:40,  7.00s/it]\u001b[A\n",
            "  6%|▌         | 78/1377 [08:46<2:24:03,  6.65s/it]\u001b[A\n",
            "  6%|▌         | 79/1377 [08:53<2:21:42,  6.55s/it]\u001b[A\n",
            "  6%|▌         | 80/1377 [08:59<2:18:10,  6.39s/it]\u001b[A\n",
            "  6%|▌         | 81/1377 [09:05<2:16:40,  6.33s/it]\u001b[A\n",
            "  6%|▌         | 82/1377 [09:13<2:27:07,  6.82s/it]\u001b[A\n",
            "  6%|▌         | 83/1377 [09:19<2:24:07,  6.68s/it]\u001b[A\n",
            "  6%|▌         | 84/1377 [09:27<2:32:11,  7.06s/it]\u001b[A\n",
            "  6%|▌         | 85/1377 [09:33<2:25:48,  6.77s/it]\u001b[A\n",
            "  6%|▌         | 86/1377 [09:40<2:26:29,  6.81s/it]\u001b[A\n",
            "  6%|▋         | 87/1377 [09:47<2:23:47,  6.69s/it]\u001b[A\n",
            "  6%|▋         | 88/1377 [09:54<2:31:09,  7.04s/it]\u001b[A\n",
            "  6%|▋         | 89/1377 [10:00<2:20:33,  6.55s/it]\u001b[A\n",
            "  7%|▋         | 90/1377 [10:07<2:24:44,  6.75s/it]\u001b[A\n",
            "  7%|▋         | 91/1377 [10:15<2:32:59,  7.14s/it]\u001b[A\n",
            "  7%|▋         | 92/1377 [10:22<2:33:03,  7.15s/it]\u001b[A\n",
            "  7%|▋         | 93/1377 [10:28<2:26:42,  6.86s/it]\u001b[A\n",
            "  7%|▋         | 94/1377 [10:36<2:29:29,  6.99s/it]\u001b[A\n",
            "  7%|▋         | 95/1377 [10:41<2:18:28,  6.48s/it]\u001b[A\n",
            "  7%|▋         | 96/1377 [10:47<2:13:58,  6.28s/it]\u001b[A\n",
            "  7%|▋         | 97/1377 [10:54<2:17:10,  6.43s/it]\u001b[A\n",
            "  7%|▋         | 98/1377 [10:59<2:10:17,  6.11s/it]\u001b[A\n",
            "  7%|▋         | 99/1377 [11:07<2:22:55,  6.71s/it]\u001b[A\n",
            "  7%|▋         | 100/1377 [11:13<2:14:55,  6.34s/it]\u001b[A\n",
            "  7%|▋         | 101/1377 [11:21<2:25:17,  6.83s/it]\u001b[A\n",
            "  7%|▋         | 102/1377 [11:26<2:15:32,  6.38s/it]\u001b[A\n",
            "  7%|▋         | 103/1377 [11:33<2:22:39,  6.72s/it]\u001b[A\n",
            "  8%|▊         | 104/1377 [11:39<2:18:28,  6.53s/it]\u001b[A\n",
            "  8%|▊         | 105/1377 [11:45<2:13:04,  6.28s/it]\u001b[A\n",
            "  8%|▊         | 106/1377 [11:52<2:16:28,  6.44s/it]\u001b[A\n",
            "  8%|▊         | 107/1377 [12:00<2:23:28,  6.78s/it]\u001b[A\n",
            "  8%|▊         | 108/1377 [12:06<2:18:21,  6.54s/it]\u001b[A\n",
            "  8%|▊         | 109/1377 [12:11<2:12:19,  6.26s/it]\u001b[A\n",
            "  8%|▊         | 110/1377 [12:18<2:18:15,  6.55s/it]\u001b[A\n",
            "  8%|▊         | 111/1377 [12:26<2:22:15,  6.74s/it]\u001b[A\n",
            "  8%|▊         | 112/1377 [12:32<2:22:23,  6.75s/it]\u001b[A\n",
            "  8%|▊         | 113/1377 [12:38<2:15:23,  6.43s/it]\u001b[A\n",
            "  8%|▊         | 114/1377 [12:46<2:23:13,  6.80s/it]\u001b[A\n",
            "  8%|▊         | 115/1377 [12:52<2:21:17,  6.72s/it]\u001b[A\n",
            "  8%|▊         | 116/1377 [12:59<2:21:52,  6.75s/it]\u001b[A\n",
            "  8%|▊         | 117/1377 [13:05<2:17:21,  6.54s/it]\u001b[A\n",
            "  9%|▊         | 118/1377 [13:13<2:26:46,  6.99s/it]\u001b[A\n",
            "  9%|▊         | 119/1377 [13:18<2:15:56,  6.48s/it]\u001b[A\n",
            "  9%|▊         | 120/1377 [13:26<2:24:20,  6.89s/it]\u001b[A\n",
            "  9%|▉         | 121/1377 [13:32<2:16:49,  6.54s/it]\u001b[A\n",
            "  9%|▉         | 122/1377 [13:38<2:13:02,  6.36s/it]\u001b[A\n",
            "  9%|▉         | 123/1377 [13:44<2:13:03,  6.37s/it]\u001b[A\n",
            "  9%|▉         | 124/1377 [13:50<2:10:45,  6.26s/it]\u001b[A\n",
            "  9%|▉         | 125/1377 [13:58<2:19:13,  6.67s/it]\u001b[A\n",
            "  9%|▉         | 126/1377 [14:03<2:11:07,  6.29s/it]\u001b[A\n",
            "  9%|▉         | 127/1377 [14:11<2:19:33,  6.70s/it]\u001b[A\n",
            "  9%|▉         | 128/1377 [14:16<2:11:41,  6.33s/it]\u001b[A\n",
            "  9%|▉         | 129/1377 [14:24<2:17:23,  6.61s/it]\u001b[A\n",
            "  9%|▉         | 130/1377 [14:30<2:17:45,  6.63s/it]\u001b[A\n",
            " 10%|▉         | 131/1377 [14:39<2:27:03,  7.08s/it]\u001b[A\n",
            " 10%|▉         | 132/1377 [14:43<2:12:32,  6.39s/it]\u001b[A\n",
            " 10%|▉         | 133/1377 [14:50<2:14:20,  6.48s/it]\u001b[A\n",
            " 10%|▉         | 134/1377 [14:56<2:08:32,  6.21s/it]\u001b[A\n",
            " 10%|▉         | 135/1377 [15:02<2:07:50,  6.18s/it]\u001b[A\n",
            " 10%|▉         | 136/1377 [15:08<2:07:22,  6.16s/it]\u001b[A\n",
            " 10%|▉         | 137/1377 [15:13<2:03:49,  5.99s/it]\u001b[A\n",
            " 10%|█         | 138/1377 [15:20<2:09:13,  6.26s/it]\u001b[A\n",
            " 10%|█         | 139/1377 [15:26<2:05:15,  6.07s/it]\u001b[A\n",
            " 10%|█         | 140/1377 [15:33<2:13:17,  6.46s/it]\u001b[A\n",
            " 10%|█         | 141/1377 [15:38<2:03:42,  6.01s/it]\u001b[A\n",
            " 10%|█         | 142/1377 [15:43<1:58:14,  5.74s/it]\u001b[A\n",
            " 10%|█         | 143/1377 [15:50<2:05:54,  6.12s/it]\u001b[A\n",
            " 10%|█         | 144/1377 [15:56<2:05:02,  6.08s/it]\u001b[A\n",
            " 11%|█         | 145/1377 [16:04<2:12:03,  6.43s/it]\u001b[A\n",
            " 11%|█         | 146/1377 [16:12<2:22:12,  6.93s/it]\u001b[A\n",
            " 11%|█         | 147/1377 [16:18<2:21:22,  6.90s/it]\u001b[A\n",
            " 11%|█         | 148/1377 [16:23<2:07:42,  6.23s/it]\u001b[A\n",
            " 11%|█         | 149/1377 [16:31<2:16:05,  6.65s/it]\u001b[A\n",
            " 11%|█         | 150/1377 [16:38<2:22:25,  6.96s/it]\u001b[A\n",
            " 11%|█         | 151/1377 [16:46<2:27:07,  7.20s/it]\u001b[A\n",
            " 11%|█         | 152/1377 [16:52<2:21:10,  6.91s/it]\u001b[A\n",
            " 11%|█         | 153/1377 [17:00<2:23:39,  7.04s/it]\u001b[A\n",
            " 11%|█         | 154/1377 [17:06<2:19:00,  6.82s/it]\u001b[A\n",
            " 11%|█▏        | 155/1377 [17:14<2:22:41,  7.01s/it]\u001b[A\n",
            " 11%|█▏        | 156/1377 [17:20<2:19:44,  6.87s/it]\u001b[A\n",
            " 11%|█▏        | 157/1377 [17:27<2:22:44,  7.02s/it]\u001b[A\n",
            " 11%|█▏        | 158/1377 [17:34<2:17:55,  6.79s/it]\u001b[A\n",
            " 12%|█▏        | 159/1377 [17:41<2:22:21,  7.01s/it]\u001b[A\n",
            " 12%|█▏        | 160/1377 [17:47<2:13:29,  6.58s/it]\u001b[A\n",
            " 12%|█▏        | 161/1377 [17:55<2:23:58,  7.10s/it]\u001b[A\n",
            " 12%|█▏        | 162/1377 [18:01<2:14:05,  6.62s/it]\u001b[A\n",
            " 12%|█▏        | 163/1377 [18:08<2:17:15,  6.78s/it]\u001b[A\n",
            " 12%|█▏        | 164/1377 [18:13<2:06:25,  6.25s/it]\u001b[A\n",
            " 12%|█▏        | 165/1377 [18:19<2:05:02,  6.19s/it]\u001b[A\n",
            " 12%|█▏        | 166/1377 [18:26<2:11:12,  6.50s/it]\u001b[A\n",
            " 12%|█▏        | 167/1377 [18:32<2:09:29,  6.42s/it]\u001b[A\n",
            " 12%|█▏        | 168/1377 [18:39<2:11:58,  6.55s/it]\u001b[A\n",
            " 12%|█▏        | 169/1377 [18:46<2:10:34,  6.49s/it]\u001b[A\n",
            " 12%|█▏        | 170/1377 [18:53<2:18:31,  6.89s/it]\u001b[A\n",
            " 12%|█▏        | 171/1377 [19:01<2:22:50,  7.11s/it]\u001b[A\n",
            " 12%|█▏        | 172/1377 [19:08<2:21:36,  7.05s/it]\u001b[A\n",
            " 13%|█▎        | 173/1377 [19:16<2:26:14,  7.29s/it]\u001b[A\n",
            " 13%|█▎        | 174/1377 [19:21<2:16:30,  6.81s/it]\u001b[A\n",
            " 13%|█▎        | 175/1377 [19:28<2:15:16,  6.75s/it]\u001b[A\n",
            " 13%|█▎        | 176/1377 [19:35<2:19:02,  6.95s/it]\u001b[A\n",
            " 13%|█▎        | 177/1377 [19:41<2:08:24,  6.42s/it]\u001b[A\n",
            " 13%|█▎        | 178/1377 [19:49<2:19:15,  6.97s/it]\u001b[A\n",
            " 13%|█▎        | 179/1377 [19:54<2:09:38,  6.49s/it]\u001b[A\n",
            " 13%|█▎        | 180/1377 [20:01<2:13:47,  6.71s/it]\u001b[A\n",
            " 13%|█▎        | 181/1377 [20:07<2:08:16,  6.44s/it]\u001b[A\n",
            " 13%|█▎        | 182/1377 [20:14<2:09:27,  6.50s/it]\u001b[A\n",
            " 13%|█▎        | 183/1377 [20:20<2:06:34,  6.36s/it]\u001b[A\n",
            " 13%|█▎        | 184/1377 [20:28<2:17:22,  6.91s/it]\u001b[A\n",
            " 13%|█▎        | 185/1377 [20:34<2:08:51,  6.49s/it]\u001b[A\n",
            " 14%|█▎        | 186/1377 [20:41<2:11:06,  6.60s/it]\u001b[A\n",
            " 14%|█▎        | 187/1377 [20:48<2:14:45,  6.79s/it]\u001b[A\n",
            " 14%|█▎        | 188/1377 [20:54<2:10:58,  6.61s/it]\u001b[A\n",
            " 14%|█▎        | 189/1377 [21:01<2:12:00,  6.67s/it]\u001b[A\n",
            " 14%|█▍        | 190/1377 [21:08<2:13:55,  6.77s/it]\u001b[A\n",
            " 14%|█▍        | 191/1377 [21:16<2:21:18,  7.15s/it]\u001b[A\n",
            " 14%|█▍        | 192/1377 [21:23<2:20:27,  7.11s/it]\u001b[A\n",
            " 14%|█▍        | 193/1377 [21:31<2:25:29,  7.37s/it]\u001b[A\n",
            " 14%|█▍        | 194/1377 [21:38<2:23:00,  7.25s/it]\u001b[A\n",
            " 14%|█▍        | 195/1377 [21:45<2:20:41,  7.14s/it]\u001b[A\n",
            " 14%|█▍        | 196/1377 [21:51<2:16:46,  6.95s/it]\u001b[A\n",
            " 14%|█▍        | 197/1377 [21:58<2:15:46,  6.90s/it]\u001b[A\n",
            " 14%|█▍        | 198/1377 [22:04<2:11:52,  6.71s/it]\u001b[A\n",
            " 14%|█▍        | 199/1377 [22:11<2:12:00,  6.72s/it]\u001b[A\n",
            " 15%|█▍        | 200/1377 [22:17<2:05:02,  6.37s/it]\u001b[A\n",
            " 15%|█▍        | 201/1377 [22:24<2:11:18,  6.70s/it]\u001b[A\n",
            " 15%|█▍        | 202/1377 [22:30<2:08:21,  6.55s/it]\u001b[A\n",
            " 15%|█▍        | 203/1377 [22:37<2:11:55,  6.74s/it]\u001b[A\n",
            " 15%|█▍        | 204/1377 [22:43<2:04:13,  6.35s/it]\u001b[A\n",
            " 15%|█▍        | 205/1377 [22:50<2:09:29,  6.63s/it]\u001b[A\n",
            " 15%|█▍        | 206/1377 [22:56<2:05:57,  6.45s/it]\u001b[A\n",
            " 15%|█▌        | 207/1377 [23:03<2:07:50,  6.56s/it]\u001b[A\n",
            " 15%|█▌        | 208/1377 [23:09<2:07:26,  6.54s/it]\u001b[A\n",
            " 15%|█▌        | 209/1377 [23:15<2:01:55,  6.26s/it]\u001b[A\n",
            " 15%|█▌        | 210/1377 [23:21<2:01:29,  6.25s/it]\u001b[A\n",
            " 15%|█▌        | 211/1377 [23:26<1:53:27,  5.84s/it]\u001b[A\n",
            " 15%|█▌        | 212/1377 [23:33<1:56:43,  6.01s/it]\u001b[A\n",
            " 15%|█▌        | 213/1377 [23:39<1:58:14,  6.10s/it]\u001b[A\n",
            " 16%|█▌        | 214/1377 [23:46<2:02:17,  6.31s/it]\u001b[A\n",
            " 16%|█▌        | 215/1377 [23:52<2:04:15,  6.42s/it]\u001b[A\n",
            " 16%|█▌        | 216/1377 [23:58<1:58:42,  6.13s/it]\u001b[A\n",
            " 16%|█▌        | 217/1377 [24:05<2:03:50,  6.41s/it]\u001b[A\n",
            " 16%|█▌        | 218/1377 [24:11<2:04:10,  6.43s/it]\u001b[A\n",
            " 16%|█▌        | 219/1377 [24:18<2:08:14,  6.64s/it]\u001b[A\n",
            " 16%|█▌        | 220/1377 [24:24<2:02:59,  6.38s/it]\u001b[A\n",
            " 16%|█▌        | 221/1377 [24:32<2:12:37,  6.88s/it]\u001b[A\n",
            " 16%|█▌        | 222/1377 [24:37<2:01:31,  6.31s/it]\u001b[A\n",
            " 16%|█▌        | 223/1377 [24:45<2:09:31,  6.73s/it]\u001b[A\n",
            " 16%|█▋        | 224/1377 [24:53<2:15:01,  7.03s/it]\u001b[A\n",
            " 16%|█▋        | 225/1377 [25:02<2:28:47,  7.75s/it]\u001b[A\n",
            " 16%|█▋        | 226/1377 [25:09<2:22:31,  7.43s/it]\u001b[A\n",
            " 16%|█▋        | 227/1377 [25:16<2:22:42,  7.45s/it]\u001b[A\n",
            " 17%|█▋        | 228/1377 [25:23<2:16:08,  7.11s/it]\u001b[A\n",
            " 17%|█▋        | 229/1377 [25:29<2:12:29,  6.92s/it]\u001b[A\n",
            " 17%|█▋        | 230/1377 [25:35<2:04:14,  6.50s/it]\u001b[A\n",
            " 17%|█▋        | 231/1377 [25:41<2:03:13,  6.45s/it]\u001b[A\n",
            " 17%|█▋        | 232/1377 [25:46<1:57:25,  6.15s/it]\u001b[A\n",
            " 17%|█▋        | 233/1377 [25:53<1:58:48,  6.23s/it]\u001b[A\n",
            " 17%|█▋        | 234/1377 [25:59<2:00:55,  6.35s/it]\u001b[A\n",
            " 17%|█▋        | 235/1377 [26:07<2:10:04,  6.83s/it]\u001b[A\n",
            " 17%|█▋        | 236/1377 [26:13<2:01:47,  6.40s/it]\u001b[A\n",
            " 17%|█▋        | 237/1377 [26:19<2:02:25,  6.44s/it]\u001b[A\n",
            " 17%|█▋        | 238/1377 [26:26<2:01:50,  6.42s/it]\u001b[A\n",
            " 17%|█▋        | 239/1377 [26:32<1:59:33,  6.30s/it]\u001b[A\n",
            " 17%|█▋        | 240/1377 [26:40<2:07:38,  6.74s/it]\u001b[A\n",
            " 18%|█▊        | 241/1377 [26:46<2:03:28,  6.52s/it]\u001b[A\n",
            " 18%|█▊        | 242/1377 [26:53<2:07:55,  6.76s/it]\u001b[A\n",
            " 18%|█▊        | 243/1377 [26:59<2:05:43,  6.65s/it]\u001b[A\n",
            " 18%|█▊        | 244/1377 [27:06<2:07:50,  6.77s/it]\u001b[A\n",
            " 18%|█▊        | 245/1377 [27:14<2:10:09,  6.90s/it]\u001b[A\n",
            " 18%|█▊        | 246/1377 [27:21<2:10:56,  6.95s/it]\u001b[A\n",
            " 18%|█▊        | 247/1377 [27:27<2:09:19,  6.87s/it]\u001b[A\n",
            " 18%|█▊        | 248/1377 [27:35<2:16:38,  7.26s/it]\u001b[A\n",
            " 18%|█▊        | 249/1377 [27:41<2:07:49,  6.80s/it]\u001b[A\n",
            " 18%|█▊        | 250/1377 [27:49<2:12:18,  7.04s/it]\u001b[A\n",
            " 18%|█▊        | 251/1377 [27:54<2:02:18,  6.52s/it]\u001b[A\n",
            " 18%|█▊        | 252/1377 [28:01<2:05:16,  6.68s/it]\u001b[A\n",
            " 18%|█▊        | 253/1377 [28:07<2:02:39,  6.55s/it]\u001b[A\n",
            " 18%|█▊        | 254/1377 [28:15<2:08:38,  6.87s/it]\u001b[A\n",
            " 19%|█▊        | 255/1377 [28:20<2:00:22,  6.44s/it]\u001b[A\n",
            " 19%|█▊        | 256/1377 [28:28<2:07:16,  6.81s/it]\u001b[A\n",
            " 19%|█▊        | 257/1377 [28:36<2:12:36,  7.10s/it]\u001b[A\n",
            " 19%|█▊        | 258/1377 [28:43<2:14:52,  7.23s/it]\u001b[A\n",
            " 19%|█▉        | 259/1377 [28:49<2:06:26,  6.79s/it]\u001b[A\n",
            " 19%|█▉        | 260/1377 [28:58<2:20:14,  7.53s/it]\u001b[A\n",
            " 19%|█▉        | 261/1377 [29:05<2:13:50,  7.20s/it]\u001b[A\n",
            " 19%|█▉        | 262/1377 [29:11<2:08:15,  6.90s/it]\u001b[A\n",
            " 19%|█▉        | 263/1377 [29:17<2:03:10,  6.63s/it]\u001b[A\n",
            " 19%|█▉        | 264/1377 [29:23<1:56:39,  6.29s/it]\u001b[A\n",
            " 19%|█▉        | 265/1377 [29:32<2:12:27,  7.15s/it]\u001b[A\n",
            " 19%|█▉        | 266/1377 [29:38<2:07:43,  6.90s/it]\u001b[A\n",
            " 19%|█▉        | 267/1377 [29:45<2:05:54,  6.81s/it]\u001b[A\n",
            " 19%|█▉        | 268/1377 [29:51<2:04:43,  6.75s/it]\u001b[A\n",
            " 20%|█▉        | 269/1377 [29:58<2:05:51,  6.82s/it]\u001b[A\n",
            " 20%|█▉        | 270/1377 [30:04<1:57:35,  6.37s/it]\u001b[A\n",
            " 20%|█▉        | 271/1377 [30:10<2:00:44,  6.55s/it]\u001b[A\n",
            " 20%|█▉        | 272/1377 [30:16<1:55:04,  6.25s/it]\u001b[A\n",
            " 20%|█▉        | 273/1377 [30:23<1:57:28,  6.38s/it]\u001b[A\n",
            " 20%|█▉        | 274/1377 [30:28<1:50:47,  6.03s/it]\u001b[A\n",
            " 20%|█▉        | 275/1377 [30:33<1:47:09,  5.83s/it]\u001b[A\n",
            " 20%|██        | 276/1377 [30:40<1:53:56,  6.21s/it]\u001b[A\n",
            " 20%|██        | 277/1377 [30:46<1:51:46,  6.10s/it]\u001b[A\n",
            " 20%|██        | 278/1377 [30:54<1:58:42,  6.48s/it]\u001b[A\n",
            " 20%|██        | 279/1377 [30:59<1:50:06,  6.02s/it]\u001b[A\n",
            " 20%|██        | 280/1377 [31:06<1:59:21,  6.53s/it]\u001b[A\n",
            " 20%|██        | 281/1377 [31:12<1:53:35,  6.22s/it]\u001b[A\n",
            " 20%|██        | 282/1377 [31:19<2:01:10,  6.64s/it]\u001b[A\n",
            " 21%|██        | 283/1377 [31:26<2:00:06,  6.59s/it]\u001b[A\n",
            " 21%|██        | 284/1377 [31:34<2:06:41,  6.95s/it]\u001b[A\n",
            " 21%|██        | 285/1377 [31:40<2:02:57,  6.76s/it]\u001b[A\n",
            " 21%|██        | 286/1377 [31:48<2:10:46,  7.19s/it]\u001b[A\n",
            " 21%|██        | 287/1377 [31:54<2:03:04,  6.77s/it]\u001b[A\n",
            " 21%|██        | 288/1377 [32:02<2:10:50,  7.21s/it]\u001b[A\n",
            " 21%|██        | 289/1377 [32:09<2:05:51,  6.94s/it]\u001b[A\n",
            " 21%|██        | 290/1377 [32:16<2:09:23,  7.14s/it]\u001b[A\n",
            " 21%|██        | 291/1377 [32:22<2:01:14,  6.70s/it]\u001b[A\n",
            " 21%|██        | 292/1377 [32:28<1:57:11,  6.48s/it]\u001b[A\n",
            " 21%|██▏       | 293/1377 [32:34<1:56:53,  6.47s/it]\u001b[A\n",
            " 21%|██▏       | 294/1377 [32:40<1:50:54,  6.14s/it]\u001b[A\n",
            " 21%|██▏       | 295/1377 [32:47<1:56:42,  6.47s/it]\u001b[A\n",
            " 21%|██▏       | 296/1377 [32:52<1:51:27,  6.19s/it]\u001b[A\n",
            " 22%|██▏       | 297/1377 [33:01<2:05:00,  6.94s/it]\u001b[A\n",
            " 22%|██▏       | 298/1377 [33:06<1:55:37,  6.43s/it]\u001b[A\n",
            " 22%|██▏       | 299/1377 [33:12<1:51:54,  6.23s/it]\u001b[A\n",
            " 22%|██▏       | 300/1377 [33:18<1:51:37,  6.22s/it]\u001b[A\n",
            " 22%|██▏       | 301/1377 [33:24<1:47:14,  5.98s/it]\u001b[A\n",
            " 22%|██▏       | 302/1377 [33:31<1:56:21,  6.49s/it]\u001b[A\n",
            " 22%|██▏       | 303/1377 [33:37<1:54:18,  6.39s/it]\u001b[A\n",
            " 22%|██▏       | 304/1377 [33:45<1:58:35,  6.63s/it]\u001b[A\n",
            " 22%|██▏       | 305/1377 [33:51<1:55:25,  6.46s/it]\u001b[A\n",
            " 22%|██▏       | 306/1377 [33:57<1:53:47,  6.37s/it]\u001b[A\n",
            " 22%|██▏       | 307/1377 [34:03<1:51:00,  6.22s/it]\u001b[A\n",
            " 22%|██▏       | 308/1377 [34:09<1:51:12,  6.24s/it]\u001b[A\n",
            " 22%|██▏       | 309/1377 [34:16<1:52:59,  6.35s/it]\u001b[A\n",
            " 23%|██▎       | 310/1377 [34:23<1:55:52,  6.52s/it]\u001b[A\n",
            " 23%|██▎       | 311/1377 [34:29<1:54:09,  6.43s/it]\u001b[A\n",
            " 23%|██▎       | 312/1377 [34:35<1:51:52,  6.30s/it]\u001b[A\n",
            " 23%|██▎       | 313/1377 [34:42<1:57:22,  6.62s/it]\u001b[A\n",
            " 23%|██▎       | 314/1377 [34:49<1:58:50,  6.71s/it]\u001b[A\n",
            " 23%|██▎       | 315/1377 [34:56<2:01:18,  6.85s/it]\u001b[A\n",
            " 23%|██▎       | 316/1377 [35:01<1:51:47,  6.32s/it]\u001b[A\n",
            " 23%|██▎       | 317/1377 [35:09<1:58:22,  6.70s/it]\u001b[A\n",
            " 23%|██▎       | 318/1377 [35:15<1:56:35,  6.61s/it]\u001b[A\n",
            " 23%|██▎       | 319/1377 [35:22<1:58:15,  6.71s/it]\u001b[A\n",
            " 23%|██▎       | 320/1377 [35:29<1:56:09,  6.59s/it]\u001b[A\n",
            " 23%|██▎       | 321/1377 [35:35<1:57:11,  6.66s/it]\u001b[A\n",
            " 23%|██▎       | 322/1377 [35:42<1:55:14,  6.55s/it]\u001b[A\n",
            " 23%|██▎       | 323/1377 [35:49<1:56:40,  6.64s/it]\u001b[A\n",
            " 24%|██▎       | 324/1377 [35:55<1:53:04,  6.44s/it]\u001b[A\n",
            " 24%|██▎       | 325/1377 [36:01<1:54:43,  6.54s/it]\u001b[A\n",
            " 24%|██▎       | 326/1377 [36:08<1:56:19,  6.64s/it]\u001b[A\n",
            " 24%|██▎       | 327/1377 [36:14<1:54:19,  6.53s/it]\u001b[A\n",
            " 24%|██▍       | 328/1377 [36:22<1:56:59,  6.69s/it]\u001b[A\n",
            " 24%|██▍       | 329/1377 [36:27<1:50:32,  6.33s/it]\u001b[A\n",
            " 24%|██▍       | 330/1377 [36:34<1:53:49,  6.52s/it]\u001b[A\n",
            " 24%|██▍       | 331/1377 [36:40<1:51:07,  6.37s/it]\u001b[A\n",
            " 24%|██▍       | 332/1377 [36:48<1:58:41,  6.81s/it]\u001b[A\n",
            " 24%|██▍       | 333/1377 [36:53<1:51:53,  6.43s/it]\u001b[A\n",
            " 24%|██▍       | 334/1377 [37:01<1:57:56,  6.79s/it]\u001b[A\n",
            " 24%|██▍       | 335/1377 [37:06<1:50:31,  6.36s/it]\u001b[A\n",
            " 24%|██▍       | 336/1377 [37:14<1:56:05,  6.69s/it]\u001b[A\n",
            " 24%|██▍       | 337/1377 [37:21<1:59:41,  6.91s/it]\u001b[A\n",
            " 25%|██▍       | 338/1377 [37:29<2:05:58,  7.28s/it]\u001b[A\n",
            " 25%|██▍       | 339/1377 [37:35<1:57:17,  6.78s/it]\u001b[A\n",
            " 25%|██▍       | 340/1377 [37:42<1:58:44,  6.87s/it]\u001b[A\n",
            " 25%|██▍       | 341/1377 [37:48<1:53:14,  6.56s/it]\u001b[A\n",
            " 25%|██▍       | 342/1377 [37:55<1:57:27,  6.81s/it]\u001b[A\n",
            " 25%|██▍       | 343/1377 [38:01<1:51:59,  6.50s/it]\u001b[A\n",
            " 25%|██▍       | 344/1377 [38:07<1:46:29,  6.19s/it]\u001b[A\n",
            " 25%|██▌       | 345/1377 [38:13<1:50:14,  6.41s/it]\u001b[A\n",
            " 25%|██▌       | 346/1377 [38:20<1:48:30,  6.31s/it]\u001b[A\n",
            " 25%|██▌       | 347/1377 [38:27<1:52:04,  6.53s/it]\u001b[A\n",
            " 25%|██▌       | 348/1377 [38:32<1:44:31,  6.09s/it]\u001b[A\n",
            " 25%|██▌       | 349/1377 [38:39<1:51:50,  6.53s/it]\u001b[A\n",
            " 25%|██▌       | 350/1377 [38:45<1:46:25,  6.22s/it]\u001b[A\n",
            " 25%|██▌       | 351/1377 [38:53<1:57:32,  6.87s/it]\u001b[A\n",
            " 26%|██▌       | 352/1377 [38:59<1:50:31,  6.47s/it]\u001b[A\n",
            " 26%|██▌       | 353/1377 [39:06<1:57:16,  6.87s/it]\u001b[A\n",
            " 26%|██▌       | 354/1377 [39:13<1:57:27,  6.89s/it]\u001b[A\n",
            " 26%|██▌       | 355/1377 [39:20<1:55:15,  6.77s/it]\u001b[A\n",
            " 26%|██▌       | 356/1377 [39:25<1:47:56,  6.34s/it]\u001b[A\n",
            " 26%|██▌       | 357/1377 [39:31<1:46:13,  6.25s/it]\u001b[A\n",
            " 26%|██▌       | 358/1377 [39:38<1:51:12,  6.55s/it]\u001b[A\n",
            " 26%|██▌       | 359/1377 [39:44<1:47:42,  6.35s/it]\u001b[A\n",
            " 26%|██▌       | 360/1377 [39:53<1:57:45,  6.95s/it]\u001b[A\n",
            " 26%|██▌       | 361/1377 [39:59<1:55:52,  6.84s/it]\u001b[A\n",
            " 26%|██▋       | 362/1377 [40:06<1:52:43,  6.66s/it]\u001b[A\n",
            " 26%|██▋       | 363/1377 [40:12<1:51:57,  6.62s/it]\u001b[A\n",
            " 26%|██▋       | 364/1377 [40:20<1:59:22,  7.07s/it]\u001b[A\n",
            " 27%|██▋       | 365/1377 [40:26<1:54:15,  6.77s/it]\u001b[A\n",
            " 27%|██▋       | 366/1377 [40:34<1:57:58,  7.00s/it]\u001b[A\n",
            " 27%|██▋       | 367/1377 [40:41<1:56:15,  6.91s/it]\u001b[A\n",
            " 27%|██▋       | 368/1377 [40:47<1:55:25,  6.86s/it]\u001b[A\n",
            " 27%|██▋       | 369/1377 [40:53<1:50:10,  6.56s/it]\u001b[A\n",
            " 27%|██▋       | 370/1377 [41:00<1:53:33,  6.77s/it]\u001b[A\n",
            " 27%|██▋       | 371/1377 [41:07<1:51:28,  6.65s/it]\u001b[A\n",
            " 27%|██▋       | 372/1377 [41:14<1:55:52,  6.92s/it]\u001b[A\n",
            " 27%|██▋       | 373/1377 [41:20<1:48:20,  6.47s/it]\u001b[A\n",
            " 27%|██▋       | 374/1377 [41:29<2:00:08,  7.19s/it]\u001b[A\n",
            " 27%|██▋       | 375/1377 [41:35<1:54:06,  6.83s/it]\u001b[A\n",
            " 27%|██▋       | 376/1377 [41:42<1:58:45,  7.12s/it]\u001b[A\n",
            " 27%|██▋       | 377/1377 [41:48<1:52:58,  6.78s/it]\u001b[A\n",
            " 27%|██▋       | 378/1377 [41:55<1:51:28,  6.70s/it]\u001b[A\n",
            " 28%|██▊       | 379/1377 [42:01<1:46:19,  6.39s/it]\u001b[A\n",
            " 28%|██▊       | 380/1377 [42:06<1:43:10,  6.21s/it]\u001b[A\n",
            " 28%|██▊       | 381/1377 [42:12<1:39:42,  6.01s/it]\u001b[A\n",
            " 28%|██▊       | 382/1377 [42:17<1:37:28,  5.88s/it]\u001b[A\n",
            " 28%|██▊       | 383/1377 [42:25<1:44:33,  6.31s/it]\u001b[A\n",
            " 28%|██▊       | 384/1377 [42:30<1:41:34,  6.14s/it]\u001b[A\n",
            " 28%|██▊       | 385/1377 [42:38<1:48:31,  6.56s/it]\u001b[A\n",
            " 28%|██▊       | 386/1377 [42:44<1:44:29,  6.33s/it]\u001b[A\n",
            " 28%|██▊       | 387/1377 [42:50<1:44:30,  6.33s/it]\u001b[A\n",
            " 28%|██▊       | 388/1377 [42:56<1:44:06,  6.32s/it]\u001b[A\n",
            " 28%|██▊       | 389/1377 [43:03<1:44:19,  6.34s/it]\u001b[A\n",
            " 28%|██▊       | 390/1377 [43:09<1:44:16,  6.34s/it]\u001b[A\n",
            " 28%|██▊       | 391/1377 [43:14<1:38:35,  6.00s/it]\u001b[A\n",
            " 28%|██▊       | 392/1377 [43:22<1:44:47,  6.38s/it]\u001b[A\n",
            " 29%|██▊       | 393/1377 [43:28<1:43:06,  6.29s/it]\u001b[A\n",
            " 29%|██▊       | 394/1377 [43:35<1:47:31,  6.56s/it]\u001b[A\n",
            " 29%|██▊       | 395/1377 [43:41<1:45:19,  6.44s/it]\u001b[A\n",
            " 29%|██▉       | 396/1377 [43:49<1:52:21,  6.87s/it]\u001b[A\n",
            " 29%|██▉       | 397/1377 [43:55<1:46:58,  6.55s/it]\u001b[A\n",
            " 29%|██▉       | 398/1377 [44:02<1:49:08,  6.69s/it]\u001b[A\n",
            " 29%|██▉       | 399/1377 [44:08<1:44:28,  6.41s/it]\u001b[A\n",
            " 29%|██▉       | 400/1377 [44:15<1:48:10,  6.64s/it]\u001b[A\n",
            " 29%|██▉       | 401/1377 [44:21<1:46:12,  6.53s/it]\u001b[A\n",
            " 29%|██▉       | 402/1377 [44:29<1:54:15,  7.03s/it]\u001b[A\n",
            " 29%|██▉       | 403/1377 [44:35<1:49:38,  6.75s/it]\u001b[A\n",
            " 29%|██▉       | 404/1377 [44:42<1:51:33,  6.88s/it]\u001b[A\n",
            " 29%|██▉       | 405/1377 [44:48<1:47:13,  6.62s/it]\u001b[A\n",
            " 29%|██▉       | 406/1377 [44:54<1:43:59,  6.43s/it]\u001b[A\n",
            " 30%|██▉       | 407/1377 [45:02<1:48:19,  6.70s/it]\u001b[A\n",
            " 30%|██▉       | 408/1377 [45:07<1:42:04,  6.32s/it]\u001b[A\n",
            " 30%|██▉       | 409/1377 [45:15<1:47:21,  6.65s/it]\u001b[A\n",
            " 30%|██▉       | 410/1377 [45:20<1:43:01,  6.39s/it]\u001b[A\n",
            " 30%|██▉       | 411/1377 [45:29<1:53:18,  7.04s/it]\u001b[A\n",
            " 30%|██▉       | 412/1377 [45:35<1:46:40,  6.63s/it]\u001b[A\n",
            " 30%|██▉       | 413/1377 [45:44<2:00:39,  7.51s/it]\u001b[A\n",
            " 30%|███       | 414/1377 [45:49<1:48:55,  6.79s/it]\u001b[A\n",
            " 30%|███       | 415/1377 [45:56<1:46:13,  6.63s/it]\u001b[A\n",
            " 30%|███       | 416/1377 [46:01<1:41:20,  6.33s/it]\u001b[A\n",
            " 30%|███       | 417/1377 [46:06<1:34:30,  5.91s/it]\u001b[A\n",
            " 30%|███       | 418/1377 [46:13<1:39:26,  6.22s/it]\u001b[A\n",
            " 30%|███       | 419/1377 [46:19<1:39:30,  6.23s/it]\u001b[A\n",
            " 31%|███       | 420/1377 [46:26<1:41:34,  6.37s/it]\u001b[A\n",
            " 31%|███       | 421/1377 [46:32<1:41:16,  6.36s/it]\u001b[A\n",
            " 31%|███       | 422/1377 [46:40<1:48:11,  6.80s/it]\u001b[A\n",
            " 31%|███       | 423/1377 [46:46<1:44:37,  6.58s/it]\u001b[A\n",
            " 31%|███       | 424/1377 [46:54<1:47:58,  6.80s/it]\u001b[A\n",
            " 31%|███       | 425/1377 [46:59<1:42:08,  6.44s/it]\u001b[A\n",
            " 31%|███       | 426/1377 [47:06<1:45:26,  6.65s/it]\u001b[A\n",
            " 31%|███       | 427/1377 [47:12<1:42:38,  6.48s/it]\u001b[A\n",
            " 31%|███       | 428/1377 [47:18<1:35:55,  6.06s/it]\u001b[A\n",
            " 31%|███       | 429/1377 [47:24<1:40:09,  6.34s/it]\u001b[A\n",
            " 31%|███       | 430/1377 [47:30<1:38:33,  6.24s/it]\u001b[A\n",
            " 31%|███▏      | 431/1377 [47:38<1:43:08,  6.54s/it]\u001b[A\n",
            " 31%|███▏      | 432/1377 [47:44<1:40:39,  6.39s/it]\u001b[A\n",
            " 31%|███▏      | 433/1377 [47:51<1:43:19,  6.57s/it]\u001b[A\n",
            " 32%|███▏      | 434/1377 [47:57<1:41:16,  6.44s/it]\u001b[A\n",
            " 32%|███▏      | 435/1377 [48:04<1:44:54,  6.68s/it]\u001b[A\n",
            " 32%|███▏      | 436/1377 [48:10<1:39:05,  6.32s/it]\u001b[A\n",
            " 32%|███▏      | 437/1377 [48:16<1:38:51,  6.31s/it]\u001b[A\n",
            " 32%|███▏      | 438/1377 [48:22<1:39:28,  6.36s/it]\u001b[A\n",
            " 32%|███▏      | 439/1377 [48:28<1:37:28,  6.24s/it]\u001b[A\n",
            " 32%|███▏      | 440/1377 [48:35<1:38:53,  6.33s/it]\u001b[A\n",
            " 32%|███▏      | 441/1377 [48:41<1:37:45,  6.27s/it]\u001b[A\n",
            " 32%|███▏      | 442/1377 [48:48<1:40:57,  6.48s/it]\u001b[A\n",
            " 32%|███▏      | 443/1377 [48:53<1:33:28,  6.01s/it]\u001b[A\n",
            " 32%|███▏      | 444/1377 [49:00<1:38:50,  6.36s/it]\u001b[A\n",
            " 32%|███▏      | 445/1377 [49:06<1:34:39,  6.09s/it]\u001b[A\n",
            " 32%|███▏      | 446/1377 [49:12<1:36:21,  6.21s/it]\u001b[A\n",
            " 32%|███▏      | 447/1377 [49:17<1:32:39,  5.98s/it]\u001b[A\n",
            " 33%|███▎      | 448/1377 [49:25<1:40:40,  6.50s/it]\u001b[A\n",
            " 33%|███▎      | 449/1377 [49:32<1:40:44,  6.51s/it]\u001b[A\n",
            " 33%|███▎      | 450/1377 [49:37<1:37:00,  6.28s/it]\u001b[A\n",
            " 33%|███▎      | 451/1377 [49:44<1:37:05,  6.29s/it]\u001b[A\n",
            " 33%|███▎      | 452/1377 [49:49<1:33:25,  6.06s/it]\u001b[A\n",
            " 33%|███▎      | 453/1377 [49:57<1:40:33,  6.53s/it]\u001b[A\n",
            " 33%|███▎      | 454/1377 [50:03<1:38:50,  6.43s/it]\u001b[A\n",
            " 33%|███▎      | 455/1377 [50:11<1:45:29,  6.87s/it]\u001b[A\n",
            " 33%|███▎      | 456/1377 [50:17<1:43:35,  6.75s/it]\u001b[A\n",
            " 33%|███▎      | 457/1377 [50:25<1:46:44,  6.96s/it]\u001b[A\n",
            " 33%|███▎      | 458/1377 [50:31<1:40:53,  6.59s/it]\u001b[A\n",
            " 33%|███▎      | 459/1377 [50:35<1:28:33,  5.79s/it]\u001b[A\n",
            " 33%|███▎      | 460/1377 [50:42<1:33:50,  6.14s/it]\u001b[A\n",
            " 33%|███▎      | 461/1377 [50:47<1:29:54,  5.89s/it]\u001b[A\n",
            " 34%|███▎      | 462/1377 [50:54<1:35:34,  6.27s/it]\u001b[A\n",
            " 34%|███▎      | 463/1377 [51:00<1:35:30,  6.27s/it]\u001b[A\n",
            " 34%|███▎      | 464/1377 [51:08<1:42:03,  6.71s/it]\u001b[A\n",
            " 34%|███▍      | 465/1377 [51:13<1:34:50,  6.24s/it]\u001b[A\n",
            " 34%|███▍      | 466/1377 [51:20<1:39:33,  6.56s/it]\u001b[A\n",
            " 34%|███▍      | 467/1377 [51:26<1:36:59,  6.39s/it]\u001b[A\n",
            " 34%|███▍      | 468/1377 [51:34<1:42:40,  6.78s/it]\u001b[A\n",
            " 34%|███▍      | 469/1377 [51:39<1:35:37,  6.32s/it]\u001b[A\n",
            " 34%|███▍      | 470/1377 [51:46<1:36:54,  6.41s/it]\u001b[A\n",
            " 34%|███▍      | 471/1377 [51:52<1:36:58,  6.42s/it]\u001b[A\n",
            " 34%|███▍      | 472/1377 [51:59<1:39:47,  6.62s/it]\u001b[A\n",
            " 34%|███▍      | 473/1377 [52:05<1:36:20,  6.39s/it]\u001b[A\n",
            " 34%|███▍      | 474/1377 [52:11<1:32:49,  6.17s/it]\u001b[A\n",
            " 34%|███▍      | 475/1377 [52:18<1:36:15,  6.40s/it]\u001b[A\n",
            " 35%|███▍      | 476/1377 [52:24<1:34:40,  6.30s/it]\u001b[A\n",
            " 35%|███▍      | 477/1377 [52:32<1:40:15,  6.68s/it]\u001b[A\n",
            " 35%|███▍      | 478/1377 [52:38<1:40:02,  6.68s/it]\u001b[A\n",
            " 35%|███▍      | 479/1377 [52:46<1:44:26,  6.98s/it]\u001b[A\n",
            " 35%|███▍      | 480/1377 [52:51<1:35:18,  6.37s/it]\u001b[A\n",
            " 35%|███▍      | 481/1377 [52:59<1:41:41,  6.81s/it]\u001b[A\n",
            " 35%|███▌      | 482/1377 [53:05<1:37:00,  6.50s/it]\u001b[A\n",
            " 35%|███▌      | 483/1377 [53:14<1:48:43,  7.30s/it]\u001b[A\n",
            " 35%|███▌      | 484/1377 [53:21<1:47:04,  7.19s/it]\u001b[A\n",
            " 35%|███▌      | 485/1377 [53:28<1:49:03,  7.34s/it]\u001b[A\n",
            " 35%|███▌      | 486/1377 [53:34<1:41:26,  6.83s/it]\u001b[A\n",
            " 35%|███▌      | 487/1377 [53:42<1:44:41,  7.06s/it]\u001b[A\n",
            " 35%|███▌      | 488/1377 [53:48<1:40:04,  6.75s/it]\u001b[A\n",
            " 36%|███▌      | 489/1377 [53:55<1:42:09,  6.90s/it]\u001b[A\n",
            " 36%|███▌      | 490/1377 [54:00<1:35:59,  6.49s/it]\u001b[A\n",
            " 36%|███▌      | 491/1377 [54:08<1:42:24,  6.93s/it]\u001b[A\n",
            " 36%|███▌      | 492/1377 [54:14<1:34:51,  6.43s/it]\u001b[A\n",
            " 36%|███▌      | 493/1377 [54:20<1:35:49,  6.50s/it]\u001b[A\n",
            " 36%|███▌      | 494/1377 [54:26<1:33:19,  6.34s/it]\u001b[A\n",
            " 36%|███▌      | 495/1377 [54:34<1:38:35,  6.71s/it]\u001b[A\n",
            " 36%|███▌      | 496/1377 [54:41<1:39:51,  6.80s/it]\u001b[A\n",
            " 36%|███▌      | 497/1377 [54:47<1:35:12,  6.49s/it]\u001b[A\n",
            " 36%|███▌      | 498/1377 [54:53<1:35:07,  6.49s/it]\u001b[A\n",
            " 36%|███▌      | 499/1377 [54:58<1:28:21,  6.04s/it]\u001b[A\n",
            " 36%|███▋      | 500/1377 [55:06<1:36:06,  6.58s/it]\u001b[A\n",
            " 36%|███▋      | 501/1377 [55:11<1:29:48,  6.15s/it]\u001b[A\n",
            " 36%|███▋      | 502/1377 [55:19<1:37:19,  6.67s/it]\u001b[A\n",
            " 37%|███▋      | 503/1377 [55:25<1:34:15,  6.47s/it]\u001b[A\n",
            " 37%|███▋      | 504/1377 [55:32<1:37:41,  6.71s/it]\u001b[A\n",
            " 37%|███▋      | 505/1377 [55:38<1:31:31,  6.30s/it]\u001b[A\n",
            " 37%|███▋      | 506/1377 [55:43<1:27:13,  6.01s/it]\u001b[A\n",
            " 37%|███▋      | 507/1377 [55:51<1:35:59,  6.62s/it]\u001b[A\n",
            " 37%|███▋      | 508/1377 [55:58<1:35:55,  6.62s/it]\u001b[A\n",
            " 37%|███▋      | 509/1377 [56:05<1:39:01,  6.85s/it]\u001b[A\n",
            " 37%|███▋      | 510/1377 [56:10<1:31:37,  6.34s/it]\u001b[A\n",
            " 37%|███▋      | 511/1377 [56:17<1:35:39,  6.63s/it]\u001b[A\n",
            " 37%|███▋      | 512/1377 [56:24<1:34:27,  6.55s/it]\u001b[A\n",
            " 37%|███▋      | 513/1377 [56:31<1:37:07,  6.74s/it]\u001b[A\n",
            " 37%|███▋      | 514/1377 [56:37<1:35:23,  6.63s/it]\u001b[A\n",
            " 37%|███▋      | 515/1377 [56:44<1:36:08,  6.69s/it]\u001b[A\n",
            " 37%|███▋      | 516/1377 [56:51<1:37:58,  6.83s/it]\u001b[A\n",
            " 38%|███▊      | 517/1377 [56:58<1:38:54,  6.90s/it]\u001b[A\n",
            " 38%|███▊      | 518/1377 [57:05<1:39:28,  6.95s/it]\u001b[A\n",
            " 38%|███▊      | 519/1377 [57:13<1:42:25,  7.16s/it]\u001b[A\n",
            " 38%|███▊      | 520/1377 [57:18<1:33:41,  6.56s/it]\u001b[A\n",
            " 38%|███▊      | 521/1377 [57:26<1:38:24,  6.90s/it]\u001b[A\n",
            " 38%|███▊      | 522/1377 [57:31<1:32:11,  6.47s/it]\u001b[A\n",
            " 38%|███▊      | 523/1377 [57:39<1:38:42,  6.94s/it]\u001b[A\n",
            " 38%|███▊      | 524/1377 [57:45<1:33:54,  6.61s/it]\u001b[A\n",
            " 38%|███▊      | 525/1377 [57:52<1:32:25,  6.51s/it]\u001b[A\n",
            " 38%|███▊      | 526/1377 [57:59<1:34:31,  6.66s/it]\u001b[A\n",
            " 38%|███▊      | 527/1377 [58:04<1:29:55,  6.35s/it]\u001b[A\n",
            " 38%|███▊      | 528/1377 [58:11<1:33:47,  6.63s/it]\u001b[A\n",
            " 38%|███▊      | 529/1377 [58:17<1:29:50,  6.36s/it]\u001b[A\n",
            " 38%|███▊      | 530/1377 [58:25<1:36:04,  6.81s/it]\u001b[A\n",
            " 39%|███▊      | 531/1377 [58:32<1:34:51,  6.73s/it]\u001b[A\n",
            " 39%|███▊      | 532/1377 [58:38<1:35:31,  6.78s/it]\u001b[A\n",
            " 39%|███▊      | 533/1377 [58:44<1:30:42,  6.45s/it]\u001b[A\n",
            " 39%|███▉      | 534/1377 [58:51<1:33:49,  6.68s/it]\u001b[A\n",
            " 39%|███▉      | 535/1377 [58:58<1:33:19,  6.65s/it]\u001b[A\n",
            " 39%|███▉      | 536/1377 [59:05<1:34:16,  6.73s/it]\u001b[A\n",
            " 39%|███▉      | 537/1377 [59:11<1:32:43,  6.62s/it]\u001b[A\n",
            " 39%|███▉      | 538/1377 [59:18<1:33:20,  6.68s/it]\u001b[A\n",
            " 39%|███▉      | 539/1377 [59:23<1:28:07,  6.31s/it]\u001b[A\n",
            " 39%|███▉      | 540/1377 [59:30<1:28:14,  6.33s/it]\u001b[A\n",
            " 39%|███▉      | 541/1377 [59:36<1:27:29,  6.28s/it]\u001b[A\n",
            " 39%|███▉      | 542/1377 [59:42<1:26:22,  6.21s/it]\u001b[A\n",
            " 39%|███▉      | 543/1377 [59:50<1:31:59,  6.62s/it]\u001b[A\n",
            " 40%|███▉      | 544/1377 [59:58<1:39:48,  7.19s/it]\u001b[A\n",
            " 40%|███▉      | 545/1377 [1:00:05<1:37:02,  7.00s/it]\u001b[A\n",
            " 40%|███▉      | 546/1377 [1:00:11<1:33:55,  6.78s/it]\u001b[A\n",
            " 40%|███▉      | 547/1377 [1:00:18<1:35:42,  6.92s/it]\u001b[A\n",
            " 40%|███▉      | 548/1377 [1:00:24<1:29:36,  6.49s/it]\u001b[A\n",
            " 40%|███▉      | 549/1377 [1:00:31<1:32:19,  6.69s/it]\u001b[A\n",
            " 40%|███▉      | 550/1377 [1:00:37<1:29:52,  6.52s/it]\u001b[A\n",
            " 40%|████      | 551/1377 [1:00:45<1:34:33,  6.87s/it]\u001b[A\n",
            " 40%|████      | 552/1377 [1:00:50<1:27:30,  6.36s/it]\u001b[A\n",
            " 40%|████      | 553/1377 [1:01:00<1:43:39,  7.55s/it]\u001b[A\n",
            " 40%|████      | 554/1377 [1:01:05<1:31:57,  6.70s/it]\u001b[A\n",
            " 40%|████      | 555/1377 [1:01:13<1:36:02,  7.01s/it]\u001b[A\n",
            " 40%|████      | 556/1377 [1:01:19<1:32:05,  6.73s/it]\u001b[A\n",
            " 40%|████      | 557/1377 [1:01:25<1:28:51,  6.50s/it]\u001b[A\n",
            " 41%|████      | 558/1377 [1:01:31<1:29:11,  6.53s/it]\u001b[A\n",
            " 41%|████      | 559/1377 [1:01:37<1:24:23,  6.19s/it]\u001b[A\n",
            " 41%|████      | 560/1377 [1:01:44<1:30:27,  6.64s/it]\u001b[A\n",
            " 41%|████      | 561/1377 [1:01:50<1:25:04,  6.26s/it]\u001b[A\n",
            " 41%|████      | 562/1377 [1:01:57<1:30:09,  6.64s/it]\u001b[A\n",
            " 41%|████      | 563/1377 [1:02:03<1:24:43,  6.24s/it]\u001b[A\n",
            " 41%|████      | 564/1377 [1:02:11<1:32:16,  6.81s/it]\u001b[A\n",
            " 41%|████      | 565/1377 [1:02:17<1:29:33,  6.62s/it]\u001b[A\n",
            " 41%|████      | 566/1377 [1:02:25<1:33:42,  6.93s/it]\u001b[A\n",
            " 41%|████      | 567/1377 [1:02:30<1:27:18,  6.47s/it]\u001b[A\n",
            " 41%|████      | 568/1377 [1:02:35<1:23:09,  6.17s/it]\u001b[A\n",
            " 41%|████▏     | 569/1377 [1:02:44<1:31:02,  6.76s/it]\u001b[A\n",
            " 41%|████▏     | 570/1377 [1:02:50<1:27:52,  6.53s/it]\u001b[A\n",
            " 41%|████▏     | 571/1377 [1:02:57<1:32:58,  6.92s/it]\u001b[A\n",
            " 42%|████▏     | 572/1377 [1:03:04<1:31:37,  6.83s/it]\u001b[A\n",
            " 42%|████▏     | 573/1377 [1:03:10<1:29:47,  6.70s/it]\u001b[A\n",
            " 42%|████▏     | 574/1377 [1:03:16<1:23:37,  6.25s/it]\u001b[A\n",
            " 42%|████▏     | 575/1377 [1:03:23<1:28:14,  6.60s/it]\u001b[A\n",
            " 42%|████▏     | 576/1377 [1:03:28<1:22:01,  6.14s/it]\u001b[A\n",
            " 42%|████▏     | 577/1377 [1:03:35<1:26:16,  6.47s/it]\u001b[A\n",
            " 42%|████▏     | 578/1377 [1:03:41<1:24:38,  6.36s/it]\u001b[A\n",
            " 42%|████▏     | 579/1377 [1:03:49<1:29:03,  6.70s/it]\u001b[A\n",
            " 42%|████▏     | 580/1377 [1:03:55<1:26:58,  6.55s/it]\u001b[A\n",
            " 42%|████▏     | 581/1377 [1:04:03<1:31:51,  6.92s/it]\u001b[A\n",
            " 42%|████▏     | 582/1377 [1:04:08<1:24:48,  6.40s/it]\u001b[A\n",
            " 42%|████▏     | 583/1377 [1:04:14<1:24:38,  6.40s/it]\u001b[A\n",
            " 42%|████▏     | 584/1377 [1:04:22<1:29:33,  6.78s/it]\u001b[A\n",
            " 42%|████▏     | 585/1377 [1:04:29<1:29:02,  6.75s/it]\u001b[A\n",
            " 43%|████▎     | 586/1377 [1:04:35<1:26:02,  6.53s/it]\u001b[A\n",
            " 43%|████▎     | 587/1377 [1:04:42<1:27:44,  6.66s/it]\u001b[A\n",
            " 43%|████▎     | 588/1377 [1:04:50<1:33:45,  7.13s/it]\u001b[A\n",
            " 43%|████▎     | 589/1377 [1:04:55<1:26:25,  6.58s/it]\u001b[A\n",
            " 43%|████▎     | 590/1377 [1:05:03<1:31:04,  6.94s/it]\u001b[A\n",
            " 43%|████▎     | 591/1377 [1:05:10<1:30:38,  6.92s/it]\u001b[A\n",
            " 43%|████▎     | 592/1377 [1:05:18<1:33:34,  7.15s/it]\u001b[A\n",
            " 43%|████▎     | 593/1377 [1:05:23<1:27:30,  6.70s/it]\u001b[A\n",
            " 43%|████▎     | 594/1377 [1:05:30<1:28:25,  6.78s/it]\u001b[A\n",
            " 43%|████▎     | 595/1377 [1:05:36<1:25:12,  6.54s/it]\u001b[A\n",
            " 43%|████▎     | 596/1377 [1:05:43<1:27:18,  6.71s/it]\u001b[A\n",
            " 43%|████▎     | 597/1377 [1:05:50<1:25:25,  6.57s/it]\u001b[A\n",
            " 43%|████▎     | 598/1377 [1:05:58<1:31:45,  7.07s/it]\u001b[A\n",
            " 44%|████▎     | 599/1377 [1:06:03<1:23:05,  6.41s/it]\u001b[A\n",
            " 44%|████▎     | 600/1377 [1:06:08<1:19:35,  6.15s/it]\u001b[A\n",
            " 44%|████▎     | 601/1377 [1:06:15<1:21:18,  6.29s/it]\u001b[A\n",
            " 44%|████▎     | 602/1377 [1:06:21<1:20:26,  6.23s/it]\u001b[A\n",
            " 44%|████▍     | 603/1377 [1:06:29<1:25:34,  6.63s/it]\u001b[A\n",
            " 44%|████▍     | 604/1377 [1:06:34<1:21:30,  6.33s/it]\u001b[A\n",
            " 44%|████▍     | 605/1377 [1:06:41<1:24:18,  6.55s/it]\u001b[A\n",
            " 44%|████▍     | 606/1377 [1:06:47<1:20:08,  6.24s/it]\u001b[A\n",
            " 44%|████▍     | 607/1377 [1:06:54<1:23:35,  6.51s/it]\u001b[A\n",
            " 44%|████▍     | 608/1377 [1:07:00<1:22:31,  6.44s/it]\u001b[A\n",
            " 44%|████▍     | 609/1377 [1:07:07<1:23:23,  6.52s/it]\u001b[A\n",
            " 44%|████▍     | 610/1377 [1:07:13<1:20:13,  6.28s/it]\u001b[A\n",
            " 44%|████▍     | 611/1377 [1:07:18<1:18:37,  6.16s/it]\u001b[A\n",
            " 44%|████▍     | 612/1377 [1:07:26<1:23:41,  6.56s/it]\u001b[A\n",
            " 45%|████▍     | 613/1377 [1:07:32<1:21:23,  6.39s/it]\u001b[A\n",
            " 45%|████▍     | 614/1377 [1:07:40<1:27:40,  6.89s/it]\u001b[A\n",
            " 45%|████▍     | 615/1377 [1:07:46<1:23:24,  6.57s/it]\u001b[A\n",
            " 45%|████▍     | 616/1377 [1:07:53<1:27:06,  6.87s/it]\u001b[A\n",
            " 45%|████▍     | 617/1377 [1:07:59<1:21:16,  6.42s/it]\u001b[A\n",
            " 45%|████▍     | 618/1377 [1:08:06<1:23:10,  6.57s/it]\u001b[A\n",
            " 45%|████▍     | 619/1377 [1:08:11<1:19:19,  6.28s/it]\u001b[A\n",
            " 45%|████▌     | 620/1377 [1:08:18<1:20:19,  6.37s/it]\u001b[A\n",
            " 45%|████▌     | 621/1377 [1:08:25<1:22:05,  6.52s/it]\u001b[A\n",
            " 45%|████▌     | 622/1377 [1:08:32<1:23:25,  6.63s/it]\u001b[A\n",
            " 45%|████▌     | 623/1377 [1:08:38<1:23:38,  6.66s/it]\u001b[A\n",
            " 45%|████▌     | 624/1377 [1:08:47<1:30:36,  7.22s/it]\u001b[A\n",
            " 45%|████▌     | 625/1377 [1:08:52<1:23:54,  6.69s/it]\u001b[A\n",
            " 45%|████▌     | 626/1377 [1:08:59<1:24:04,  6.72s/it]\u001b[A\n",
            " 46%|████▌     | 627/1377 [1:09:05<1:20:33,  6.45s/it]\u001b[A\n",
            " 46%|████▌     | 628/1377 [1:09:11<1:19:34,  6.37s/it]\u001b[A\n",
            " 46%|████▌     | 629/1377 [1:09:18<1:22:20,  6.61s/it]\u001b[A\n",
            " 46%|████▌     | 630/1377 [1:09:24<1:20:00,  6.43s/it]\u001b[A\n",
            " 46%|████▌     | 631/1377 [1:09:32<1:24:00,  6.76s/it]\u001b[A\n",
            " 46%|████▌     | 632/1377 [1:09:37<1:17:40,  6.26s/it]\u001b[A\n",
            " 46%|████▌     | 633/1377 [1:09:44<1:21:28,  6.57s/it]\u001b[A\n",
            " 46%|████▌     | 634/1377 [1:09:49<1:15:50,  6.12s/it]\u001b[A\n",
            " 46%|████▌     | 635/1377 [1:09:56<1:17:00,  6.23s/it]\u001b[A\n",
            " 46%|████▌     | 636/1377 [1:10:02<1:16:16,  6.18s/it]\u001b[A\n",
            " 46%|████▋     | 637/1377 [1:10:07<1:13:20,  5.95s/it]\u001b[A\n",
            " 46%|████▋     | 638/1377 [1:10:14<1:18:08,  6.34s/it]\u001b[A\n",
            " 46%|████▋     | 639/1377 [1:10:20<1:15:32,  6.14s/it]\u001b[A\n",
            " 46%|████▋     | 640/1377 [1:10:28<1:21:54,  6.67s/it]\u001b[A\n",
            " 47%|████▋     | 641/1377 [1:10:34<1:20:47,  6.59s/it]\u001b[A\n",
            " 47%|████▋     | 642/1377 [1:10:43<1:27:25,  7.14s/it]\u001b[A\n",
            " 47%|████▋     | 643/1377 [1:10:49<1:23:15,  6.81s/it]\u001b[A\n",
            " 47%|████▋     | 644/1377 [1:10:57<1:27:40,  7.18s/it]\u001b[A\n",
            " 47%|████▋     | 645/1377 [1:11:03<1:23:17,  6.83s/it]\u001b[A\n",
            " 47%|████▋     | 646/1377 [1:11:10<1:24:24,  6.93s/it]\u001b[A\n",
            " 47%|████▋     | 647/1377 [1:11:15<1:18:23,  6.44s/it]\u001b[A\n",
            " 47%|████▋     | 648/1377 [1:11:23<1:23:29,  6.87s/it]\u001b[A\n",
            " 47%|████▋     | 649/1377 [1:11:29<1:17:36,  6.40s/it]\u001b[A\n",
            " 47%|████▋     | 650/1377 [1:11:35<1:18:32,  6.48s/it]\u001b[A\n",
            " 47%|████▋     | 651/1377 [1:11:41<1:14:04,  6.12s/it]\u001b[A\n",
            " 47%|████▋     | 652/1377 [1:11:47<1:16:37,  6.34s/it]\u001b[A\n",
            " 47%|████▋     | 653/1377 [1:11:54<1:16:39,  6.35s/it]\u001b[A\n",
            " 47%|████▋     | 654/1377 [1:11:59<1:14:08,  6.15s/it]\u001b[A\n",
            " 48%|████▊     | 655/1377 [1:12:06<1:16:59,  6.40s/it]\u001b[A\n",
            " 48%|████▊     | 656/1377 [1:12:12<1:15:37,  6.29s/it]\u001b[A\n",
            " 48%|████▊     | 657/1377 [1:12:21<1:22:34,  6.88s/it]\u001b[A\n",
            " 48%|████▊     | 658/1377 [1:12:28<1:23:53,  7.00s/it]\u001b[A\n",
            " 48%|████▊     | 659/1377 [1:12:35<1:23:49,  7.00s/it]\u001b[A\n",
            " 48%|████▊     | 660/1377 [1:12:41<1:20:40,  6.75s/it]\u001b[A\n",
            " 48%|████▊     | 661/1377 [1:12:48<1:19:24,  6.65s/it]\u001b[A\n",
            " 48%|████▊     | 662/1377 [1:12:53<1:15:46,  6.36s/it]\u001b[A\n",
            " 48%|████▊     | 663/1377 [1:13:01<1:20:25,  6.76s/it]\u001b[A\n",
            " 48%|████▊     | 664/1377 [1:13:07<1:16:27,  6.43s/it]\u001b[A\n",
            " 48%|████▊     | 665/1377 [1:13:13<1:16:53,  6.48s/it]\u001b[A\n",
            " 48%|████▊     | 666/1377 [1:13:20<1:16:24,  6.45s/it]\u001b[A\n",
            " 48%|████▊     | 667/1377 [1:13:27<1:20:33,  6.81s/it]\u001b[A\n",
            " 49%|████▊     | 668/1377 [1:13:33<1:16:32,  6.48s/it]\u001b[A\n",
            " 49%|████▊     | 669/1377 [1:13:42<1:26:12,  7.31s/it]\u001b[A\n",
            " 49%|████▊     | 670/1377 [1:13:49<1:23:13,  7.06s/it]\u001b[A\n",
            " 49%|████▊     | 671/1377 [1:13:55<1:21:41,  6.94s/it]\u001b[A\n",
            " 49%|████▉     | 672/1377 [1:14:02<1:20:38,  6.86s/it]\u001b[A\n",
            " 49%|████▉     | 673/1377 [1:14:12<1:29:59,  7.67s/it]\u001b[A\n",
            " 49%|████▉     | 674/1377 [1:14:17<1:20:55,  6.91s/it]\u001b[A\n",
            " 49%|████▉     | 675/1377 [1:14:24<1:22:01,  7.01s/it]\u001b[A\n",
            " 49%|████▉     | 676/1377 [1:14:29<1:16:06,  6.51s/it]\u001b[A\n",
            " 49%|████▉     | 677/1377 [1:14:35<1:14:29,  6.38s/it]\u001b[A\n",
            " 49%|████▉     | 678/1377 [1:14:43<1:19:38,  6.84s/it]\u001b[A\n",
            " 49%|████▉     | 679/1377 [1:14:50<1:17:24,  6.65s/it]\u001b[A\n",
            " 49%|████▉     | 680/1377 [1:14:56<1:17:34,  6.68s/it]\u001b[A\n",
            " 49%|████▉     | 681/1377 [1:15:02<1:13:47,  6.36s/it]\u001b[A\n",
            " 50%|████▉     | 682/1377 [1:15:08<1:14:04,  6.39s/it]\u001b[A\n",
            " 50%|████▉     | 683/1377 [1:15:14<1:11:06,  6.15s/it]\u001b[A\n",
            " 50%|████▉     | 684/1377 [1:15:21<1:15:03,  6.50s/it]\u001b[A\n",
            " 50%|████▉     | 685/1377 [1:15:27<1:10:41,  6.13s/it]\u001b[A\n",
            " 50%|████▉     | 686/1377 [1:15:34<1:16:13,  6.62s/it]\u001b[A\n",
            " 50%|████▉     | 687/1377 [1:15:40<1:12:53,  6.34s/it]\u001b[A\n",
            " 50%|████▉     | 688/1377 [1:15:46<1:13:12,  6.38s/it]\u001b[A\n",
            " 50%|█████     | 689/1377 [1:15:53<1:14:10,  6.47s/it]\u001b[A\n",
            " 50%|█████     | 690/1377 [1:15:59<1:13:46,  6.44s/it]\u001b[A\n",
            " 50%|█████     | 691/1377 [1:16:07<1:18:58,  6.91s/it]\u001b[A\n",
            " 50%|█████     | 692/1377 [1:16:16<1:24:31,  7.40s/it]\u001b[A\n",
            " 50%|█████     | 693/1377 [1:16:22<1:20:43,  7.08s/it]\u001b[A\n",
            " 50%|█████     | 694/1377 [1:16:32<1:28:25,  7.77s/it]\u001b[A\n",
            " 50%|█████     | 695/1377 [1:16:38<1:23:57,  7.39s/it]\u001b[A\n",
            " 51%|█████     | 696/1377 [1:16:46<1:24:56,  7.48s/it]\u001b[A\n",
            " 51%|█████     | 697/1377 [1:16:52<1:18:48,  6.95s/it]\u001b[A\n",
            " 51%|█████     | 698/1377 [1:16:59<1:19:39,  7.04s/it]\u001b[A\n",
            " 51%|█████     | 699/1377 [1:17:04<1:12:55,  6.45s/it]\u001b[A\n",
            " 51%|█████     | 700/1377 [1:17:11<1:14:04,  6.56s/it]\u001b[A\n",
            " 51%|█████     | 701/1377 [1:17:17<1:12:48,  6.46s/it]\u001b[A\n",
            " 51%|█████     | 702/1377 [1:17:24<1:14:48,  6.65s/it]\u001b[A\n",
            " 51%|█████     | 703/1377 [1:17:31<1:16:51,  6.84s/it]\u001b[A\n",
            " 51%|█████     | 704/1377 [1:17:37<1:10:53,  6.32s/it]\u001b[A\n",
            " 51%|█████     | 705/1377 [1:17:43<1:12:27,  6.47s/it]\u001b[A\n",
            " 51%|█████▏    | 706/1377 [1:17:49<1:09:15,  6.19s/it]\u001b[A\n",
            " 51%|█████▏    | 707/1377 [1:17:56<1:13:08,  6.55s/it]\u001b[A\n",
            " 51%|█████▏    | 708/1377 [1:18:02<1:11:22,  6.40s/it]\u001b[A\n",
            " 51%|█████▏    | 709/1377 [1:18:10<1:14:53,  6.73s/it]\u001b[A\n",
            " 52%|█████▏    | 710/1377 [1:18:16<1:13:52,  6.64s/it]\u001b[A\n",
            " 52%|█████▏    | 711/1377 [1:18:24<1:16:12,  6.87s/it]\u001b[A\n",
            " 52%|█████▏    | 712/1377 [1:18:29<1:11:57,  6.49s/it]\u001b[A\n",
            " 52%|█████▏    | 713/1377 [1:18:37<1:14:37,  6.74s/it]\u001b[A\n",
            " 52%|█████▏    | 714/1377 [1:18:43<1:12:04,  6.52s/it]\u001b[A\n",
            " 52%|█████▏    | 715/1377 [1:18:48<1:08:09,  6.18s/it]\u001b[A\n",
            " 52%|█████▏    | 716/1377 [1:18:56<1:12:39,  6.59s/it]\u001b[A\n",
            " 52%|█████▏    | 717/1377 [1:19:01<1:08:02,  6.19s/it]\u001b[A\n",
            " 52%|█████▏    | 718/1377 [1:19:08<1:12:18,  6.58s/it]\u001b[A\n",
            " 52%|█████▏    | 719/1377 [1:19:14<1:09:40,  6.35s/it]\u001b[A\n",
            " 52%|█████▏    | 720/1377 [1:19:22<1:15:25,  6.89s/it]\u001b[A\n",
            " 52%|█████▏    | 721/1377 [1:19:28<1:11:29,  6.54s/it]\u001b[A\n",
            " 52%|█████▏    | 722/1377 [1:19:35<1:13:31,  6.73s/it]\u001b[A\n",
            " 53%|█████▎    | 723/1377 [1:19:43<1:17:36,  7.12s/it]\u001b[A\n",
            " 53%|█████▎    | 724/1377 [1:19:51<1:20:51,  7.43s/it]\u001b[A\n",
            " 53%|█████▎    | 725/1377 [1:19:57<1:14:08,  6.82s/it]\u001b[A\n",
            " 53%|█████▎    | 726/1377 [1:20:06<1:22:45,  7.63s/it]\u001b[A\n",
            " 53%|█████▎    | 727/1377 [1:20:12<1:16:44,  7.08s/it]\u001b[A\n",
            " 53%|█████▎    | 728/1377 [1:20:20<1:18:21,  7.24s/it]\u001b[A\n",
            " 53%|█████▎    | 729/1377 [1:20:25<1:13:01,  6.76s/it]\u001b[A\n",
            " 53%|█████▎    | 730/1377 [1:20:33<1:16:06,  7.06s/it]\u001b[A\n",
            " 53%|█████▎    | 731/1377 [1:20:38<1:09:59,  6.50s/it]\u001b[A\n",
            " 53%|█████▎    | 732/1377 [1:20:46<1:13:47,  6.87s/it]\u001b[A\n",
            " 53%|█████▎    | 733/1377 [1:20:51<1:08:22,  6.37s/it]\u001b[A\n",
            " 53%|█████▎    | 734/1377 [1:20:59<1:12:11,  6.74s/it]\u001b[A\n",
            " 53%|█████▎    | 735/1377 [1:21:05<1:10:11,  6.56s/it]\u001b[A\n",
            " 53%|█████▎    | 736/1377 [1:21:12<1:13:05,  6.84s/it]\u001b[A\n",
            " 54%|█████▎    | 737/1377 [1:21:18<1:09:45,  6.54s/it]\u001b[A\n",
            " 54%|█████▎    | 738/1377 [1:21:24<1:08:42,  6.45s/it]\u001b[A\n",
            " 54%|█████▎    | 739/1377 [1:21:31<1:09:44,  6.56s/it]\u001b[A\n",
            " 54%|█████▎    | 740/1377 [1:21:37<1:07:44,  6.38s/it]\u001b[A\n",
            " 54%|█████▍    | 741/1377 [1:21:44<1:09:19,  6.54s/it]\u001b[A\n",
            " 54%|█████▍    | 742/1377 [1:21:50<1:06:15,  6.26s/it]\u001b[A\n",
            " 54%|█████▍    | 743/1377 [1:21:57<1:08:19,  6.47s/it]\u001b[A\n",
            " 54%|█████▍    | 744/1377 [1:22:03<1:06:42,  6.32s/it]\u001b[A\n",
            " 54%|█████▍    | 745/1377 [1:22:11<1:11:32,  6.79s/it]\u001b[A\n",
            " 54%|█████▍    | 746/1377 [1:22:16<1:07:32,  6.42s/it]\u001b[A\n",
            " 54%|█████▍    | 747/1377 [1:22:24<1:10:17,  6.69s/it]\u001b[A\n",
            " 54%|█████▍    | 748/1377 [1:22:30<1:08:35,  6.54s/it]\u001b[A\n",
            " 54%|█████▍    | 749/1377 [1:22:36<1:07:30,  6.45s/it]\u001b[A\n",
            " 54%|█████▍    | 750/1377 [1:22:42<1:07:36,  6.47s/it]\u001b[A\n",
            " 55%|█████▍    | 751/1377 [1:22:48<1:05:05,  6.24s/it]\u001b[A\n",
            " 55%|█████▍    | 752/1377 [1:22:56<1:08:58,  6.62s/it]\u001b[A\n",
            " 55%|█████▍    | 753/1377 [1:23:01<1:03:55,  6.15s/it]\u001b[A\n",
            " 55%|█████▍    | 754/1377 [1:23:07<1:05:36,  6.32s/it]\u001b[A\n",
            " 55%|█████▍    | 755/1377 [1:23:13<1:03:51,  6.16s/it]\u001b[A\n",
            " 55%|█████▍    | 756/1377 [1:23:21<1:07:18,  6.50s/it]\u001b[A\n",
            " 55%|█████▍    | 757/1377 [1:23:26<1:05:06,  6.30s/it]\u001b[A\n",
            " 55%|█████▌    | 758/1377 [1:23:33<1:06:30,  6.45s/it]\u001b[A\n",
            " 55%|█████▌    | 759/1377 [1:23:38<1:02:42,  6.09s/it]\u001b[A\n",
            " 55%|█████▌    | 760/1377 [1:23:44<1:01:12,  5.95s/it]\u001b[A\n",
            " 55%|█████▌    | 761/1377 [1:23:53<1:09:53,  6.81s/it]\u001b[A\n",
            " 55%|█████▌    | 762/1377 [1:23:59<1:06:21,  6.47s/it]\u001b[A\n",
            " 55%|█████▌    | 763/1377 [1:24:05<1:06:28,  6.50s/it]\u001b[A\n",
            " 55%|█████▌    | 764/1377 [1:24:11<1:03:54,  6.26s/it]\u001b[A\n",
            " 56%|█████▌    | 765/1377 [1:24:18<1:06:37,  6.53s/it]\u001b[A\n",
            " 56%|█████▌    | 766/1377 [1:24:24<1:03:44,  6.26s/it]\u001b[A\n",
            " 56%|█████▌    | 767/1377 [1:24:30<1:04:47,  6.37s/it]\u001b[A\n",
            " 56%|█████▌    | 768/1377 [1:24:37<1:05:24,  6.44s/it]\u001b[A\n",
            " 56%|█████▌    | 769/1377 [1:24:42<1:00:44,  5.99s/it]\u001b[A\n",
            " 56%|█████▌    | 770/1377 [1:24:49<1:05:47,  6.50s/it]\u001b[A\n",
            " 56%|█████▌    | 771/1377 [1:24:55<1:02:34,  6.19s/it]\u001b[A\n",
            " 56%|█████▌    | 772/1377 [1:25:03<1:08:17,  6.77s/it]\u001b[A\n",
            " 56%|█████▌    | 773/1377 [1:25:09<1:04:58,  6.45s/it]\u001b[A\n",
            " 56%|█████▌    | 774/1377 [1:25:16<1:08:18,  6.80s/it]\u001b[A\n",
            " 56%|█████▋    | 775/1377 [1:25:22<1:04:24,  6.42s/it]\u001b[A\n",
            " 56%|█████▋    | 776/1377 [1:25:30<1:08:36,  6.85s/it]\u001b[A\n",
            " 56%|█████▋    | 777/1377 [1:25:35<1:02:37,  6.26s/it]\u001b[A\n",
            " 56%|█████▋    | 778/1377 [1:25:40<1:01:18,  6.14s/it]\u001b[A\n",
            " 57%|█████▋    | 779/1377 [1:25:46<59:39,  5.99s/it]  \u001b[A\n",
            " 57%|█████▋    | 780/1377 [1:25:52<58:25,  5.87s/it]\u001b[A\n",
            " 57%|█████▋    | 781/1377 [1:25:59<1:02:37,  6.30s/it]\u001b[A\n",
            " 57%|█████▋    | 782/1377 [1:26:04<59:16,  5.98s/it]  \u001b[A\n",
            " 57%|█████▋    | 783/1377 [1:26:12<1:05:12,  6.59s/it]\u001b[A\n",
            " 57%|█████▋    | 784/1377 [1:26:19<1:04:34,  6.53s/it]\u001b[A\n",
            " 57%|█████▋    | 785/1377 [1:26:26<1:07:40,  6.86s/it]\u001b[A\n",
            " 57%|█████▋    | 786/1377 [1:26:32<1:03:12,  6.42s/it]\u001b[A\n",
            " 57%|█████▋    | 787/1377 [1:26:38<1:03:41,  6.48s/it]\u001b[A\n",
            " 57%|█████▋    | 788/1377 [1:26:45<1:03:35,  6.48s/it]\u001b[A\n",
            " 57%|█████▋    | 789/1377 [1:26:53<1:08:08,  6.95s/it]\u001b[A\n",
            " 57%|█████▋    | 790/1377 [1:26:59<1:05:56,  6.74s/it]\u001b[A\n",
            " 57%|█████▋    | 791/1377 [1:27:07<1:08:00,  6.96s/it]\u001b[A\n",
            " 58%|█████▊    | 792/1377 [1:27:11<1:01:13,  6.28s/it]\u001b[A\n",
            " 58%|█████▊    | 793/1377 [1:27:17<59:01,  6.06s/it]  \u001b[A\n",
            " 58%|█████▊    | 794/1377 [1:27:28<1:14:26,  7.66s/it]\u001b[A\n",
            " 58%|█████▊    | 795/1377 [1:27:35<1:12:57,  7.52s/it]\u001b[A\n",
            " 58%|█████▊    | 796/1377 [1:27:41<1:08:04,  7.03s/it]\u001b[A\n",
            " 58%|█████▊    | 797/1377 [1:27:48<1:05:41,  6.80s/it]\u001b[A\n",
            " 58%|█████▊    | 798/1377 [1:27:54<1:05:55,  6.83s/it]\u001b[A\n",
            " 58%|█████▊    | 799/1377 [1:28:02<1:07:41,  7.03s/it]\u001b[A\n",
            " 58%|█████▊    | 800/1377 [1:28:07<1:01:37,  6.41s/it]\u001b[A\n",
            " 58%|█████▊    | 801/1377 [1:28:13<1:01:21,  6.39s/it]\u001b[A\n",
            " 58%|█████▊    | 802/1377 [1:28:20<1:02:19,  6.50s/it]\u001b[A\n",
            " 58%|█████▊    | 803/1377 [1:28:26<59:35,  6.23s/it]  \u001b[A\n",
            " 58%|█████▊    | 804/1377 [1:28:32<1:01:15,  6.41s/it]\u001b[A\n",
            " 58%|█████▊    | 805/1377 [1:28:38<59:01,  6.19s/it]  \u001b[A\n",
            " 59%|█████▊    | 806/1377 [1:28:45<1:00:39,  6.37s/it]\u001b[A\n",
            " 59%|█████▊    | 807/1377 [1:28:51<59:44,  6.29s/it]  \u001b[A\n",
            " 59%|█████▊    | 808/1377 [1:28:58<1:01:14,  6.46s/it]\u001b[A\n",
            " 59%|█████▉    | 809/1377 [1:29:04<1:00:13,  6.36s/it]\u001b[A\n",
            " 59%|█████▉    | 810/1377 [1:29:10<57:51,  6.12s/it]  \u001b[A\n",
            " 59%|█████▉    | 811/1377 [1:29:17<1:01:27,  6.52s/it]\u001b[A\n",
            " 59%|█████▉    | 812/1377 [1:29:23<1:00:43,  6.45s/it]\u001b[A\n",
            " 59%|█████▉    | 813/1377 [1:29:31<1:03:27,  6.75s/it]\u001b[A\n",
            " 59%|█████▉    | 814/1377 [1:29:36<59:27,  6.34s/it]  \u001b[A\n",
            " 59%|█████▉    | 815/1377 [1:29:43<1:01:22,  6.55s/it]\u001b[A\n",
            " 59%|█████▉    | 816/1377 [1:29:49<58:09,  6.22s/it]  \u001b[A\n",
            " 59%|█████▉    | 817/1377 [1:29:55<59:29,  6.37s/it]\u001b[A\n",
            " 59%|█████▉    | 818/1377 [1:30:01<58:19,  6.26s/it]\u001b[A\n",
            " 59%|█████▉    | 819/1377 [1:30:07<57:47,  6.21s/it]\u001b[A\n",
            " 60%|█████▉    | 820/1377 [1:30:13<55:53,  6.02s/it]\u001b[A\n",
            " 60%|█████▉    | 821/1377 [1:30:18<54:11,  5.85s/it]\u001b[A\n",
            " 60%|█████▉    | 822/1377 [1:30:25<56:44,  6.13s/it]\u001b[A\n",
            " 60%|█████▉    | 823/1377 [1:30:31<55:11,  5.98s/it]\u001b[A\n",
            " 60%|█████▉    | 824/1377 [1:30:38<57:59,  6.29s/it]\u001b[A\n",
            " 60%|█████▉    | 825/1377 [1:30:44<56:07,  6.10s/it]\u001b[A\n",
            " 60%|█████▉    | 826/1377 [1:30:49<54:44,  5.96s/it]\u001b[A\n",
            " 60%|██████    | 827/1377 [1:30:56<55:46,  6.08s/it]\u001b[A\n",
            " 60%|██████    | 828/1377 [1:31:01<53:24,  5.84s/it]\u001b[A\n",
            " 60%|██████    | 829/1377 [1:31:10<1:02:10,  6.81s/it]\u001b[A\n",
            " 60%|██████    | 830/1377 [1:31:16<59:13,  6.50s/it]  \u001b[A\n",
            " 60%|██████    | 831/1377 [1:31:22<59:13,  6.51s/it]\u001b[A\n",
            " 60%|██████    | 832/1377 [1:31:28<57:30,  6.33s/it]\u001b[A\n",
            " 60%|██████    | 833/1377 [1:31:34<56:14,  6.20s/it]\u001b[A\n",
            " 61%|██████    | 834/1377 [1:31:41<57:01,  6.30s/it]\u001b[A\n",
            " 61%|██████    | 835/1377 [1:31:46<55:29,  6.14s/it]\u001b[A\n",
            " 61%|██████    | 836/1377 [1:31:53<57:51,  6.42s/it]\u001b[A\n",
            " 61%|██████    | 837/1377 [1:31:58<54:14,  6.03s/it]\u001b[A\n",
            " 61%|██████    | 838/1377 [1:32:06<57:51,  6.44s/it]\u001b[A\n",
            " 61%|██████    | 839/1377 [1:32:12<57:07,  6.37s/it]\u001b[A\n",
            " 61%|██████    | 840/1377 [1:32:20<1:01:16,  6.85s/it]\u001b[A\n",
            " 61%|██████    | 841/1377 [1:32:26<57:59,  6.49s/it]  \u001b[A\n",
            " 61%|██████    | 842/1377 [1:32:32<58:03,  6.51s/it]\u001b[A\n",
            " 61%|██████    | 843/1377 [1:32:38<55:46,  6.27s/it]\u001b[A\n",
            " 61%|██████▏   | 844/1377 [1:32:45<58:15,  6.56s/it]\u001b[A\n",
            " 61%|██████▏   | 845/1377 [1:32:52<58:20,  6.58s/it]\u001b[A\n",
            " 61%|██████▏   | 846/1377 [1:32:58<58:18,  6.59s/it]\u001b[A\n",
            " 62%|██████▏   | 847/1377 [1:33:05<58:09,  6.58s/it]\u001b[A\n",
            " 62%|██████▏   | 848/1377 [1:33:12<59:19,  6.73s/it]\u001b[A\n",
            " 62%|██████▏   | 849/1377 [1:33:18<57:01,  6.48s/it]\u001b[A\n",
            " 62%|██████▏   | 850/1377 [1:33:25<59:02,  6.72s/it]\u001b[A\n",
            " 62%|██████▏   | 851/1377 [1:33:34<1:04:11,  7.32s/it]\u001b[A\n",
            " 62%|██████▏   | 852/1377 [1:33:42<1:06:32,  7.61s/it]\u001b[A\n",
            " 62%|██████▏   | 853/1377 [1:33:48<1:00:16,  6.90s/it]\u001b[A\n",
            " 62%|██████▏   | 854/1377 [1:33:53<56:31,  6.48s/it]  \u001b[A\n",
            " 62%|██████▏   | 855/1377 [1:34:00<58:08,  6.68s/it]\u001b[A\n",
            " 62%|██████▏   | 856/1377 [1:34:06<56:19,  6.49s/it]\u001b[A\n",
            " 62%|██████▏   | 857/1377 [1:34:13<58:17,  6.73s/it]\u001b[A\n",
            " 62%|██████▏   | 858/1377 [1:34:20<56:48,  6.57s/it]\u001b[A\n",
            " 62%|██████▏   | 859/1377 [1:34:27<59:53,  6.94s/it]\u001b[A\n",
            " 62%|██████▏   | 860/1377 [1:34:34<57:40,  6.69s/it]\u001b[A\n",
            " 63%|██████▎   | 861/1377 [1:34:41<59:46,  6.95s/it]\u001b[A\n",
            " 63%|██████▎   | 862/1377 [1:34:49<1:02:32,  7.29s/it]\u001b[A\n",
            " 63%|██████▎   | 863/1377 [1:34:56<1:01:38,  7.20s/it]\u001b[A\n",
            " 63%|██████▎   | 864/1377 [1:35:01<56:05,  6.56s/it]  \u001b[A\n",
            " 63%|██████▎   | 865/1377 [1:35:09<59:09,  6.93s/it]\u001b[A\n",
            " 63%|██████▎   | 866/1377 [1:35:15<55:36,  6.53s/it]\u001b[A\n",
            " 63%|██████▎   | 867/1377 [1:35:23<58:52,  6.93s/it]\u001b[A\n",
            " 63%|██████▎   | 868/1377 [1:35:28<55:06,  6.50s/it]\u001b[A\n",
            " 63%|██████▎   | 869/1377 [1:35:35<55:22,  6.54s/it]\u001b[A\n",
            " 63%|██████▎   | 870/1377 [1:35:41<54:31,  6.45s/it]\u001b[A\n",
            " 63%|██████▎   | 871/1377 [1:35:48<55:40,  6.60s/it]\u001b[A\n",
            " 63%|██████▎   | 872/1377 [1:35:54<53:54,  6.40s/it]\u001b[A\n",
            " 63%|██████▎   | 873/1377 [1:36:01<54:35,  6.50s/it]\u001b[A\n",
            " 63%|██████▎   | 874/1377 [1:36:06<52:42,  6.29s/it]\u001b[A\n",
            " 64%|██████▎   | 875/1377 [1:36:12<49:51,  5.96s/it]\u001b[A\n",
            " 64%|██████▎   | 876/1377 [1:36:18<51:47,  6.20s/it]\u001b[A\n",
            " 64%|██████▎   | 877/1377 [1:36:24<51:40,  6.20s/it]\u001b[A\n",
            " 64%|██████▍   | 878/1377 [1:36:31<52:46,  6.34s/it]\u001b[A\n",
            " 64%|██████▍   | 879/1377 [1:36:37<51:54,  6.25s/it]\u001b[A\n",
            " 64%|██████▍   | 880/1377 [1:36:45<54:55,  6.63s/it]\u001b[A\n",
            " 64%|██████▍   | 881/1377 [1:36:52<55:33,  6.72s/it]\u001b[A\n",
            " 64%|██████▍   | 882/1377 [1:36:58<55:11,  6.69s/it]\u001b[A\n",
            " 64%|██████▍   | 883/1377 [1:37:04<51:58,  6.31s/it]\u001b[A\n",
            " 64%|██████▍   | 884/1377 [1:37:11<53:12,  6.48s/it]\u001b[A\n",
            " 64%|██████▍   | 885/1377 [1:37:18<54:27,  6.64s/it]\u001b[A\n",
            " 64%|██████▍   | 886/1377 [1:37:23<51:59,  6.35s/it]\u001b[A\n",
            " 64%|██████▍   | 887/1377 [1:37:31<55:37,  6.81s/it]\u001b[A\n",
            " 64%|██████▍   | 888/1377 [1:37:37<53:46,  6.60s/it]\u001b[A\n",
            " 65%|██████▍   | 889/1377 [1:37:43<52:39,  6.48s/it]\u001b[A\n",
            " 65%|██████▍   | 890/1377 [1:37:49<50:46,  6.26s/it]\u001b[A\n",
            " 65%|██████▍   | 891/1377 [1:37:57<53:33,  6.61s/it]\u001b[A\n",
            " 65%|██████▍   | 892/1377 [1:38:03<54:03,  6.69s/it]\u001b[A\n",
            " 65%|██████▍   | 893/1377 [1:38:10<54:36,  6.77s/it]\u001b[A\n",
            " 65%|██████▍   | 894/1377 [1:38:16<50:31,  6.28s/it]\u001b[A\n",
            " 65%|██████▍   | 895/1377 [1:38:24<55:24,  6.90s/it]\u001b[A\n",
            " 65%|██████▌   | 896/1377 [1:38:30<53:44,  6.70s/it]\u001b[A\n",
            " 65%|██████▌   | 897/1377 [1:38:36<52:12,  6.53s/it]\u001b[A\n",
            " 65%|██████▌   | 898/1377 [1:38:43<53:29,  6.70s/it]\u001b[A\n",
            " 65%|██████▌   | 899/1377 [1:38:50<54:08,  6.80s/it]\u001b[A\n",
            " 65%|██████▌   | 900/1377 [1:38:58<55:53,  7.03s/it]\u001b[A\n",
            " 65%|██████▌   | 901/1377 [1:39:04<53:52,  6.79s/it]\u001b[A\n",
            " 66%|██████▌   | 902/1377 [1:39:10<51:59,  6.57s/it]\u001b[A\n",
            " 66%|██████▌   | 903/1377 [1:39:15<48:44,  6.17s/it]\u001b[A\n",
            " 66%|██████▌   | 904/1377 [1:39:24<53:29,  6.79s/it]\u001b[A\n",
            " 66%|██████▌   | 905/1377 [1:39:29<50:37,  6.44s/it]\u001b[A\n",
            " 66%|██████▌   | 906/1377 [1:39:36<51:23,  6.55s/it]\u001b[A\n",
            " 66%|██████▌   | 907/1377 [1:39:43<51:28,  6.57s/it]\u001b[A\n",
            " 66%|██████▌   | 908/1377 [1:39:50<53:05,  6.79s/it]\u001b[A\n",
            " 66%|██████▌   | 909/1377 [1:39:56<51:48,  6.64s/it]\u001b[A\n",
            " 66%|██████▌   | 910/1377 [1:40:03<52:05,  6.69s/it]\u001b[A\n",
            " 66%|██████▌   | 911/1377 [1:40:10<52:17,  6.73s/it]\u001b[A\n",
            " 66%|██████▌   | 912/1377 [1:40:17<53:39,  6.92s/it]\u001b[A\n",
            " 66%|██████▋   | 913/1377 [1:40:23<50:03,  6.47s/it]\u001b[A\n",
            " 66%|██████▋   | 914/1377 [1:40:28<47:41,  6.18s/it]\u001b[A\n",
            " 66%|██████▋   | 915/1377 [1:40:35<49:31,  6.43s/it]\u001b[A\n",
            " 67%|██████▋   | 916/1377 [1:40:41<48:22,  6.30s/it]\u001b[A\n",
            " 67%|██████▋   | 917/1377 [1:40:49<52:21,  6.83s/it]\u001b[A\n",
            " 67%|██████▋   | 918/1377 [1:40:53<43:50,  5.73s/it]\u001b[A\n",
            " 67%|██████▋   | 919/1377 [1:41:00<48:35,  6.36s/it]\u001b[A\n",
            " 67%|██████▋   | 920/1377 [1:41:06<46:29,  6.10s/it]\u001b[A\n",
            " 67%|██████▋   | 921/1377 [1:41:13<48:48,  6.42s/it]\u001b[A\n",
            " 67%|██████▋   | 922/1377 [1:41:19<47:25,  6.25s/it]\u001b[A\n",
            " 67%|██████▋   | 923/1377 [1:41:24<45:27,  6.01s/it]\u001b[A\n",
            " 67%|██████▋   | 924/1377 [1:41:32<48:58,  6.49s/it]\u001b[A\n",
            " 67%|██████▋   | 925/1377 [1:41:38<47:58,  6.37s/it]\u001b[A\n",
            " 67%|██████▋   | 926/1377 [1:41:46<50:30,  6.72s/it]\u001b[A\n",
            " 67%|██████▋   | 927/1377 [1:41:51<48:05,  6.41s/it]\u001b[A\n",
            " 67%|██████▋   | 928/1377 [1:42:00<54:10,  7.24s/it]\u001b[A\n",
            " 67%|██████▋   | 929/1377 [1:42:06<50:32,  6.77s/it]\u001b[A\n",
            " 68%|██████▊   | 930/1377 [1:42:13<50:17,  6.75s/it]\u001b[A\n",
            " 68%|██████▊   | 931/1377 [1:42:19<49:58,  6.72s/it]\u001b[A\n",
            " 68%|██████▊   | 932/1377 [1:42:27<52:42,  7.11s/it]\u001b[A\n",
            " 68%|██████▊   | 933/1377 [1:42:33<50:09,  6.78s/it]\u001b[A\n",
            " 68%|██████▊   | 934/1377 [1:42:41<51:57,  7.04s/it]\u001b[A\n",
            " 68%|██████▊   | 935/1377 [1:42:47<49:09,  6.67s/it]\u001b[A\n",
            " 68%|██████▊   | 936/1377 [1:42:55<52:29,  7.14s/it]\u001b[A\n",
            " 68%|██████▊   | 937/1377 [1:43:01<49:05,  6.69s/it]\u001b[A\n",
            " 68%|██████▊   | 938/1377 [1:43:08<49:38,  6.78s/it]\u001b[A\n",
            " 68%|██████▊   | 939/1377 [1:43:13<45:58,  6.30s/it]\u001b[A\n",
            " 68%|██████▊   | 940/1377 [1:43:20<47:49,  6.57s/it]\u001b[A\n",
            " 68%|██████▊   | 941/1377 [1:43:26<46:33,  6.41s/it]\u001b[A\n",
            " 68%|██████▊   | 942/1377 [1:43:31<43:07,  5.95s/it]\u001b[A\n",
            " 68%|██████▊   | 943/1377 [1:43:39<46:13,  6.39s/it]\u001b[A\n",
            " 69%|██████▊   | 944/1377 [1:43:45<46:43,  6.47s/it]\u001b[A\n",
            " 69%|██████▊   | 945/1377 [1:43:52<46:36,  6.47s/it]\u001b[A\n",
            " 69%|██████▊   | 946/1377 [1:43:57<43:54,  6.11s/it]\u001b[A\n",
            " 69%|██████▉   | 947/1377 [1:44:05<47:04,  6.57s/it]\u001b[A\n",
            " 69%|██████▉   | 948/1377 [1:44:10<44:10,  6.18s/it]\u001b[A\n",
            " 69%|██████▉   | 949/1377 [1:44:17<46:27,  6.51s/it]\u001b[A\n",
            " 69%|██████▉   | 950/1377 [1:44:23<44:01,  6.19s/it]\u001b[A\n",
            " 69%|██████▉   | 951/1377 [1:44:30<46:39,  6.57s/it]\u001b[A\n",
            " 69%|██████▉   | 952/1377 [1:44:37<48:02,  6.78s/it]\u001b[A\n",
            " 69%|██████▉   | 953/1377 [1:44:44<47:50,  6.77s/it]\u001b[A\n",
            " 69%|██████▉   | 954/1377 [1:44:50<46:03,  6.53s/it]\u001b[A\n",
            " 69%|██████▉   | 955/1377 [1:44:55<43:19,  6.16s/it]\u001b[A\n",
            " 69%|██████▉   | 956/1377 [1:45:03<46:52,  6.68s/it]\u001b[A\n",
            " 69%|██████▉   | 957/1377 [1:45:10<47:21,  6.76s/it]\u001b[A\n",
            " 70%|██████▉   | 958/1377 [1:45:17<47:40,  6.83s/it]\u001b[A\n",
            " 70%|██████▉   | 959/1377 [1:45:24<46:47,  6.72s/it]\u001b[A\n",
            " 70%|██████▉   | 960/1377 [1:45:30<45:37,  6.57s/it]\u001b[A\n",
            " 70%|██████▉   | 961/1377 [1:45:36<44:20,  6.40s/it]\u001b[A\n",
            " 70%|██████▉   | 962/1377 [1:45:44<48:58,  7.08s/it]\u001b[A\n",
            " 70%|██████▉   | 963/1377 [1:45:51<47:07,  6.83s/it]\u001b[A\n",
            " 70%|███████   | 964/1377 [1:45:58<48:27,  7.04s/it]\u001b[A\n",
            " 70%|███████   | 965/1377 [1:46:05<47:07,  6.86s/it]\u001b[A\n",
            " 70%|███████   | 966/1377 [1:46:12<48:39,  7.10s/it]\u001b[A\n",
            " 70%|███████   | 967/1377 [1:46:18<45:18,  6.63s/it]\u001b[A\n",
            " 70%|███████   | 968/1377 [1:46:25<46:21,  6.80s/it]\u001b[A\n",
            " 70%|███████   | 969/1377 [1:46:31<44:30,  6.55s/it]\u001b[A\n",
            " 70%|███████   | 970/1377 [1:46:38<44:32,  6.57s/it]\u001b[A\n",
            " 71%|███████   | 971/1377 [1:46:44<44:39,  6.60s/it]\u001b[A\n",
            " 71%|███████   | 972/1377 [1:46:50<42:07,  6.24s/it]\u001b[A\n",
            " 71%|███████   | 973/1377 [1:46:57<43:29,  6.46s/it]\u001b[A\n",
            " 71%|███████   | 974/1377 [1:47:03<42:09,  6.28s/it]\u001b[A\n",
            " 71%|███████   | 975/1377 [1:47:10<44:18,  6.61s/it]\u001b[A\n",
            " 71%|███████   | 976/1377 [1:47:15<41:17,  6.18s/it]\u001b[A\n",
            " 71%|███████   | 977/1377 [1:47:23<44:45,  6.71s/it]\u001b[A\n",
            " 71%|███████   | 978/1377 [1:47:28<42:00,  6.32s/it]\u001b[A\n",
            " 71%|███████   | 979/1377 [1:47:36<43:59,  6.63s/it]\u001b[A\n",
            " 71%|███████   | 980/1377 [1:47:42<42:01,  6.35s/it]\u001b[A\n",
            " 71%|███████   | 981/1377 [1:47:50<45:34,  6.90s/it]\u001b[A\n",
            " 71%|███████▏  | 982/1377 [1:47:56<43:14,  6.57s/it]\u001b[A\n",
            " 71%|███████▏  | 983/1377 [1:48:03<44:55,  6.84s/it]\u001b[A\n",
            " 71%|███████▏  | 984/1377 [1:48:09<43:38,  6.66s/it]\u001b[A\n",
            " 72%|███████▏  | 985/1377 [1:48:16<44:08,  6.76s/it]\u001b[A\n",
            " 72%|███████▏  | 986/1377 [1:48:22<42:03,  6.45s/it]\u001b[A\n",
            " 72%|███████▏  | 987/1377 [1:48:30<44:52,  6.90s/it]\u001b[A\n",
            " 72%|███████▏  | 988/1377 [1:48:36<42:42,  6.59s/it]\u001b[A\n",
            " 72%|███████▏  | 989/1377 [1:48:41<39:12,  6.06s/it]\u001b[A\n",
            " 72%|███████▏  | 990/1377 [1:48:48<41:05,  6.37s/it]\u001b[A\n",
            " 72%|███████▏  | 991/1377 [1:48:54<40:27,  6.29s/it]\u001b[A\n",
            " 72%|███████▏  | 992/1377 [1:49:01<41:18,  6.44s/it]\u001b[A\n",
            " 72%|███████▏  | 993/1377 [1:49:06<39:17,  6.14s/it]\u001b[A\n",
            " 72%|███████▏  | 994/1377 [1:49:14<42:08,  6.60s/it]\u001b[A\n",
            " 72%|███████▏  | 995/1377 [1:49:22<44:28,  6.99s/it]\u001b[A\n",
            " 72%|███████▏  | 996/1377 [1:49:29<45:48,  7.21s/it]\u001b[A\n",
            " 72%|███████▏  | 997/1377 [1:49:35<42:12,  6.67s/it]\u001b[A\n",
            " 72%|███████▏  | 998/1377 [1:49:42<43:23,  6.87s/it]\u001b[A\n",
            " 73%|███████▎  | 999/1377 [1:49:49<42:48,  6.79s/it]\u001b[A\n",
            " 73%|███████▎  | 1000/1377 [1:49:56<43:25,  6.91s/it]\u001b[A\n",
            " 73%|███████▎  | 1001/1377 [1:50:01<40:51,  6.52s/it]\u001b[A\n",
            " 73%|███████▎  | 1002/1377 [1:50:08<41:22,  6.62s/it]\u001b[A\n",
            " 73%|███████▎  | 1003/1377 [1:50:14<40:16,  6.46s/it]\u001b[A\n",
            " 73%|███████▎  | 1004/1377 [1:50:20<38:29,  6.19s/it]\u001b[A\n",
            " 73%|███████▎  | 1005/1377 [1:50:26<38:23,  6.19s/it]\u001b[A\n",
            " 73%|███████▎  | 1006/1377 [1:50:32<36:58,  5.98s/it]\u001b[A\n",
            " 73%|███████▎  | 1007/1377 [1:50:39<39:58,  6.48s/it]\u001b[A\n",
            " 73%|███████▎  | 1008/1377 [1:50:45<38:40,  6.29s/it]\u001b[A\n",
            " 73%|███████▎  | 1009/1377 [1:50:52<39:32,  6.45s/it]\u001b[A\n",
            " 73%|███████▎  | 1010/1377 [1:50:58<39:34,  6.47s/it]\u001b[A\n",
            " 73%|███████▎  | 1011/1377 [1:51:06<41:42,  6.84s/it]\u001b[A\n",
            " 73%|███████▎  | 1012/1377 [1:51:12<39:30,  6.49s/it]\u001b[A\n",
            " 74%|███████▎  | 1013/1377 [1:51:21<43:18,  7.14s/it]\u001b[A\n",
            " 74%|███████▎  | 1014/1377 [1:51:26<40:11,  6.64s/it]\u001b[A\n",
            " 74%|███████▎  | 1015/1377 [1:51:34<42:27,  7.04s/it]\u001b[A\n",
            " 74%|███████▍  | 1016/1377 [1:51:39<39:24,  6.55s/it]\u001b[A\n",
            " 74%|███████▍  | 1017/1377 [1:51:49<45:13,  7.54s/it]\u001b[A\n",
            " 74%|███████▍  | 1018/1377 [1:51:57<45:09,  7.55s/it]\u001b[A\n",
            " 74%|███████▍  | 1019/1377 [1:52:03<43:22,  7.27s/it]\u001b[A\n",
            " 74%|███████▍  | 1020/1377 [1:52:09<39:56,  6.71s/it]\u001b[A\n",
            " 74%|███████▍  | 1021/1377 [1:52:16<40:47,  6.87s/it]\u001b[A\n",
            " 74%|███████▍  | 1022/1377 [1:52:22<39:44,  6.72s/it]\u001b[A\n",
            " 74%|███████▍  | 1023/1377 [1:52:30<40:30,  6.87s/it]\u001b[A\n",
            " 74%|███████▍  | 1024/1377 [1:52:36<39:03,  6.64s/it]\u001b[A\n",
            " 74%|███████▍  | 1025/1377 [1:52:44<41:47,  7.12s/it]\u001b[A\n",
            " 75%|███████▍  | 1026/1377 [1:52:51<40:58,  7.00s/it]\u001b[A\n",
            " 75%|███████▍  | 1027/1377 [1:52:58<40:59,  7.03s/it]\u001b[A\n",
            " 75%|███████▍  | 1028/1377 [1:53:03<37:49,  6.50s/it]\u001b[A\n",
            " 75%|███████▍  | 1029/1377 [1:53:11<39:19,  6.78s/it]\u001b[A\n",
            " 75%|███████▍  | 1030/1377 [1:53:16<37:31,  6.49s/it]\u001b[A\n",
            " 75%|███████▍  | 1031/1377 [1:53:24<40:00,  6.94s/it]\u001b[A\n",
            " 75%|███████▍  | 1032/1377 [1:53:30<38:28,  6.69s/it]\u001b[A\n",
            " 75%|███████▌  | 1033/1377 [1:53:36<36:58,  6.45s/it]\u001b[A\n",
            " 75%|███████▌  | 1034/1377 [1:53:43<37:01,  6.48s/it]\u001b[A\n",
            " 75%|███████▌  | 1035/1377 [1:53:49<36:48,  6.46s/it]\u001b[A\n",
            " 75%|███████▌  | 1036/1377 [1:53:56<37:28,  6.59s/it]\u001b[A\n",
            " 75%|███████▌  | 1037/1377 [1:54:02<36:18,  6.41s/it]\u001b[A\n",
            " 75%|███████▌  | 1038/1377 [1:54:09<36:47,  6.51s/it]\u001b[A\n",
            " 75%|███████▌  | 1039/1377 [1:54:15<35:57,  6.38s/it]\u001b[A\n",
            " 76%|███████▌  | 1040/1377 [1:54:22<36:33,  6.51s/it]\u001b[A\n",
            " 76%|███████▌  | 1041/1377 [1:54:28<35:52,  6.41s/it]\u001b[A\n",
            " 76%|███████▌  | 1042/1377 [1:54:36<38:08,  6.83s/it]\u001b[A\n",
            " 76%|███████▌  | 1043/1377 [1:54:42<36:56,  6.64s/it]\u001b[A\n",
            " 76%|███████▌  | 1044/1377 [1:54:49<37:33,  6.77s/it]\u001b[A\n",
            " 76%|███████▌  | 1045/1377 [1:54:55<35:56,  6.50s/it]\u001b[A\n",
            " 76%|███████▌  | 1046/1377 [1:55:02<36:45,  6.66s/it]\u001b[A\n",
            " 76%|███████▌  | 1047/1377 [1:55:08<35:16,  6.41s/it]\u001b[A\n",
            " 76%|███████▌  | 1048/1377 [1:55:13<33:10,  6.05s/it]\u001b[A\n",
            " 76%|███████▌  | 1049/1377 [1:55:21<35:38,  6.52s/it]\u001b[A\n",
            " 76%|███████▋  | 1050/1377 [1:55:26<34:08,  6.26s/it]\u001b[A\n",
            " 76%|███████▋  | 1051/1377 [1:55:34<35:41,  6.57s/it]\u001b[A\n",
            " 76%|███████▋  | 1052/1377 [1:55:39<33:27,  6.18s/it]\u001b[A\n",
            " 76%|███████▋  | 1053/1377 [1:55:46<35:05,  6.50s/it]\u001b[A\n",
            " 77%|███████▋  | 1054/1377 [1:55:51<32:35,  6.06s/it]\u001b[A\n",
            " 77%|███████▋  | 1055/1377 [1:55:58<34:30,  6.43s/it]\u001b[A\n",
            " 77%|███████▋  | 1056/1377 [1:56:04<32:31,  6.08s/it]\u001b[A\n",
            " 77%|███████▋  | 1057/1377 [1:56:09<31:21,  5.88s/it]\u001b[A\n",
            " 77%|███████▋  | 1058/1377 [1:56:16<32:37,  6.14s/it]\u001b[A\n",
            " 77%|███████▋  | 1059/1377 [1:56:22<32:31,  6.14s/it]\u001b[A\n",
            " 77%|███████▋  | 1060/1377 [1:56:30<34:58,  6.62s/it]\u001b[A\n",
            " 77%|███████▋  | 1061/1377 [1:56:35<33:20,  6.33s/it]\u001b[A\n",
            " 77%|███████▋  | 1062/1377 [1:56:42<33:24,  6.36s/it]\u001b[A\n",
            " 77%|███████▋  | 1063/1377 [1:56:48<33:45,  6.45s/it]\u001b[A\n",
            " 77%|███████▋  | 1064/1377 [1:56:55<34:23,  6.59s/it]\u001b[A\n",
            " 77%|███████▋  | 1065/1377 [1:57:01<33:13,  6.39s/it]\u001b[A\n",
            " 77%|███████▋  | 1066/1377 [1:57:08<33:03,  6.38s/it]\u001b[A\n",
            " 77%|███████▋  | 1067/1377 [1:57:14<32:59,  6.39s/it]\u001b[A\n",
            " 78%|███████▊  | 1068/1377 [1:57:20<31:56,  6.20s/it]\u001b[A\n",
            " 78%|███████▊  | 1069/1377 [1:57:27<33:38,  6.55s/it]\u001b[A\n",
            " 78%|███████▊  | 1070/1377 [1:57:33<32:11,  6.29s/it]\u001b[A\n",
            " 78%|███████▊  | 1071/1377 [1:57:40<33:00,  6.47s/it]\u001b[A\n",
            " 78%|███████▊  | 1072/1377 [1:57:46<31:54,  6.28s/it]\u001b[A\n",
            " 78%|███████▊  | 1073/1377 [1:57:53<34:03,  6.72s/it]\u001b[A\n",
            " 78%|███████▊  | 1074/1377 [1:58:00<33:10,  6.57s/it]\u001b[A\n",
            " 78%|███████▊  | 1075/1377 [1:58:07<34:03,  6.77s/it]\u001b[A\n",
            " 78%|███████▊  | 1076/1377 [1:58:12<31:50,  6.35s/it]\u001b[A\n",
            " 78%|███████▊  | 1077/1377 [1:58:19<32:33,  6.51s/it]\u001b[A\n",
            " 78%|███████▊  | 1078/1377 [1:58:26<32:30,  6.52s/it]\u001b[A\n",
            " 78%|███████▊  | 1079/1377 [1:58:32<32:27,  6.54s/it]\u001b[A\n",
            " 78%|███████▊  | 1080/1377 [1:58:39<33:13,  6.71s/it]\u001b[A\n",
            " 79%|███████▊  | 1081/1377 [1:58:45<32:03,  6.50s/it]\u001b[A\n",
            " 79%|███████▊  | 1082/1377 [1:58:53<33:10,  6.75s/it]\u001b[A\n",
            " 79%|███████▊  | 1083/1377 [1:58:58<31:28,  6.42s/it]\u001b[A\n",
            " 79%|███████▊  | 1084/1377 [1:59:06<33:02,  6.77s/it]\u001b[A\n",
            " 79%|███████▉  | 1085/1377 [1:59:11<30:24,  6.25s/it]\u001b[A\n",
            " 79%|███████▉  | 1086/1377 [1:59:18<31:54,  6.58s/it]\u001b[A\n",
            " 79%|███████▉  | 1087/1377 [1:59:24<30:24,  6.29s/it]\u001b[A\n",
            " 79%|███████▉  | 1088/1377 [1:59:31<32:12,  6.69s/it]\u001b[A\n",
            " 79%|███████▉  | 1089/1377 [1:59:38<31:54,  6.65s/it]\u001b[A\n",
            " 79%|███████▉  | 1090/1377 [1:59:46<33:36,  7.03s/it]\u001b[A\n",
            " 79%|███████▉  | 1091/1377 [1:59:52<32:20,  6.78s/it]\u001b[A\n",
            " 79%|███████▉  | 1092/1377 [2:00:01<35:27,  7.46s/it]\u001b[A\n",
            " 79%|███████▉  | 1093/1377 [2:00:07<32:26,  6.85s/it]\u001b[A\n",
            " 79%|███████▉  | 1094/1377 [2:00:14<33:06,  7.02s/it]\u001b[A\n",
            " 80%|███████▉  | 1095/1377 [2:00:19<30:32,  6.50s/it]\u001b[A\n",
            " 80%|███████▉  | 1096/1377 [2:00:25<28:48,  6.15s/it]\u001b[A\n",
            " 80%|███████▉  | 1097/1377 [2:00:34<32:38,  7.00s/it]\u001b[A\n",
            " 80%|███████▉  | 1098/1377 [2:00:41<32:32,  7.00s/it]\u001b[A\n",
            " 80%|███████▉  | 1099/1377 [2:00:47<31:20,  6.76s/it]\u001b[A\n",
            " 80%|███████▉  | 1100/1377 [2:00:52<28:57,  6.27s/it]\u001b[A\n",
            " 80%|███████▉  | 1101/1377 [2:01:00<31:35,  6.87s/it]\u001b[A\n",
            " 80%|████████  | 1102/1377 [2:01:06<29:30,  6.44s/it]\u001b[A\n",
            " 80%|████████  | 1103/1377 [2:01:13<30:42,  6.73s/it]\u001b[A\n",
            " 80%|████████  | 1104/1377 [2:01:19<29:36,  6.51s/it]\u001b[A\n",
            " 80%|████████  | 1105/1377 [2:01:27<31:01,  6.84s/it]\u001b[A\n",
            " 80%|████████  | 1106/1377 [2:01:32<29:17,  6.48s/it]\u001b[A\n",
            " 80%|████████  | 1107/1377 [2:01:40<30:58,  6.88s/it]\u001b[A\n",
            " 80%|████████  | 1108/1377 [2:01:46<29:08,  6.50s/it]\u001b[A\n",
            " 81%|████████  | 1109/1377 [2:01:54<31:03,  6.95s/it]\u001b[A\n",
            " 81%|████████  | 1110/1377 [2:02:00<29:51,  6.71s/it]\u001b[A\n",
            " 81%|████████  | 1111/1377 [2:02:07<30:51,  6.96s/it]\u001b[A\n",
            " 81%|████████  | 1112/1377 [2:02:13<28:58,  6.56s/it]\u001b[A\n",
            " 81%|████████  | 1113/1377 [2:02:19<28:08,  6.40s/it]\u001b[A\n",
            " 81%|████████  | 1114/1377 [2:02:25<27:28,  6.27s/it]\u001b[A\n",
            " 81%|████████  | 1115/1377 [2:02:32<28:38,  6.56s/it]\u001b[A\n",
            " 81%|████████  | 1116/1377 [2:02:39<28:15,  6.50s/it]\u001b[A\n",
            " 81%|████████  | 1117/1377 [2:02:44<27:08,  6.26s/it]\u001b[A\n",
            " 81%|████████  | 1118/1377 [2:02:53<29:35,  6.86s/it]\u001b[A\n",
            " 81%|████████▏ | 1119/1377 [2:02:59<28:48,  6.70s/it]\u001b[A\n",
            " 81%|████████▏ | 1120/1377 [2:03:06<28:44,  6.71s/it]\u001b[A\n",
            " 81%|████████▏ | 1121/1377 [2:03:12<28:29,  6.68s/it]\u001b[A\n",
            " 81%|████████▏ | 1122/1377 [2:03:19<28:15,  6.65s/it]\u001b[A\n",
            " 82%|████████▏ | 1123/1377 [2:03:26<29:24,  6.95s/it]\u001b[A\n",
            " 82%|████████▏ | 1124/1377 [2:03:34<29:52,  7.09s/it]\u001b[A\n",
            " 82%|████████▏ | 1125/1377 [2:03:40<28:43,  6.84s/it]\u001b[A\n",
            " 82%|████████▏ | 1126/1377 [2:03:47<28:09,  6.73s/it]\u001b[A\n",
            " 82%|████████▏ | 1127/1377 [2:03:53<27:15,  6.54s/it]\u001b[A\n",
            " 82%|████████▏ | 1128/1377 [2:04:01<28:49,  6.95s/it]\u001b[A\n",
            " 82%|████████▏ | 1129/1377 [2:04:05<26:03,  6.30s/it]\u001b[A\n",
            " 82%|████████▏ | 1130/1377 [2:04:15<29:54,  7.26s/it]\u001b[A\n",
            " 82%|████████▏ | 1131/1377 [2:04:20<27:31,  6.71s/it]\u001b[A\n",
            " 82%|████████▏ | 1132/1377 [2:04:27<27:10,  6.65s/it]\u001b[A\n",
            " 82%|████████▏ | 1133/1377 [2:04:33<26:37,  6.55s/it]\u001b[A\n",
            " 82%|████████▏ | 1134/1377 [2:04:38<24:38,  6.08s/it]\u001b[A\n",
            " 82%|████████▏ | 1135/1377 [2:04:45<25:35,  6.34s/it]\u001b[A\n",
            " 82%|████████▏ | 1136/1377 [2:04:51<24:30,  6.10s/it]\u001b[A\n",
            " 83%|████████▎ | 1137/1377 [2:04:59<26:30,  6.63s/it]\u001b[A\n",
            " 83%|████████▎ | 1138/1377 [2:05:04<25:18,  6.35s/it]\u001b[A\n",
            " 83%|████████▎ | 1139/1377 [2:05:12<26:44,  6.74s/it]\u001b[A\n",
            " 83%|████████▎ | 1140/1377 [2:05:18<25:18,  6.41s/it]\u001b[A\n",
            " 83%|████████▎ | 1141/1377 [2:05:25<26:42,  6.79s/it]\u001b[A\n",
            " 83%|████████▎ | 1142/1377 [2:05:30<24:33,  6.27s/it]\u001b[A\n",
            " 83%|████████▎ | 1143/1377 [2:05:37<25:12,  6.46s/it]\u001b[A\n",
            " 83%|████████▎ | 1144/1377 [2:05:43<24:08,  6.22s/it]\u001b[A\n",
            " 83%|████████▎ | 1145/1377 [2:05:48<23:20,  6.04s/it]\u001b[A\n",
            " 83%|████████▎ | 1146/1377 [2:05:56<24:46,  6.43s/it]\u001b[A\n",
            " 83%|████████▎ | 1147/1377 [2:06:01<23:38,  6.17s/it]\u001b[A\n",
            " 83%|████████▎ | 1148/1377 [2:06:09<25:08,  6.59s/it]\u001b[A\n",
            " 83%|████████▎ | 1149/1377 [2:06:14<23:28,  6.18s/it]\u001b[A\n",
            " 84%|████████▎ | 1150/1377 [2:06:21<24:38,  6.51s/it]\u001b[A\n",
            " 84%|████████▎ | 1151/1377 [2:06:28<24:22,  6.47s/it]\u001b[A\n",
            " 84%|████████▎ | 1152/1377 [2:06:36<26:32,  7.08s/it]\u001b[A\n",
            " 84%|████████▎ | 1153/1377 [2:06:42<25:21,  6.79s/it]\u001b[A\n",
            " 84%|████████▍ | 1154/1377 [2:06:50<26:07,  7.03s/it]\u001b[A\n",
            " 84%|████████▍ | 1155/1377 [2:06:57<26:07,  7.06s/it]\u001b[A\n",
            " 84%|████████▍ | 1156/1377 [2:07:04<25:29,  6.92s/it]\u001b[A\n",
            " 84%|████████▍ | 1157/1377 [2:07:10<24:08,  6.58s/it]\u001b[A\n",
            " 84%|████████▍ | 1158/1377 [2:07:17<24:46,  6.79s/it]\u001b[A\n",
            " 84%|████████▍ | 1159/1377 [2:07:22<23:18,  6.41s/it]\u001b[A\n",
            " 84%|████████▍ | 1160/1377 [2:07:28<22:04,  6.11s/it]\u001b[A\n",
            " 84%|████████▍ | 1161/1377 [2:07:35<23:00,  6.39s/it]\u001b[A\n",
            " 84%|████████▍ | 1162/1377 [2:07:43<24:35,  6.86s/it]\u001b[A\n",
            " 84%|████████▍ | 1163/1377 [2:07:49<23:19,  6.54s/it]\u001b[A\n",
            " 85%|████████▍ | 1164/1377 [2:07:54<22:08,  6.24s/it]\u001b[A\n",
            " 85%|████████▍ | 1165/1377 [2:08:01<22:43,  6.43s/it]\u001b[A\n",
            " 85%|████████▍ | 1166/1377 [2:08:07<22:10,  6.31s/it]\u001b[A\n",
            " 85%|████████▍ | 1167/1377 [2:08:15<23:26,  6.70s/it]\u001b[A\n",
            " 85%|████████▍ | 1168/1377 [2:08:20<21:37,  6.21s/it]\u001b[A\n",
            " 85%|████████▍ | 1169/1377 [2:08:27<22:40,  6.54s/it]\u001b[A\n",
            " 85%|████████▍ | 1170/1377 [2:08:33<21:59,  6.37s/it]\u001b[A\n",
            " 85%|████████▌ | 1171/1377 [2:08:40<22:19,  6.50s/it]\u001b[A\n",
            " 85%|████████▌ | 1172/1377 [2:08:46<21:59,  6.44s/it]\u001b[A\n",
            " 85%|████████▌ | 1173/1377 [2:08:52<21:36,  6.35s/it]\u001b[A\n",
            " 85%|████████▌ | 1174/1377 [2:08:58<21:23,  6.32s/it]\u001b[A\n",
            " 85%|████████▌ | 1175/1377 [2:09:05<21:01,  6.25s/it]\u001b[A\n",
            " 85%|████████▌ | 1176/1377 [2:09:11<21:15,  6.34s/it]\u001b[A\n",
            " 85%|████████▌ | 1177/1377 [2:09:18<21:41,  6.51s/it]\u001b[A\n",
            " 86%|████████▌ | 1178/1377 [2:09:25<22:23,  6.75s/it]\u001b[A\n",
            " 86%|████████▌ | 1179/1377 [2:09:31<21:32,  6.53s/it]\u001b[A\n",
            " 86%|████████▌ | 1180/1377 [2:09:38<21:45,  6.63s/it]\u001b[A\n",
            " 86%|████████▌ | 1181/1377 [2:09:43<20:19,  6.22s/it]\u001b[A\n",
            " 86%|████████▌ | 1182/1377 [2:09:49<19:50,  6.10s/it]\u001b[A\n",
            " 86%|████████▌ | 1183/1377 [2:09:56<20:00,  6.19s/it]\u001b[A\n",
            " 86%|████████▌ | 1184/1377 [2:10:02<20:18,  6.31s/it]\u001b[A\n",
            " 86%|████████▌ | 1185/1377 [2:10:09<20:30,  6.41s/it]\u001b[A\n",
            " 86%|████████▌ | 1186/1377 [2:10:16<20:37,  6.48s/it]\u001b[A\n",
            " 86%|████████▌ | 1187/1377 [2:10:24<22:46,  7.19s/it]\u001b[A\n",
            " 86%|████████▋ | 1188/1377 [2:10:31<21:48,  6.92s/it]\u001b[A\n",
            " 86%|████████▋ | 1189/1377 [2:10:36<20:32,  6.56s/it]\u001b[A\n",
            " 86%|████████▋ | 1190/1377 [2:10:42<19:55,  6.39s/it]\u001b[A\n",
            " 86%|████████▋ | 1191/1377 [2:10:50<21:18,  6.87s/it]\u001b[A\n",
            " 87%|████████▋ | 1192/1377 [2:10:56<19:56,  6.47s/it]\u001b[A\n",
            " 87%|████████▋ | 1193/1377 [2:11:03<20:21,  6.64s/it]\u001b[A\n",
            " 87%|████████▋ | 1194/1377 [2:11:08<19:12,  6.30s/it]\u001b[A\n",
            " 87%|████████▋ | 1195/1377 [2:11:16<19:57,  6.58s/it]\u001b[A\n",
            " 87%|████████▋ | 1196/1377 [2:11:21<18:20,  6.08s/it]\u001b[A\n",
            " 87%|████████▋ | 1197/1377 [2:11:26<17:41,  5.90s/it]\u001b[A\n",
            " 87%|████████▋ | 1198/1377 [2:11:34<19:13,  6.44s/it]\u001b[A\n",
            " 87%|████████▋ | 1199/1377 [2:11:39<18:21,  6.19s/it]\u001b[A\n",
            " 87%|████████▋ | 1200/1377 [2:11:47<19:49,  6.72s/it]\u001b[A\n",
            " 87%|████████▋ | 1201/1377 [2:11:54<19:21,  6.60s/it]\u001b[A\n",
            " 87%|████████▋ | 1202/1377 [2:12:01<19:30,  6.69s/it]\u001b[A\n",
            " 87%|████████▋ | 1203/1377 [2:12:06<18:16,  6.30s/it]\u001b[A\n",
            " 87%|████████▋ | 1204/1377 [2:12:13<18:35,  6.45s/it]\u001b[A\n",
            " 88%|████████▊ | 1205/1377 [2:12:18<17:18,  6.04s/it]\u001b[A\n",
            " 88%|████████▊ | 1206/1377 [2:12:26<18:59,  6.67s/it]\u001b[A\n",
            " 88%|████████▊ | 1207/1377 [2:12:31<17:56,  6.33s/it]\u001b[A\n",
            " 88%|████████▊ | 1208/1377 [2:12:39<18:26,  6.55s/it]\u001b[A\n",
            " 88%|████████▊ | 1209/1377 [2:12:45<18:24,  6.57s/it]\u001b[A\n",
            " 88%|████████▊ | 1210/1377 [2:12:52<18:05,  6.50s/it]\u001b[A\n",
            " 88%|████████▊ | 1211/1377 [2:12:57<17:24,  6.29s/it]\u001b[A\n",
            " 88%|████████▊ | 1212/1377 [2:13:03<16:35,  6.04s/it]\u001b[A\n",
            " 88%|████████▊ | 1213/1377 [2:13:09<17:03,  6.24s/it]\u001b[A\n",
            " 88%|████████▊ | 1214/1377 [2:13:16<16:58,  6.25s/it]\u001b[A\n",
            " 88%|████████▊ | 1215/1377 [2:13:23<17:54,  6.63s/it]\u001b[A\n",
            " 88%|████████▊ | 1216/1377 [2:13:29<16:40,  6.22s/it]\u001b[A\n",
            " 88%|████████▊ | 1217/1377 [2:13:36<17:55,  6.72s/it]\u001b[A\n",
            " 88%|████████▊ | 1218/1377 [2:13:42<16:53,  6.37s/it]\u001b[A\n",
            " 89%|████████▊ | 1219/1377 [2:13:50<17:43,  6.73s/it]\u001b[A\n",
            " 89%|████████▊ | 1220/1377 [2:13:57<17:54,  6.84s/it]\u001b[A\n",
            " 89%|████████▊ | 1221/1377 [2:14:03<17:31,  6.74s/it]\u001b[A\n",
            " 89%|████████▊ | 1222/1377 [2:14:10<17:35,  6.81s/it]\u001b[A\n",
            " 89%|████████▉ | 1223/1377 [2:14:15<15:47,  6.15s/it]\u001b[A\n",
            " 89%|████████▉ | 1224/1377 [2:14:22<16:10,  6.34s/it]\u001b[A\n",
            " 89%|████████▉ | 1225/1377 [2:14:28<16:15,  6.42s/it]\u001b[A\n",
            " 89%|████████▉ | 1226/1377 [2:14:36<17:17,  6.87s/it]\u001b[A\n",
            " 89%|████████▉ | 1227/1377 [2:14:42<16:09,  6.46s/it]\u001b[A\n",
            " 89%|████████▉ | 1228/1377 [2:14:48<16:16,  6.55s/it]\u001b[A\n",
            " 89%|████████▉ | 1229/1377 [2:14:54<15:35,  6.32s/it]\u001b[A\n",
            " 89%|████████▉ | 1230/1377 [2:15:02<16:40,  6.80s/it]\u001b[A\n",
            " 89%|████████▉ | 1231/1377 [2:15:08<16:00,  6.58s/it]\u001b[A\n",
            " 89%|████████▉ | 1232/1377 [2:15:15<15:52,  6.57s/it]\u001b[A\n",
            " 90%|████████▉ | 1233/1377 [2:15:20<15:09,  6.32s/it]\u001b[A\n",
            " 90%|████████▉ | 1234/1377 [2:15:25<14:01,  5.88s/it]\u001b[A\n",
            " 90%|████████▉ | 1235/1377 [2:15:33<15:11,  6.42s/it]\u001b[A\n",
            " 90%|████████▉ | 1236/1377 [2:15:39<15:02,  6.40s/it]\u001b[A\n",
            " 90%|████████▉ | 1237/1377 [2:15:46<15:06,  6.47s/it]\u001b[A\n",
            " 90%|████████▉ | 1238/1377 [2:15:51<14:08,  6.10s/it]\u001b[A\n",
            " 90%|████████▉ | 1239/1377 [2:15:58<14:33,  6.33s/it]\u001b[A\n",
            " 90%|█████████ | 1240/1377 [2:16:04<14:31,  6.36s/it]\u001b[A\n",
            " 90%|█████████ | 1241/1377 [2:16:12<15:10,  6.70s/it]\u001b[A\n",
            " 90%|█████████ | 1242/1377 [2:16:18<14:22,  6.39s/it]\u001b[A\n",
            " 90%|█████████ | 1243/1377 [2:16:23<13:44,  6.16s/it]\u001b[A\n",
            " 90%|█████████ | 1244/1377 [2:16:31<14:31,  6.55s/it]\u001b[A\n",
            " 90%|█████████ | 1245/1377 [2:16:36<13:30,  6.14s/it]\u001b[A\n",
            " 90%|█████████ | 1246/1377 [2:16:44<14:54,  6.83s/it]\u001b[A\n",
            " 91%|█████████ | 1247/1377 [2:16:52<15:24,  7.11s/it]\u001b[A\n",
            " 91%|█████████ | 1248/1377 [2:16:59<15:10,  7.06s/it]\u001b[A\n",
            " 91%|█████████ | 1249/1377 [2:17:04<13:52,  6.50s/it]\u001b[A\n",
            " 91%|█████████ | 1250/1377 [2:17:11<14:05,  6.66s/it]\u001b[A\n",
            " 91%|█████████ | 1251/1377 [2:17:18<14:03,  6.70s/it]\u001b[A\n",
            " 91%|█████████ | 1252/1377 [2:17:25<14:15,  6.84s/it]\u001b[A\n",
            " 91%|█████████ | 1253/1377 [2:17:30<12:56,  6.27s/it]\u001b[A\n",
            " 91%|█████████ | 1254/1377 [2:17:38<13:38,  6.65s/it]\u001b[A\n",
            " 91%|█████████ | 1255/1377 [2:17:43<12:54,  6.35s/it]\u001b[A\n",
            " 91%|█████████ | 1256/1377 [2:17:51<13:28,  6.69s/it]\u001b[A\n",
            " 91%|█████████▏| 1257/1377 [2:17:56<12:35,  6.30s/it]\u001b[A\n",
            " 91%|█████████▏| 1258/1377 [2:18:03<12:48,  6.46s/it]\u001b[A\n",
            " 91%|█████████▏| 1259/1377 [2:18:09<12:38,  6.43s/it]\u001b[A\n",
            " 92%|█████████▏| 1260/1377 [2:18:16<12:51,  6.59s/it]\u001b[A\n",
            " 92%|█████████▏| 1261/1377 [2:18:23<12:49,  6.63s/it]\u001b[A\n",
            " 92%|█████████▏| 1262/1377 [2:18:29<12:06,  6.32s/it]\u001b[A\n",
            " 92%|█████████▏| 1263/1377 [2:18:35<12:18,  6.48s/it]\u001b[A\n",
            " 92%|█████████▏| 1264/1377 [2:18:42<12:12,  6.49s/it]\u001b[A\n",
            " 92%|█████████▏| 1265/1377 [2:18:50<12:42,  6.80s/it]\u001b[A\n",
            " 92%|█████████▏| 1266/1377 [2:18:56<12:37,  6.83s/it]\u001b[A\n",
            " 92%|█████████▏| 1267/1377 [2:19:04<13:12,  7.20s/it]\u001b[A\n",
            " 92%|█████████▏| 1268/1377 [2:19:11<12:31,  6.90s/it]\u001b[A\n",
            " 92%|█████████▏| 1269/1377 [2:19:18<12:44,  7.08s/it]\u001b[A\n",
            " 92%|█████████▏| 1270/1377 [2:19:24<11:52,  6.66s/it]\u001b[A\n",
            " 92%|█████████▏| 1271/1377 [2:19:32<12:24,  7.03s/it]\u001b[A\n",
            " 92%|█████████▏| 1272/1377 [2:19:38<11:39,  6.66s/it]\u001b[A\n",
            " 92%|█████████▏| 1273/1377 [2:19:45<11:52,  6.85s/it]\u001b[A\n",
            " 93%|█████████▎| 1274/1377 [2:19:51<11:11,  6.52s/it]\u001b[A\n",
            " 93%|█████████▎| 1275/1377 [2:19:57<11:10,  6.58s/it]\u001b[A\n",
            " 93%|█████████▎| 1276/1377 [2:20:02<10:16,  6.10s/it]\u001b[A\n",
            " 93%|█████████▎| 1277/1377 [2:20:09<10:26,  6.26s/it]\u001b[A\n",
            " 93%|█████████▎| 1278/1377 [2:20:16<10:30,  6.37s/it]\u001b[A\n",
            " 93%|█████████▎| 1279/1377 [2:20:21<09:43,  5.95s/it]\u001b[A\n",
            " 93%|█████████▎| 1280/1377 [2:20:29<10:43,  6.63s/it]\u001b[A\n",
            " 93%|█████████▎| 1281/1377 [2:20:35<10:25,  6.52s/it]\u001b[A\n",
            " 93%|█████████▎| 1282/1377 [2:20:43<11:13,  7.09s/it]\u001b[A\n",
            " 93%|█████████▎| 1283/1377 [2:20:49<10:24,  6.65s/it]\u001b[A\n",
            " 93%|█████████▎| 1284/1377 [2:20:57<10:52,  7.02s/it]\u001b[A\n",
            " 93%|█████████▎| 1285/1377 [2:21:03<10:09,  6.63s/it]\u001b[A\n",
            " 93%|█████████▎| 1286/1377 [2:21:10<10:34,  6.98s/it]\u001b[A\n",
            " 93%|█████████▎| 1287/1377 [2:21:16<09:46,  6.52s/it]\u001b[A\n",
            " 94%|█████████▎| 1288/1377 [2:21:23<10:09,  6.84s/it]\u001b[A\n",
            " 94%|█████████▎| 1289/1377 [2:21:30<09:49,  6.69s/it]\u001b[A\n",
            " 94%|█████████▎| 1290/1377 [2:21:36<09:34,  6.60s/it]\u001b[A\n",
            " 94%|█████████▍| 1291/1377 [2:21:42<09:18,  6.49s/it]\u001b[A\n",
            " 94%|█████████▍| 1292/1377 [2:21:49<09:23,  6.62s/it]\u001b[A\n",
            " 94%|█████████▍| 1293/1377 [2:21:58<10:00,  7.15s/it]\u001b[A\n",
            " 94%|█████████▍| 1294/1377 [2:22:05<10:04,  7.29s/it]\u001b[A\n",
            " 94%|█████████▍| 1295/1377 [2:22:10<09:03,  6.62s/it]\u001b[A\n",
            " 94%|█████████▍| 1296/1377 [2:22:17<09:04,  6.72s/it]\u001b[A\n",
            " 94%|█████████▍| 1297/1377 [2:22:25<09:11,  6.89s/it]\u001b[A\n",
            " 94%|█████████▍| 1298/1377 [2:22:32<09:04,  6.90s/it]\u001b[A\n",
            " 94%|█████████▍| 1299/1377 [2:22:39<08:59,  6.91s/it]\u001b[A\n",
            " 94%|█████████▍| 1300/1377 [2:22:45<08:50,  6.89s/it]\u001b[A\n",
            " 94%|█████████▍| 1301/1377 [2:22:51<08:24,  6.63s/it]\u001b[A\n",
            " 95%|█████████▍| 1302/1377 [2:22:57<07:49,  6.26s/it]\u001b[A\n",
            " 95%|█████████▍| 1303/1377 [2:23:04<08:00,  6.49s/it]\u001b[A\n",
            " 95%|█████████▍| 1304/1377 [2:23:09<07:26,  6.12s/it]\u001b[A\n",
            " 95%|█████████▍| 1305/1377 [2:23:16<07:45,  6.47s/it]\u001b[A\n",
            " 95%|█████████▍| 1306/1377 [2:23:21<07:05,  5.99s/it]\u001b[A\n",
            " 95%|█████████▍| 1307/1377 [2:23:28<07:08,  6.13s/it]\u001b[A\n",
            " 95%|█████████▍| 1308/1377 [2:23:35<07:32,  6.56s/it]\u001b[A\n",
            " 95%|█████████▌| 1309/1377 [2:23:42<07:24,  6.54s/it]\u001b[A\n",
            " 95%|█████████▌| 1310/1377 [2:23:49<07:25,  6.65s/it]\u001b[A\n",
            " 95%|█████████▌| 1311/1377 [2:23:54<06:59,  6.36s/it]\u001b[A\n",
            " 95%|█████████▌| 1312/1377 [2:24:02<07:14,  6.68s/it]\u001b[A\n",
            " 95%|█████████▌| 1313/1377 [2:24:08<06:59,  6.56s/it]\u001b[A\n",
            " 95%|█████████▌| 1314/1377 [2:24:15<07:04,  6.74s/it]\u001b[A\n",
            " 95%|█████████▌| 1315/1377 [2:24:20<06:29,  6.28s/it]\u001b[A\n",
            " 96%|█████████▌| 1316/1377 [2:24:28<06:51,  6.75s/it]\u001b[A\n",
            " 96%|█████████▌| 1317/1377 [2:24:34<06:31,  6.53s/it]\u001b[A\n",
            " 96%|█████████▌| 1318/1377 [2:24:42<06:37,  6.74s/it]\u001b[A\n",
            " 96%|█████████▌| 1319/1377 [2:24:47<06:15,  6.47s/it]\u001b[A\n",
            " 96%|█████████▌| 1320/1377 [2:24:54<06:17,  6.63s/it]\u001b[A\n",
            " 96%|█████████▌| 1321/1377 [2:25:00<06:02,  6.47s/it]\u001b[A\n",
            " 96%|█████████▌| 1322/1377 [2:25:07<05:59,  6.54s/it]\u001b[A\n",
            " 96%|█████████▌| 1323/1377 [2:25:14<05:50,  6.49s/it]\u001b[A\n",
            " 96%|█████████▌| 1324/1377 [2:25:23<06:30,  7.36s/it]\u001b[A\n",
            " 96%|█████████▌| 1325/1377 [2:25:29<06:06,  7.05s/it]\u001b[A\n",
            " 96%|█████████▋| 1326/1377 [2:25:36<05:59,  7.04s/it]\u001b[A\n",
            " 96%|█████████▋| 1327/1377 [2:25:41<05:24,  6.49s/it]\u001b[A\n",
            " 96%|█████████▋| 1328/1377 [2:25:46<04:55,  6.03s/it]\u001b[A\n",
            " 97%|█████████▋| 1329/1377 [2:25:53<05:03,  6.33s/it]\u001b[A\n",
            " 97%|█████████▋| 1330/1377 [2:26:00<04:53,  6.25s/it]\u001b[A\n",
            " 97%|█████████▋| 1331/1377 [2:26:07<05:02,  6.58s/it]\u001b[A\n",
            " 97%|█████████▋| 1332/1377 [2:26:13<04:45,  6.34s/it]\u001b[A\n",
            " 97%|█████████▋| 1333/1377 [2:26:20<04:50,  6.60s/it]\u001b[A\n",
            " 97%|█████████▋| 1334/1377 [2:26:26<04:36,  6.43s/it]\u001b[A\n",
            " 97%|█████████▋| 1335/1377 [2:26:33<04:38,  6.63s/it]\u001b[A\n",
            " 97%|█████████▋| 1336/1377 [2:26:38<04:17,  6.28s/it]\u001b[A\n",
            " 97%|█████████▋| 1337/1377 [2:26:46<04:26,  6.66s/it]\u001b[A\n",
            " 97%|█████████▋| 1338/1377 [2:26:53<04:27,  6.87s/it]\u001b[A\n",
            " 97%|█████████▋| 1339/1377 [2:27:00<04:20,  6.85s/it]\u001b[A\n",
            " 97%|█████████▋| 1340/1377 [2:27:07<04:08,  6.72s/it]\u001b[A\n",
            " 97%|█████████▋| 1341/1377 [2:27:12<03:47,  6.31s/it]\u001b[A\n",
            " 97%|█████████▋| 1342/1377 [2:27:19<03:48,  6.52s/it]\u001b[A\n",
            " 98%|█████████▊| 1343/1377 [2:27:25<03:32,  6.26s/it]\u001b[A\n",
            " 98%|█████████▊| 1344/1377 [2:27:33<03:43,  6.78s/it]\u001b[A\n",
            " 98%|█████████▊| 1345/1377 [2:27:40<03:38,  6.84s/it]\u001b[A\n",
            " 98%|█████████▊| 1346/1377 [2:27:46<03:31,  6.84s/it]\u001b[A\n",
            " 98%|█████████▊| 1347/1377 [2:27:53<03:19,  6.64s/it]\u001b[A\n",
            " 98%|█████████▊| 1348/1377 [2:28:02<03:37,  7.50s/it]\u001b[A\n",
            " 98%|█████████▊| 1349/1377 [2:28:08<03:16,  7.03s/it]\u001b[A\n",
            " 98%|█████████▊| 1350/1377 [2:28:15<03:10,  7.07s/it]\u001b[A\n",
            " 98%|█████████▊| 1351/1377 [2:28:21<02:51,  6.58s/it]\u001b[A\n",
            " 98%|█████████▊| 1352/1377 [2:28:28<02:53,  6.92s/it]\u001b[A\n",
            " 98%|█████████▊| 1353/1377 [2:28:34<02:37,  6.55s/it]\u001b[A\n",
            " 98%|█████████▊| 1354/1377 [2:28:42<02:41,  7.02s/it]\u001b[A\n",
            " 98%|█████████▊| 1355/1377 [2:28:48<02:28,  6.74s/it]\u001b[A\n",
            " 98%|█████████▊| 1356/1377 [2:28:55<02:23,  6.81s/it]\u001b[A\n",
            " 99%|█████████▊| 1357/1377 [2:29:01<02:07,  6.39s/it]\u001b[A\n",
            " 99%|█████████▊| 1358/1377 [2:29:08<02:06,  6.68s/it]\u001b[A\n",
            " 99%|█████████▊| 1359/1377 [2:29:14<01:54,  6.37s/it]\u001b[A\n",
            " 99%|█████████▉| 1360/1377 [2:29:21<01:53,  6.66s/it]\u001b[A\n",
            " 99%|█████████▉| 1361/1377 [2:29:29<01:53,  7.11s/it]\u001b[A\n",
            " 99%|█████████▉| 1362/1377 [2:29:37<01:48,  7.20s/it]\u001b[A\n",
            " 99%|█████████▉| 1363/1377 [2:29:42<01:31,  6.55s/it]\u001b[A\n",
            " 99%|█████████▉| 1364/1377 [2:29:47<01:21,  6.29s/it]\u001b[A\n",
            " 99%|█████████▉| 1365/1377 [2:29:53<01:14,  6.23s/it]\u001b[A\n",
            " 99%|█████████▉| 1366/1377 [2:30:00<01:08,  6.25s/it]\u001b[A\n",
            " 99%|█████████▉| 1367/1377 [2:30:07<01:06,  6.68s/it]\u001b[A\n",
            " 99%|█████████▉| 1368/1377 [2:30:14<00:58,  6.56s/it]\u001b[A\n",
            " 99%|█████████▉| 1369/1377 [2:30:20<00:52,  6.59s/it]\u001b[A\n",
            " 99%|█████████▉| 1370/1377 [2:30:26<00:44,  6.36s/it]\u001b[A\n",
            "100%|█████████▉| 1371/1377 [2:30:35<00:41,  6.99s/it]\u001b[A\n",
            "100%|█████████▉| 1372/1377 [2:30:39<00:31,  6.27s/it]\u001b[A\n",
            "100%|█████████▉| 1373/1377 [2:30:47<00:26,  6.61s/it]\u001b[A\n",
            "100%|█████████▉| 1374/1377 [2:30:52<00:18,  6.22s/it]\u001b[A\n",
            "100%|█████████▉| 1375/1377 [2:31:00<00:13,  6.92s/it]\u001b[A\n",
            "100%|█████████▉| 1376/1377 [2:31:08<00:07,  7.04s/it]\u001b[A\n",
            "100%|██████████| 1377/1377 [2:31:10<00:00,  5.59s/it]\u001b[A"
          ]
        }
      ],
      "source": [
        "from accelerate import Accelerator\n",
        "from transformers import AutoModelForSequenceClassification, AdamW, get_scheduler\n",
        "\n",
        "# Initialize Accelerator (adjust device configuration if needed)\n",
        "accelerator = Accelerator()\n",
        "\n",
        "# Load pre-trained model\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)\n",
        "\n",
        "# Create optimizer\n",
        "optimizer = AdamW(model.parameters(), lr=3e-5)  # Adjust learning rate as needed\n",
        "\n",
        "# Prepare datasets and model on accelerator\n",
        "train_dl, eval_dl, model, optimizer = accelerator.prepare(train_dataloader, eval_dataloader,\n",
        "model, optimizer)\n",
        "\n",
        "# Training parameters\n",
        "num_epochs = 3\n",
        "num_training_steps = num_epochs * len(train_dl)\n",
        "\n",
        "# Learning rate scheduler (optional)\n",
        "lr_scheduler = get_scheduler(\n",
        "    \"linear\",\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=0,  # Adjust warmup steps if needed\n",
        "    num_training_steps=num_training_steps,\n",
        ")\n",
        "\n",
        "# Progress bar (optional)\n",
        "from tqdm import tqdm\n",
        "progress_bar = tqdm(range(num_training_steps))  # Uncomment to use a progress bar\n",
        "\n",
        "model.train()  # Set model to training mode\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for batch in train_dl:\n",
        "        # Move data to device (handled by Accelerator)\n",
        "        outputs = model(**batch)\n",
        "        loss = outputs.loss\n",
        "\n",
        "        # Backward pass\n",
        "        accelerator.backward(loss)\n",
        "\n",
        "        # Optimizer steps\n",
        "        optimizer.step()\n",
        "\n",
        "        # Learning rate scheduler (if used)\n",
        "        #if lr_scheduler is not None:\n",
        "        lr_scheduler.step()\n",
        "\n",
        "        # Zero gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Progress bar update (if used)\n",
        "        #if progress_bar is not None:\n",
        "        progress_bar.update(1)\n",
        "\n",
        "# Close progress bar (if used)\n",
        "#if progress_bar is not None:\n",
        "    #progress_bar.close()\n",
        "\n",
        "#print(\"Training complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RrxmujQYS4O6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqmhu2-CdkEE"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMIsDO2yV24ksFQzNbizBkd",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00eb02e931774f5db9bd1f259b524153": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "05c583e1319f4e37bf4169ba415459f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea855ef28b194860980b65ed33355857",
            "placeholder": "​",
            "style": "IPY_MODEL_ca44cd25451846afab140913b046d430",
            "value": "Map: 100%"
          }
        },
        "068d05c7c65b4d00af3a45a77fa84326": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_075737954525497e837a9da736313d0d",
              "IPY_MODEL_5b30a76b8d3843c4adbe39cf3a318422",
              "IPY_MODEL_8512abfb3e4b4da5bec9bb18b6cf2da2"
            ],
            "layout": "IPY_MODEL_41e5b9affce2480a8aa8b159fa5a0e93"
          }
        },
        "075737954525497e837a9da736313d0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30261d4719044732bbcb8f1293eec3b0",
            "placeholder": "​",
            "style": "IPY_MODEL_00eb02e931774f5db9bd1f259b524153",
            "value": "Map: 100%"
          }
        },
        "0fd043a6d67c428bab277f120ecc6637": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a9f21fc893d40a48080fc1e48d180d7",
            "max": 408,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8017d8c61e7a487db87d9f2b1442279c",
            "value": 408
          }
        },
        "10d0d2a6dab749cbafb2fb7d797dffb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee25e44c03914f849eeba4379d5c2e46",
            "max": 1725,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8f6476ad2970476290016b872164e978",
            "value": 1725
          }
        },
        "13353bb8dc5444ab8031d868326c806c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e5c68d8de65e44b089b4b9e14aa3753e",
              "IPY_MODEL_e15c53783c994ae4869c7675beac8ba8",
              "IPY_MODEL_eda8c74b61ec4782a368dd199390102f"
            ],
            "layout": "IPY_MODEL_26e0e90956f94c3992bb7afae89a43e6"
          }
        },
        "152d9931075c473abcccc38f8bc98a73": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6a27c5ece674977a0dc9e1d1a3ceea7",
            "placeholder": "​",
            "style": "IPY_MODEL_d138e5f113d644659ffe3ec4742c527c",
            "value": "Map: 100%"
          }
        },
        "1b465a9fae1a4d90a1467dfdf703b8a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_05c583e1319f4e37bf4169ba415459f5",
              "IPY_MODEL_10d0d2a6dab749cbafb2fb7d797dffb6",
              "IPY_MODEL_efdda830abc442e1b125c474c7b02057"
            ],
            "layout": "IPY_MODEL_43c19d81b7704786aaae293237d36fdb"
          }
        },
        "26e0e90956f94c3992bb7afae89a43e6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30261d4719044732bbcb8f1293eec3b0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3046b3f2522b4cb7a2b4a255c66a7d75": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "342500f7b84047429d3891736bc584b5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34c74502ec8e43629d1029f52e263f0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "41e5b9affce2480a8aa8b159fa5a0e93": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43adbb55e0ae4205a9eadfb320bacbdf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43c19d81b7704786aaae293237d36fdb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43da891411984f5b90219c24928c1f0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_342500f7b84047429d3891736bc584b5",
            "max": 408,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e5596bb6951f4f26b6ab0f7559672c88",
            "value": 408
          }
        },
        "536fb15c9d4b4126b07ee11cf267f3da": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5abff6fc4e71446b974412876fd70b84": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dce8f33164c24e749a343c6b85f08e93",
            "placeholder": "​",
            "style": "IPY_MODEL_cce7e5e39b5e4de0ac98317e9ca324b1",
            "value": "Map: 100%"
          }
        },
        "5b30a76b8d3843c4adbe39cf3a318422": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99264947bcdf43f1b0b0799df186b1ee",
            "max": 3668,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6d7923c824144f1f8c19b09faeed66c8",
            "value": 3668
          }
        },
        "5fbedac3216d4bce93ba2e8d0d880909": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "62443c400f2f4cac8e0124f3fa26f081": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6456bf586ad84e27806ca49c0af33c64": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "67dc6c7ce69e42c983009ca037db81e3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69d378fd866f4a28b1441a97d31166fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd29138f267a4675a0148eceb5cfb9d4",
            "placeholder": "​",
            "style": "IPY_MODEL_e82735f0b3ac417c8fe58f4d7d45311b",
            "value": " 408/408 [00:00&lt;00:00, 1439.58 examples/s]"
          }
        },
        "6bb7fa0e522d4a739c250fec4aad8a6c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d7923c824144f1f8c19b09faeed66c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "70588b3ecacc484b89da71f25cae7180": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_152d9931075c473abcccc38f8bc98a73",
              "IPY_MODEL_0fd043a6d67c428bab277f120ecc6637",
              "IPY_MODEL_69d378fd866f4a28b1441a97d31166fe"
            ],
            "layout": "IPY_MODEL_67dc6c7ce69e42c983009ca037db81e3"
          }
        },
        "723d781ab3f04c55b2efff36d662fd6b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7958f8efdcb2411084b62e7f9bec4698": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a9f21fc893d40a48080fc1e48d180d7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d2f83b3c4d441219eacdec86f5324cd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8017d8c61e7a487db87d9f2b1442279c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8512abfb3e4b4da5bec9bb18b6cf2da2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7958f8efdcb2411084b62e7f9bec4698",
            "placeholder": "​",
            "style": "IPY_MODEL_34c74502ec8e43629d1029f52e263f0e",
            "value": " 3668/3668 [00:00&lt;00:00, 4036.49 examples/s]"
          }
        },
        "861c5d9c92b2420f9eacc8d2003e0db4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6bb7fa0e522d4a739c250fec4aad8a6c",
            "placeholder": "​",
            "style": "IPY_MODEL_d0086d192d6544bfb406aebd640bdf6c",
            "value": " 5.75k/5.75k [00:00&lt;00:00, 207kB/s]"
          }
        },
        "89afc011e5004936ba6b2443f6029107": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f6476ad2970476290016b872164e978": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "98bf3ac2006a492abc65ff012622573d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43adbb55e0ae4205a9eadfb320bacbdf",
            "max": 5749,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3046b3f2522b4cb7a2b4a255c66a7d75",
            "value": 5749
          }
        },
        "99264947bcdf43f1b0b0799df186b1ee": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99ac9859eaea421880e0c30c626503ff": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c9d12c690614ec08a688806a92d6481": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6a27c5ece674977a0dc9e1d1a3ceea7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3e6f2364dc740ad8b2c6ca8374c3968": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89afc011e5004936ba6b2443f6029107",
            "placeholder": "​",
            "style": "IPY_MODEL_c71b4b85b4e541e592721d88c88a17f1",
            "value": "Downloading builder script: 100%"
          }
        },
        "b58f436dcf664d8eb9ba3ca574c38707": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc44600265724608a033659b3f15b26d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5abff6fc4e71446b974412876fd70b84",
              "IPY_MODEL_43da891411984f5b90219c24928c1f0d",
              "IPY_MODEL_e7a8cc79695b4788a57446d5878426a6"
            ],
            "layout": "IPY_MODEL_e8f762acaa95468a80efe683c6c71845"
          }
        },
        "bd29138f267a4675a0148eceb5cfb9d4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c40a94dd21a847ca9e30de09afa51ea9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c71b4b85b4e541e592721d88c88a17f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca44cd25451846afab140913b046d430": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cce7e5e39b5e4de0ac98317e9ca324b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d0086d192d6544bfb406aebd640bdf6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d138e5f113d644659ffe3ec4742c527c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d3badedd89db41c9b3d8eb9f2454fb62": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b3e6f2364dc740ad8b2c6ca8374c3968",
              "IPY_MODEL_98bf3ac2006a492abc65ff012622573d",
              "IPY_MODEL_861c5d9c92b2420f9eacc8d2003e0db4"
            ],
            "layout": "IPY_MODEL_7d2f83b3c4d441219eacdec86f5324cd"
          }
        },
        "dbc6591f505c4d2abd1de6e3d7577f38": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dce8f33164c24e749a343c6b85f08e93": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e15c53783c994ae4869c7675beac8ba8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_723d781ab3f04c55b2efff36d662fd6b",
            "max": 408,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dbc6591f505c4d2abd1de6e3d7577f38",
            "value": 408
          }
        },
        "e5596bb6951f4f26b6ab0f7559672c88": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e5c68d8de65e44b089b4b9e14aa3753e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c40a94dd21a847ca9e30de09afa51ea9",
            "placeholder": "​",
            "style": "IPY_MODEL_62443c400f2f4cac8e0124f3fa26f081",
            "value": "Map: 100%"
          }
        },
        "e7a8cc79695b4788a57446d5878426a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_536fb15c9d4b4126b07ee11cf267f3da",
            "placeholder": "​",
            "style": "IPY_MODEL_5fbedac3216d4bce93ba2e8d0d880909",
            "value": " 408/408 [00:00&lt;00:00, 2264.48 examples/s]"
          }
        },
        "e82735f0b3ac417c8fe58f4d7d45311b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e8f762acaa95468a80efe683c6c71845": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea855ef28b194860980b65ed33355857": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eda8c74b61ec4782a368dd199390102f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c9d12c690614ec08a688806a92d6481",
            "placeholder": "​",
            "style": "IPY_MODEL_b58f436dcf664d8eb9ba3ca574c38707",
            "value": " 408/408 [00:00&lt;00:00, 1917.63 examples/s]"
          }
        },
        "ee25e44c03914f849eeba4379d5c2e46": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efdda830abc442e1b125c474c7b02057": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99ac9859eaea421880e0c30c626503ff",
            "placeholder": "​",
            "style": "IPY_MODEL_6456bf586ad84e27806ca49c0af33c64",
            "value": " 1725/1725 [00:00&lt;00:00, 2899.01 examples/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}